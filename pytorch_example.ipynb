{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "a-iz1CbZPn2C",
        "uRjrFuK-jK2D",
        "No575nWqkfEu"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/eladhoffer/colab-notebooks/blob/master/pytorch_example.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "EgGjfCwNnYAF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train using Pytorch with a free K80 GPU from Google\n",
        "This is an example how to use one of repos to train Cifar10\n",
        "## using a K80 gpu\n",
        "change \"Runtime->change runtime type->Hardware accelerator->GPU\" before running"
      ]
    },
    {
      "metadata": {
        "id": "a-iz1CbZPn2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "metadata": {
        "id": "nTJ1uQFUioCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "fe26d5b3-5d89-4983-bc65-5921d06a1486"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "accelerator = 'cu80' if os.path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "assert accelerator == 'cu80'\n",
        "try:\n",
        "  import torch\n",
        "except:\n",
        "  !pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "\n",
        "!pip3 install torchvision\n",
        "!pip3 install bokeh"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (483.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 483.0MB 2.3MB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x561b6000 @  0x7fdc180dc2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-0.4.1\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 9.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torchvision-0.2.1\n",
            "Collecting bokeh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/1b/1bb751797f0bbbafc2642c629656ce158e7e7b7fb1110f449f7c320fb819/bokeh-0.13.0.tar.gz (16.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 16.0MB 919kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.11.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.5.3)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.10)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.14.6)\n",
            "Collecting packaging>=16.8 (from bokeh)\n",
            "  Downloading https://files.pythonhosted.org/packages/89/d1/92e6df2e503a69df9faab187c684585f0136662c12bb1f36901d426f3fab/packaging-18.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh) (1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh) (2.2.2)\n",
            "Building wheels for collected packages: bokeh\n",
            "  Running setup.py bdist_wheel for bokeh ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/05/3e/43/95ff0bde940a0a5d86ec13c22d2a4bddc97271cd788f441a63\n",
            "Successfully built bokeh\n",
            "Installing collected packages: packaging, bokeh\n",
            "Successfully installed bokeh-0.13.0 packaging-18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uRjrFuK-jK2D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create a Google Drive folder to save results"
      ]
    },
    {
      "metadata": {
        "id": "MY7FmBtGg4Gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GOOGLE_DRIVE_PATH = 'colab'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = os.path.join(\"/content/drive/My Drive/\", GOOGLE_DRIVE_PATH)\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "\n",
        "os.chdir(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3cvGLra9jklq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Use a specific github repo"
      ]
    },
    {
      "metadata": {
        "id": "rV-vJe_yjGWs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if not os.path.exists('convNet.pytorch'):\n",
        "  !git clone https://github.com/eladhoffer/convNet.pytorch --recursive\n",
        "os.chdir(os.path.join(path, 'convNet.pytorch'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "No575nWqkfEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run experiment"
      ]
    },
    {
      "metadata": {
        "id": "-Lxe9vi0O4gG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35061
        },
        "outputId": "d5b4e084-aeb8-4a6a-e916-69a13047969f"
      },
      "cell_type": "code",
      "source": [
        "!python main.py --dataset cifar10 --model resnet --model-config \"{'depth': 18}\" -b 512 --epochs 100 --save resnet18_test "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving to ./results/resnet18_test\n",
            "creating model resnet\n",
            "created model with configuration: {'dataset': 'cifar10', 'depth': 18}\n",
            "number of parameters: 175258\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'weight_decay': 0, 'momentum': 0.9}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001, 'weight_decay': 0}, {'epoch': 164, 'lr': 0.0001}]\n",
            "\n",
            "Starting Epoch: 1\n",
            "\n",
            "TRAINING - Epoch: [0][0/97]\tTime 2.424 (2.424)\tData 0.998 (0.998)\tLoss 2.3051 (2.3051)\tPrec@1 8.594 (8.594)\tPrec@5 46.875 (46.875)\t\n",
            "TRAINING - Epoch: [0][10/97]\tTime 0.149 (0.361)\tData 0.000 (0.092)\tLoss 2.1968 (2.2665)\tPrec@1 19.336 (13.459)\tPrec@5 72.461 (60.831)\t\n",
            "TRAINING - Epoch: [0][20/97]\tTime 0.152 (0.268)\tData 0.000 (0.049)\tLoss 2.0724 (2.1926)\tPrec@1 22.070 (17.866)\tPrec@5 75.391 (67.522)\t\n",
            "TRAINING - Epoch: [0][30/97]\tTime 0.155 (0.232)\tData 0.005 (0.034)\tLoss 2.0517 (2.1419)\tPrec@1 27.148 (19.890)\tPrec@5 78.906 (70.974)\t\n",
            "TRAINING - Epoch: [0][40/97]\tTime 0.152 (0.214)\tData 0.000 (0.026)\tLoss 1.9294 (2.1056)\tPrec@1 27.539 (21.151)\tPrec@5 80.664 (73.042)\t\n",
            "TRAINING - Epoch: [0][50/97]\tTime 0.172 (0.204)\tData 0.000 (0.021)\tLoss 1.8897 (2.0754)\tPrec@1 29.297 (22.300)\tPrec@5 83.789 (74.740)\t\n",
            "TRAINING - Epoch: [0][60/97]\tTime 0.153 (0.196)\tData 0.000 (0.018)\tLoss 1.9542 (2.0503)\tPrec@1 27.734 (23.121)\tPrec@5 81.055 (76.002)\t\n",
            "TRAINING - Epoch: [0][70/97]\tTime 0.151 (0.191)\tData 0.000 (0.016)\tLoss 1.8472 (2.0208)\tPrec@1 31.641 (24.122)\tPrec@5 84.570 (77.195)\t\n",
            "TRAINING - Epoch: [0][80/97]\tTime 0.159 (0.188)\tData 0.000 (0.014)\tLoss 1.7615 (1.9925)\tPrec@1 34.570 (25.096)\tPrec@5 87.891 (78.376)\t\n",
            "TRAINING - Epoch: [0][90/97]\tTime 0.149 (0.184)\tData 0.000 (0.012)\tLoss 1.7687 (1.9670)\tPrec@1 36.133 (26.080)\tPrec@5 86.719 (79.320)\t\n",
            "EVALUATING - Epoch: [0][0/20]\tTime 1.117 (1.117)\tData 1.056 (1.056)\tLoss 1.7817 (1.7817)\tPrec@1 33.398 (33.398)\tPrec@5 87.695 (87.695)\t\n",
            "EVALUATING - Epoch: [0][10/20]\tTime 0.050 (0.189)\tData 0.000 (0.129)\tLoss 1.8167 (1.7600)\tPrec@1 34.180 (34.126)\tPrec@5 86.523 (86.754)\t\n",
            "\n",
            "Results - Epoch: 1\n",
            "Training Loss 1.9527 \tTraining Prec@1 26.560 \tTraining Prec@5 79.820 \tValidation Loss 1.7631 \tValidation Prec@1 33.890 \tValidation Prec@5 86.460 \t\n",
            "\n",
            "Plot file saved at: /content/drive/My Drive/colab/convNet.pytorch/results/resnet18_test/results.html\n",
            "\n",
            "Starting Epoch: 2\n",
            "\n",
            "TRAINING - Epoch: [1][0/97]\tTime 1.338 (1.338)\tData 1.014 (1.014)\tLoss 1.7351 (1.7351)\tPrec@1 34.961 (34.961)\tPrec@5 86.914 (86.914)\t\n",
            "TRAINING - Epoch: [1][10/97]\tTime 0.176 (0.325)\tData 0.000 (0.098)\tLoss 1.7274 (1.7138)\tPrec@1 34.961 (34.055)\tPrec@5 88.477 (88.228)\t\n",
            "TRAINING - Epoch: [1][20/97]\tTime 0.157 (0.248)\tData 0.001 (0.052)\tLoss 1.7589 (1.7056)\tPrec@1 34.961 (34.626)\tPrec@5 87.695 (88.597)\t\n",
            "TRAINING - Epoch: [1][30/97]\tTime 0.160 (0.220)\tData 0.000 (0.035)\tLoss 1.7013 (1.7011)\tPrec@1 36.914 (34.690)\tPrec@5 87.891 (88.577)\t\n",
            "TRAINING - Epoch: [1][40/97]\tTime 0.164 (0.205)\tData 0.000 (0.027)\tLoss 1.5834 (1.6884)\tPrec@1 37.891 (35.175)\tPrec@5 91.211 (88.839)\t\n",
            "TRAINING - Epoch: [1][50/97]\tTime 0.174 (0.197)\tData 0.000 (0.022)\tLoss 1.6043 (1.6801)\tPrec@1 39.453 (35.616)\tPrec@5 90.625 (88.917)\t\n",
            "TRAINING - Epoch: [1][60/97]\tTime 0.157 (0.191)\tData 0.000 (0.018)\tLoss 1.6374 (1.6704)\tPrec@1 38.867 (36.014)\tPrec@5 89.648 (89.168)\t\n",
            "TRAINING - Epoch: [1][70/97]\tTime 0.156 (0.186)\tData 0.000 (0.016)\tLoss 1.5859 (1.6626)\tPrec@1 36.719 (36.257)\tPrec@5 90.820 (89.277)\t\n",
            "TRAINING - Epoch: [1][80/97]\tTime 0.147 (0.183)\tData 0.000 (0.014)\tLoss 1.5735 (1.6529)\tPrec@1 41.016 (36.605)\tPrec@5 91.211 (89.475)\t\n",
            "TRAINING - Epoch: [1][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.013)\tLoss 1.5651 (1.6422)\tPrec@1 40.820 (37.090)\tPrec@5 91.406 (89.668)\t\n",
            "EVALUATING - Epoch: [1][0/20]\tTime 1.267 (1.267)\tData 1.220 (1.220)\tLoss 1.5646 (1.5646)\tPrec@1 43.555 (43.555)\tPrec@5 91.797 (91.797)\t\n",
            "EVALUATING - Epoch: [1][10/20]\tTime 0.043 (0.191)\tData 0.000 (0.138)\tLoss 1.6707 (1.5776)\tPrec@1 41.211 (40.785)\tPrec@5 88.477 (90.891)\t\n",
            "\n",
            "Results - Epoch: 2\n",
            "Training Loss 1.6352 \tTraining Prec@1 37.371 \tTraining Prec@5 89.812 \tValidation Loss 1.5663 \tValidation Prec@1 40.940 \tValidation Prec@5 91.070 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 3\n",
            "\n",
            "TRAINING - Epoch: [2][0/97]\tTime 1.359 (1.359)\tData 1.085 (1.085)\tLoss 1.5318 (1.5318)\tPrec@1 42.578 (42.578)\tPrec@5 92.773 (92.773)\t\n",
            "TRAINING - Epoch: [2][10/97]\tTime 0.180 (0.334)\tData 0.004 (0.104)\tLoss 1.4891 (1.5167)\tPrec@1 44.922 (42.436)\tPrec@5 90.625 (91.460)\t\n",
            "TRAINING - Epoch: [2][20/97]\tTime 0.168 (0.251)\tData 0.000 (0.055)\tLoss 1.5377 (1.5122)\tPrec@1 43.164 (43.331)\tPrec@5 92.188 (91.546)\t\n",
            "TRAINING - Epoch: [2][30/97]\tTime 0.175 (0.222)\tData 0.000 (0.037)\tLoss 1.4374 (1.5026)\tPrec@1 49.414 (43.845)\tPrec@5 92.773 (91.734)\t\n",
            "TRAINING - Epoch: [2][40/97]\tTime 0.161 (0.207)\tData 0.000 (0.029)\tLoss 1.4675 (1.4924)\tPrec@1 46.094 (44.336)\tPrec@5 91.211 (91.825)\t\n",
            "TRAINING - Epoch: [2][50/97]\tTime 0.186 (0.198)\tData 0.000 (0.023)\tLoss 1.4264 (1.4826)\tPrec@1 48.438 (44.684)\tPrec@5 92.188 (91.981)\t\n",
            "TRAINING - Epoch: [2][60/97]\tTime 0.159 (0.192)\tData 0.007 (0.020)\tLoss 1.4103 (1.4725)\tPrec@1 47.852 (45.060)\tPrec@5 93.945 (92.143)\t\n",
            "TRAINING - Epoch: [2][70/97]\tTime 0.162 (0.188)\tData 0.000 (0.017)\tLoss 1.4074 (1.4570)\tPrec@1 46.094 (45.698)\tPrec@5 92.578 (92.344)\t\n",
            "TRAINING - Epoch: [2][80/97]\tTime 0.155 (0.184)\tData 0.000 (0.015)\tLoss 1.4573 (1.4467)\tPrec@1 46.875 (46.094)\tPrec@5 92.773 (92.527)\t\n",
            "TRAINING - Epoch: [2][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.014)\tLoss 1.3143 (1.4358)\tPrec@1 52.148 (46.596)\tPrec@5 93.945 (92.700)\t\n",
            "EVALUATING - Epoch: [2][0/20]\tTime 0.989 (0.989)\tData 0.945 (0.945)\tLoss 1.5360 (1.5360)\tPrec@1 43.750 (43.750)\tPrec@5 94.336 (94.336)\t\n",
            "EVALUATING - Epoch: [2][10/20]\tTime 0.051 (0.196)\tData 0.000 (0.144)\tLoss 1.7384 (1.5593)\tPrec@1 43.555 (46.982)\tPrec@5 90.234 (92.791)\t\n",
            "\n",
            "Results - Epoch: 3\n",
            "Training Loss 1.4283 \tTraining Prec@1 46.952 \tTraining Prec@5 92.808 \tValidation Loss 1.5452 \tValidation Prec@1 46.540 \tValidation Prec@5 92.890 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 4\n",
            "\n",
            "TRAINING - Epoch: [3][0/97]\tTime 1.618 (1.618)\tData 1.317 (1.317)\tLoss 1.3083 (1.3083)\tPrec@1 52.930 (52.930)\tPrec@5 92.188 (92.188)\t\n",
            "TRAINING - Epoch: [3][10/97]\tTime 0.156 (0.334)\tData 0.000 (0.122)\tLoss 1.4001 (1.3278)\tPrec@1 47.656 (50.373)\tPrec@5 92.188 (94.460)\t\n",
            "TRAINING - Epoch: [3][20/97]\tTime 0.147 (0.252)\tData 0.000 (0.064)\tLoss 1.3078 (1.3136)\tPrec@1 55.273 (51.618)\tPrec@5 94.336 (94.522)\t\n",
            "TRAINING - Epoch: [3][30/97]\tTime 0.155 (0.222)\tData 0.005 (0.044)\tLoss 1.3143 (1.3124)\tPrec@1 52.539 (51.670)\tPrec@5 92.969 (94.361)\t\n",
            "TRAINING - Epoch: [3][40/97]\tTime 0.171 (0.207)\tData 0.000 (0.033)\tLoss 1.2481 (1.3039)\tPrec@1 55.273 (51.944)\tPrec@5 95.508 (94.393)\t\n",
            "TRAINING - Epoch: [3][50/97]\tTime 0.164 (0.198)\tData 0.000 (0.027)\tLoss 1.2716 (1.3016)\tPrec@1 53.711 (52.106)\tPrec@5 93.750 (94.328)\t\n",
            "TRAINING - Epoch: [3][60/97]\tTime 0.174 (0.192)\tData 0.000 (0.023)\tLoss 1.2269 (1.2989)\tPrec@1 53.125 (52.251)\tPrec@5 95.703 (94.349)\t\n",
            "TRAINING - Epoch: [3][70/97]\tTime 0.148 (0.187)\tData 0.000 (0.020)\tLoss 1.2283 (1.2907)\tPrec@1 56.641 (52.616)\tPrec@5 94.141 (94.460)\t\n",
            "TRAINING - Epoch: [3][80/97]\tTime 0.153 (0.184)\tData 0.001 (0.018)\tLoss 1.1743 (1.2824)\tPrec@1 54.102 (52.889)\tPrec@5 96.289 (94.507)\t\n",
            "TRAINING - Epoch: [3][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.016)\tLoss 1.1634 (1.2745)\tPrec@1 60.156 (53.207)\tPrec@5 94.727 (94.602)\t\n",
            "EVALUATING - Epoch: [3][0/20]\tTime 1.251 (1.251)\tData 1.196 (1.196)\tLoss 1.2980 (1.2980)\tPrec@1 55.469 (55.469)\tPrec@5 96.094 (96.094)\t\n",
            "EVALUATING - Epoch: [3][10/20]\tTime 0.051 (0.200)\tData 0.000 (0.143)\tLoss 1.3498 (1.2883)\tPrec@1 51.562 (55.433)\tPrec@5 94.141 (95.348)\t\n",
            "\n",
            "Results - Epoch: 4\n",
            "Training Loss 1.2684 \tTraining Prec@1 53.455 \tTraining Prec@5 94.648 \tValidation Loss 1.2883 \tValidation Prec@1 55.010 \tValidation Prec@5 95.420 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 5\n",
            "\n",
            "TRAINING - Epoch: [4][0/97]\tTime 1.097 (1.097)\tData 0.834 (0.834)\tLoss 1.1543 (1.1543)\tPrec@1 56.445 (56.445)\tPrec@5 96.680 (96.680)\t\n",
            "TRAINING - Epoch: [4][10/97]\tTime 0.196 (0.330)\tData 0.000 (0.096)\tLoss 1.1648 (1.1551)\tPrec@1 58.008 (58.416)\tPrec@5 96.289 (95.774)\t\n",
            "TRAINING - Epoch: [4][20/97]\tTime 0.170 (0.249)\tData 0.000 (0.051)\tLoss 1.1032 (1.1645)\tPrec@1 61.719 (58.119)\tPrec@5 96.875 (95.685)\t\n",
            "TRAINING - Epoch: [4][30/97]\tTime 0.147 (0.221)\tData 0.000 (0.034)\tLoss 1.0998 (1.1533)\tPrec@1 61.523 (58.531)\tPrec@5 96.289 (95.785)\t\n",
            "TRAINING - Epoch: [4][40/97]\tTime 0.161 (0.205)\tData 0.000 (0.026)\tLoss 1.1098 (1.1455)\tPrec@1 60.547 (58.851)\tPrec@5 96.094 (95.875)\t\n",
            "TRAINING - Epoch: [4][50/97]\tTime 0.152 (0.196)\tData 0.000 (0.021)\tLoss 1.1601 (1.1418)\tPrec@1 55.859 (58.950)\tPrec@5 96.289 (95.837)\t\n",
            "TRAINING - Epoch: [4][60/97]\tTime 0.163 (0.191)\tData 0.005 (0.018)\tLoss 1.1030 (1.1357)\tPrec@1 58.594 (59.138)\tPrec@5 95.898 (95.950)\t\n",
            "TRAINING - Epoch: [4][70/97]\tTime 0.152 (0.187)\tData 0.005 (0.016)\tLoss 0.9912 (1.1283)\tPrec@1 63.086 (59.433)\tPrec@5 97.070 (95.995)\t\n",
            "TRAINING - Epoch: [4][80/97]\tTime 0.145 (0.183)\tData 0.000 (0.014)\tLoss 1.0663 (1.1206)\tPrec@1 62.695 (59.698)\tPrec@5 96.484 (96.050)\t\n",
            "TRAINING - Epoch: [4][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.013)\tLoss 1.0019 (1.1150)\tPrec@1 65.039 (59.944)\tPrec@5 95.508 (96.051)\t\n",
            "EVALUATING - Epoch: [4][0/20]\tTime 1.251 (1.251)\tData 1.193 (1.193)\tLoss 1.5090 (1.5090)\tPrec@1 49.609 (49.609)\tPrec@5 92.578 (92.578)\t\n",
            "EVALUATING - Epoch: [4][10/20]\tTime 0.044 (0.204)\tData 0.000 (0.151)\tLoss 1.6838 (1.5325)\tPrec@1 49.609 (52.557)\tPrec@5 92.969 (92.738)\t\n",
            "\n",
            "Results - Epoch: 5\n",
            "Training Loss 1.1115 \tTraining Prec@1 60.027 \tTraining Prec@5 96.035 \tValidation Loss 1.5081 \tValidation Prec@1 52.400 \tValidation Prec@5 92.920 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 6\n",
            "\n",
            "TRAINING - Epoch: [5][0/97]\tTime 0.835 (0.835)\tData 0.578 (0.578)\tLoss 1.0855 (1.0855)\tPrec@1 62.305 (62.305)\tPrec@5 95.312 (95.312)\t\n",
            "TRAINING - Epoch: [5][10/97]\tTime 0.196 (0.329)\tData 0.003 (0.097)\tLoss 1.0500 (1.0637)\tPrec@1 64.062 (61.896)\tPrec@5 94.922 (96.662)\t\n",
            "TRAINING - Epoch: [5][20/97]\tTime 0.162 (0.250)\tData 0.005 (0.052)\tLoss 1.0470 (1.0544)\tPrec@1 62.305 (62.174)\tPrec@5 96.484 (96.652)\t\n",
            "TRAINING - Epoch: [5][30/97]\tTime 0.153 (0.221)\tData 0.000 (0.035)\tLoss 1.0823 (1.0520)\tPrec@1 62.305 (62.279)\tPrec@5 96.680 (96.705)\t\n",
            "TRAINING - Epoch: [5][40/97]\tTime 0.154 (0.206)\tData 0.000 (0.027)\tLoss 0.9990 (1.0454)\tPrec@1 62.891 (62.400)\tPrec@5 97.266 (96.789)\t\n",
            "TRAINING - Epoch: [5][50/97]\tTime 0.173 (0.197)\tData 0.000 (0.022)\tLoss 1.0229 (1.0394)\tPrec@1 62.500 (62.542)\tPrec@5 97.070 (96.791)\t\n",
            "TRAINING - Epoch: [5][60/97]\tTime 0.156 (0.191)\tData 0.000 (0.018)\tLoss 0.9604 (1.0290)\tPrec@1 64.258 (62.820)\tPrec@5 96.875 (96.843)\t\n",
            "TRAINING - Epoch: [5][70/97]\tTime 0.162 (0.187)\tData 0.000 (0.016)\tLoss 0.8739 (1.0193)\tPrec@1 66.797 (63.254)\tPrec@5 97.852 (96.911)\t\n",
            "TRAINING - Epoch: [5][80/97]\tTime 0.154 (0.184)\tData 0.000 (0.014)\tLoss 1.0185 (1.0174)\tPrec@1 61.914 (63.320)\tPrec@5 97.266 (96.882)\t\n",
            "TRAINING - Epoch: [5][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.013)\tLoss 0.9708 (1.0155)\tPrec@1 66.797 (63.447)\tPrec@5 96.875 (96.884)\t\n",
            "EVALUATING - Epoch: [5][0/20]\tTime 1.029 (1.029)\tData 0.977 (0.977)\tLoss 1.1466 (1.1466)\tPrec@1 60.742 (60.742)\tPrec@5 95.508 (95.508)\t\n",
            "EVALUATING - Epoch: [5][10/20]\tTime 0.045 (0.192)\tData 0.000 (0.136)\tLoss 1.2510 (1.1842)\tPrec@1 55.664 (58.629)\tPrec@5 95.312 (96.023)\t\n",
            "\n",
            "Results - Epoch: 6\n",
            "Training Loss 1.0152 \tTraining Prec@1 63.531 \tTraining Prec@5 96.875 \tValidation Loss 1.1851 \tValidation Prec@1 58.320 \tValidation Prec@5 96.000 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 7\n",
            "\n",
            "TRAINING - Epoch: [6][0/97]\tTime 1.301 (1.301)\tData 1.030 (1.030)\tLoss 0.9252 (0.9252)\tPrec@1 68.164 (68.164)\tPrec@5 97.266 (97.266)\t\n",
            "TRAINING - Epoch: [6][10/97]\tTime 0.210 (0.335)\tData 0.012 (0.097)\tLoss 0.9724 (0.9638)\tPrec@1 64.648 (65.909)\tPrec@5 97.266 (96.928)\t\n",
            "TRAINING - Epoch: [6][20/97]\tTime 0.150 (0.253)\tData 0.000 (0.051)\tLoss 0.9216 (0.9621)\tPrec@1 67.773 (65.904)\tPrec@5 98.242 (97.024)\t\n",
            "TRAINING - Epoch: [6][30/97]\tTime 0.149 (0.221)\tData 0.001 (0.035)\tLoss 1.0226 (0.9606)\tPrec@1 64.453 (65.770)\tPrec@5 96.680 (96.925)\t\n",
            "TRAINING - Epoch: [6][40/97]\tTime 0.157 (0.207)\tData 0.000 (0.027)\tLoss 0.9550 (0.9562)\tPrec@1 65.234 (65.844)\tPrec@5 96.875 (97.004)\t\n",
            "TRAINING - Epoch: [6][50/97]\tTime 0.156 (0.198)\tData 0.000 (0.022)\tLoss 0.9495 (0.9519)\tPrec@1 66.211 (65.939)\tPrec@5 96.875 (97.032)\t\n",
            "TRAINING - Epoch: [6][60/97]\tTime 0.157 (0.192)\tData 0.000 (0.018)\tLoss 0.8893 (0.9508)\tPrec@1 68.555 (65.968)\tPrec@5 96.875 (97.090)\t\n",
            "TRAINING - Epoch: [6][70/97]\tTime 0.161 (0.187)\tData 0.000 (0.016)\tLoss 0.9984 (0.9489)\tPrec@1 64.258 (66.010)\tPrec@5 97.070 (97.120)\t\n",
            "TRAINING - Epoch: [6][80/97]\tTime 0.168 (0.184)\tData 0.003 (0.014)\tLoss 0.9349 (0.9471)\tPrec@1 64.062 (66.023)\tPrec@5 97.266 (97.145)\t\n",
            "TRAINING - Epoch: [6][90/97]\tTime 0.149 (0.180)\tData 0.000 (0.013)\tLoss 0.9366 (0.9445)\tPrec@1 68.555 (66.054)\tPrec@5 97.070 (97.184)\t\n",
            "EVALUATING - Epoch: [6][0/20]\tTime 1.023 (1.023)\tData 0.966 (0.966)\tLoss 1.0044 (1.0044)\tPrec@1 63.867 (63.867)\tPrec@5 97.461 (97.461)\t\n",
            "EVALUATING - Epoch: [6][10/20]\tTime 0.052 (0.191)\tData 0.000 (0.138)\tLoss 1.0503 (1.0261)\tPrec@1 62.695 (64.702)\tPrec@5 97.070 (97.159)\t\n",
            "\n",
            "Results - Epoch: 7\n",
            "Training Loss 0.9424 \tTraining Prec@1 66.159 \tTraining Prec@5 97.219 \tValidation Loss 1.0193 \tValidation Prec@1 64.590 \tValidation Prec@5 97.090 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 8\n",
            "\n",
            "TRAINING - Epoch: [7][0/97]\tTime 1.358 (1.358)\tData 1.072 (1.072)\tLoss 0.9595 (0.9595)\tPrec@1 64.844 (64.844)\tPrec@5 97.266 (97.266)\t\n",
            "TRAINING - Epoch: [7][10/97]\tTime 0.203 (0.338)\tData 0.010 (0.102)\tLoss 0.8368 (0.8881)\tPrec@1 70.703 (68.164)\tPrec@5 98.047 (97.638)\t\n",
            "TRAINING - Epoch: [7][20/97]\tTime 0.152 (0.252)\tData 0.005 (0.054)\tLoss 0.7772 (0.8916)\tPrec@1 70.898 (68.034)\tPrec@5 98.438 (97.684)\t\n",
            "TRAINING - Epoch: [7][30/97]\tTime 0.167 (0.222)\tData 0.000 (0.037)\tLoss 0.8358 (0.8899)\tPrec@1 70.117 (68.145)\tPrec@5 98.047 (97.612)\t\n",
            "TRAINING - Epoch: [7][40/97]\tTime 0.156 (0.208)\tData 0.000 (0.028)\tLoss 0.8501 (0.8856)\tPrec@1 68.359 (68.345)\tPrec@5 98.438 (97.642)\t\n",
            "TRAINING - Epoch: [7][50/97]\tTime 0.158 (0.198)\tData 0.000 (0.023)\tLoss 0.8423 (0.8804)\tPrec@1 70.312 (68.413)\tPrec@5 97.070 (97.664)\t\n",
            "TRAINING - Epoch: [7][60/97]\tTime 0.148 (0.192)\tData 0.000 (0.019)\tLoss 0.8959 (0.8756)\tPrec@1 68.359 (68.564)\tPrec@5 97.070 (97.704)\t\n",
            "TRAINING - Epoch: [7][70/97]\tTime 0.150 (0.187)\tData 0.000 (0.017)\tLoss 0.9092 (0.8755)\tPrec@1 65.625 (68.491)\tPrec@5 97.266 (97.706)\t\n",
            "TRAINING - Epoch: [7][80/97]\tTime 0.150 (0.184)\tData 0.000 (0.015)\tLoss 0.8593 (0.8708)\tPrec@1 67.773 (68.680)\tPrec@5 97.852 (97.741)\t\n",
            "TRAINING - Epoch: [7][90/97]\tTime 0.149 (0.180)\tData 0.000 (0.013)\tLoss 0.8497 (0.8684)\tPrec@1 67.578 (68.814)\tPrec@5 97.852 (97.742)\t\n",
            "EVALUATING - Epoch: [7][0/20]\tTime 1.028 (1.028)\tData 0.975 (0.975)\tLoss 1.2370 (1.2370)\tPrec@1 61.523 (61.523)\tPrec@5 96.289 (96.289)\t\n",
            "EVALUATING - Epoch: [7][10/20]\tTime 0.063 (0.189)\tData 0.000 (0.134)\tLoss 1.2470 (1.2720)\tPrec@1 59.961 (59.712)\tPrec@5 96.289 (95.188)\t\n",
            "\n",
            "Results - Epoch: 8\n",
            "Training Loss 0.8663 \tTraining Prec@1 68.861 \tTraining Prec@5 97.761 \tValidation Loss 1.2764 \tValidation Prec@1 59.790 \tValidation Prec@5 95.090 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 9\n",
            "\n",
            "TRAINING - Epoch: [8][0/97]\tTime 1.452 (1.452)\tData 1.172 (1.172)\tLoss 0.9020 (0.9020)\tPrec@1 69.727 (69.727)\tPrec@5 97.656 (97.656)\t\n",
            "TRAINING - Epoch: [8][10/97]\tTime 0.163 (0.337)\tData 0.000 (0.110)\tLoss 0.8453 (0.8469)\tPrec@1 70.312 (69.549)\tPrec@5 97.852 (97.727)\t\n",
            "TRAINING - Epoch: [8][20/97]\tTime 0.166 (0.254)\tData 0.000 (0.058)\tLoss 0.7194 (0.8314)\tPrec@1 73.047 (70.136)\tPrec@5 98.633 (97.805)\t\n",
            "TRAINING - Epoch: [8][30/97]\tTime 0.150 (0.224)\tData 0.000 (0.039)\tLoss 0.8919 (0.8274)\tPrec@1 68.555 (70.237)\tPrec@5 97.852 (97.921)\t\n",
            "TRAINING - Epoch: [8][40/97]\tTime 0.191 (0.208)\tData 0.000 (0.030)\tLoss 0.8080 (0.8210)\tPrec@1 68.945 (70.251)\tPrec@5 98.633 (97.990)\t\n",
            "TRAINING - Epoch: [8][50/97]\tTime 0.166 (0.199)\tData 0.000 (0.024)\tLoss 0.8117 (0.8179)\tPrec@1 72.852 (70.508)\tPrec@5 97.461 (98.024)\t\n",
            "TRAINING - Epoch: [8][60/97]\tTime 0.161 (0.194)\tData 0.000 (0.020)\tLoss 0.9292 (0.8169)\tPrec@1 68.164 (70.694)\tPrec@5 96.484 (97.960)\t\n",
            "TRAINING - Epoch: [8][70/97]\tTime 0.155 (0.189)\tData 0.000 (0.018)\tLoss 0.8907 (0.8206)\tPrec@1 69.141 (70.555)\tPrec@5 97.461 (97.931)\t\n",
            "TRAINING - Epoch: [8][80/97]\tTime 0.154 (0.185)\tData 0.000 (0.016)\tLoss 0.8297 (0.8186)\tPrec@1 70.312 (70.616)\tPrec@5 98.047 (97.967)\t\n",
            "TRAINING - Epoch: [8][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.014)\tLoss 0.6810 (0.8161)\tPrec@1 74.609 (70.737)\tPrec@5 99.219 (97.995)\t\n",
            "EVALUATING - Epoch: [8][0/20]\tTime 1.001 (1.001)\tData 0.950 (0.950)\tLoss 0.9103 (0.9103)\tPrec@1 68.164 (68.164)\tPrec@5 98.242 (98.242)\t\n",
            "EVALUATING - Epoch: [8][10/20]\tTime 0.060 (0.194)\tData 0.000 (0.138)\tLoss 0.9905 (0.9874)\tPrec@1 69.336 (67.010)\tPrec@5 98.047 (97.798)\t\n",
            "\n",
            "Results - Epoch: 9\n",
            "Training Loss 0.8129 \tTraining Prec@1 70.852 \tTraining Prec@5 98.001 \tValidation Loss 0.9813 \tValidation Prec@1 66.870 \tValidation Prec@5 97.920 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 10\n",
            "\n",
            "TRAINING - Epoch: [9][0/97]\tTime 1.376 (1.376)\tData 1.103 (1.103)\tLoss 0.7292 (0.7292)\tPrec@1 74.023 (74.023)\tPrec@5 98.242 (98.242)\t\n",
            "TRAINING - Epoch: [9][10/97]\tTime 0.203 (0.337)\tData 0.000 (0.103)\tLoss 0.7811 (0.7801)\tPrec@1 73.047 (72.230)\tPrec@5 97.852 (98.331)\t\n",
            "TRAINING - Epoch: [9][20/97]\tTime 0.157 (0.255)\tData 0.000 (0.055)\tLoss 0.8006 (0.7804)\tPrec@1 70.508 (72.405)\tPrec@5 98.242 (98.298)\t\n",
            "TRAINING - Epoch: [9][30/97]\tTime 0.181 (0.226)\tData 0.000 (0.037)\tLoss 0.8448 (0.7791)\tPrec@1 68.945 (72.360)\tPrec@5 98.047 (98.230)\t\n",
            "TRAINING - Epoch: [9][40/97]\tTime 0.148 (0.210)\tData 0.000 (0.029)\tLoss 0.8310 (0.7758)\tPrec@1 70.898 (72.447)\tPrec@5 98.047 (98.247)\t\n",
            "TRAINING - Epoch: [9][50/97]\tTime 0.151 (0.200)\tData 0.000 (0.023)\tLoss 0.8339 (0.7751)\tPrec@1 70.703 (72.403)\tPrec@5 98.828 (98.235)\t\n",
            "TRAINING - Epoch: [9][60/97]\tTime 0.154 (0.193)\tData 0.000 (0.020)\tLoss 0.7483 (0.7718)\tPrec@1 73.047 (72.541)\tPrec@5 98.438 (98.236)\t\n",
            "TRAINING - Epoch: [9][70/97]\tTime 0.159 (0.189)\tData 0.000 (0.017)\tLoss 0.7302 (0.7701)\tPrec@1 74.805 (72.585)\tPrec@5 98.242 (98.253)\t\n",
            "TRAINING - Epoch: [9][80/97]\tTime 0.151 (0.185)\tData 0.000 (0.015)\tLoss 0.7995 (0.7742)\tPrec@1 72.656 (72.468)\tPrec@5 98.438 (98.225)\t\n",
            "TRAINING - Epoch: [9][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.013)\tLoss 0.7868 (0.7734)\tPrec@1 73.242 (72.540)\tPrec@5 97.852 (98.234)\t\n",
            "EVALUATING - Epoch: [9][0/20]\tTime 1.003 (1.003)\tData 0.930 (0.930)\tLoss 0.8861 (0.8861)\tPrec@1 70.117 (70.117)\tPrec@5 99.023 (99.023)\t\n",
            "EVALUATING - Epoch: [9][10/20]\tTime 0.051 (0.190)\tData 0.000 (0.138)\tLoss 0.8534 (0.8989)\tPrec@1 71.289 (69.300)\tPrec@5 97.656 (97.976)\t\n",
            "\n",
            "Results - Epoch: 10\n",
            "Training Loss 0.7700 \tTraining Prec@1 72.682 \tTraining Prec@5 98.262 \tValidation Loss 0.8970 \tValidation Prec@1 69.420 \tValidation Prec@5 98.010 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 11\n",
            "\n",
            "TRAINING - Epoch: [10][0/97]\tTime 1.289 (1.289)\tData 1.008 (1.008)\tLoss 0.7349 (0.7349)\tPrec@1 71.680 (71.680)\tPrec@5 98.242 (98.242)\t\n",
            "TRAINING - Epoch: [10][10/97]\tTime 0.175 (0.327)\tData 0.000 (0.095)\tLoss 0.7151 (0.7182)\tPrec@1 73.242 (74.148)\tPrec@5 98.828 (98.526)\t\n",
            "TRAINING - Epoch: [10][20/97]\tTime 0.151 (0.247)\tData 0.000 (0.050)\tLoss 0.7631 (0.7186)\tPrec@1 71.484 (73.856)\tPrec@5 98.828 (98.428)\t\n",
            "TRAINING - Epoch: [10][30/97]\tTime 0.157 (0.218)\tData 0.000 (0.034)\tLoss 0.6582 (0.7214)\tPrec@1 77.539 (73.771)\tPrec@5 97.852 (98.482)\t\n",
            "TRAINING - Epoch: [10][40/97]\tTime 0.164 (0.204)\tData 0.001 (0.026)\tLoss 0.7692 (0.7233)\tPrec@1 74.219 (73.823)\tPrec@5 98.047 (98.447)\t\n",
            "TRAINING - Epoch: [10][50/97]\tTime 0.157 (0.195)\tData 0.000 (0.021)\tLoss 0.7170 (0.7260)\tPrec@1 74.219 (73.790)\tPrec@5 98.242 (98.430)\t\n",
            "TRAINING - Epoch: [10][60/97]\tTime 0.155 (0.189)\tData 0.000 (0.018)\tLoss 0.7524 (0.7281)\tPrec@1 75.586 (73.851)\tPrec@5 97.852 (98.447)\t\n",
            "TRAINING - Epoch: [10][70/97]\tTime 0.150 (0.184)\tData 0.000 (0.016)\tLoss 0.7266 (0.7264)\tPrec@1 75.195 (74.026)\tPrec@5 97.852 (98.415)\t\n",
            "TRAINING - Epoch: [10][80/97]\tTime 0.168 (0.181)\tData 0.000 (0.014)\tLoss 0.7751 (0.7292)\tPrec@1 75.391 (73.978)\tPrec@5 97.656 (98.423)\t\n",
            "TRAINING - Epoch: [10][90/97]\tTime 0.149 (0.178)\tData 0.000 (0.012)\tLoss 0.7150 (0.7265)\tPrec@1 71.289 (74.062)\tPrec@5 99.414 (98.483)\t\n",
            "EVALUATING - Epoch: [10][0/20]\tTime 1.107 (1.107)\tData 1.051 (1.051)\tLoss 0.8944 (0.8944)\tPrec@1 69.141 (69.141)\tPrec@5 96.875 (96.875)\t\n",
            "EVALUATING - Epoch: [10][10/20]\tTime 0.116 (0.190)\tData 0.072 (0.132)\tLoss 0.9578 (0.9712)\tPrec@1 70.312 (69.283)\tPrec@5 97.461 (96.378)\t\n",
            "\n",
            "Results - Epoch: 11\n",
            "Training Loss 0.7277 \tTraining Prec@1 74.096 \tTraining Prec@5 98.452 \tValidation Loss 0.9770 \tValidation Prec@1 68.720 \tValidation Prec@5 96.620 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 12\n",
            "\n",
            "TRAINING - Epoch: [11][0/97]\tTime 1.409 (1.409)\tData 1.135 (1.135)\tLoss 0.6537 (0.6537)\tPrec@1 75.391 (75.391)\tPrec@5 98.828 (98.828)\t\n",
            "TRAINING - Epoch: [11][10/97]\tTime 0.160 (0.333)\tData 0.000 (0.109)\tLoss 0.7393 (0.6995)\tPrec@1 75.000 (75.036)\tPrec@5 98.047 (98.526)\t\n",
            "TRAINING - Epoch: [11][20/97]\tTime 0.152 (0.251)\tData 0.000 (0.058)\tLoss 0.7330 (0.6958)\tPrec@1 72.266 (75.009)\tPrec@5 99.414 (98.689)\t\n",
            "TRAINING - Epoch: [11][30/97]\tTime 0.174 (0.222)\tData 0.000 (0.040)\tLoss 0.6346 (0.6886)\tPrec@1 76.172 (75.315)\tPrec@5 98.438 (98.677)\t\n",
            "TRAINING - Epoch: [11][40/97]\tTime 0.170 (0.207)\tData 0.000 (0.031)\tLoss 0.7012 (0.6886)\tPrec@1 75.000 (75.476)\tPrec@5 98.633 (98.714)\t\n",
            "TRAINING - Epoch: [11][50/97]\tTime 0.173 (0.198)\tData 0.000 (0.025)\tLoss 0.6991 (0.6915)\tPrec@1 75.391 (75.452)\tPrec@5 98.438 (98.671)\t\n",
            "TRAINING - Epoch: [11][60/97]\tTime 0.156 (0.192)\tData 0.000 (0.021)\tLoss 0.5976 (0.6972)\tPrec@1 82.617 (75.227)\tPrec@5 98.633 (98.620)\t\n",
            "TRAINING - Epoch: [11][70/97]\tTime 0.161 (0.187)\tData 0.000 (0.018)\tLoss 0.6919 (0.6970)\tPrec@1 75.391 (75.162)\tPrec@5 97.852 (98.605)\t\n",
            "TRAINING - Epoch: [11][80/97]\tTime 0.159 (0.184)\tData 0.000 (0.016)\tLoss 0.7154 (0.6952)\tPrec@1 77.539 (75.229)\tPrec@5 98.242 (98.592)\t\n",
            "TRAINING - Epoch: [11][90/97]\tTime 0.149 (0.180)\tData 0.000 (0.014)\tLoss 0.5731 (0.6929)\tPrec@1 81.055 (75.376)\tPrec@5 99.414 (98.592)\t\n",
            "EVALUATING - Epoch: [11][0/20]\tTime 1.113 (1.113)\tData 1.049 (1.049)\tLoss 0.7345 (0.7345)\tPrec@1 73.633 (73.633)\tPrec@5 99.023 (99.023)\t\n",
            "EVALUATING - Epoch: [11][10/20]\tTime 0.048 (0.188)\tData 0.000 (0.134)\tLoss 0.8193 (0.8157)\tPrec@1 73.438 (72.532)\tPrec@5 98.047 (98.207)\t\n",
            "\n",
            "Results - Epoch: 12\n",
            "Training Loss 0.6927 \tTraining Prec@1 75.415 \tTraining Prec@5 98.587 \tValidation Loss 0.8176 \tValidation Prec@1 72.510 \tValidation Prec@5 98.220 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 13\n",
            "\n",
            "TRAINING - Epoch: [12][0/97]\tTime 1.370 (1.370)\tData 1.114 (1.114)\tLoss 0.7758 (0.7758)\tPrec@1 73.047 (73.047)\tPrec@5 97.656 (97.656)\t\n",
            "TRAINING - Epoch: [12][10/97]\tTime 0.154 (0.333)\tData 0.000 (0.104)\tLoss 0.6978 (0.6755)\tPrec@1 72.852 (75.763)\tPrec@5 98.828 (98.739)\t\n",
            "TRAINING - Epoch: [12][20/97]\tTime 0.153 (0.252)\tData 0.000 (0.055)\tLoss 0.6267 (0.6740)\tPrec@1 78.125 (76.144)\tPrec@5 98.438 (98.865)\t\n",
            "TRAINING - Epoch: [12][30/97]\tTime 0.163 (0.222)\tData 0.009 (0.038)\tLoss 0.7076 (0.6665)\tPrec@1 73.828 (76.481)\tPrec@5 99.414 (98.872)\t\n",
            "TRAINING - Epoch: [12][40/97]\tTime 0.162 (0.208)\tData 0.000 (0.029)\tLoss 0.6959 (0.6659)\tPrec@1 73.828 (76.577)\tPrec@5 98.828 (98.795)\t\n",
            "TRAINING - Epoch: [12][50/97]\tTime 0.173 (0.199)\tData 0.000 (0.024)\tLoss 0.6375 (0.6636)\tPrec@1 79.102 (76.727)\tPrec@5 98.828 (98.805)\t\n",
            "TRAINING - Epoch: [12][60/97]\tTime 0.168 (0.193)\tData 0.000 (0.020)\tLoss 0.6544 (0.6581)\tPrec@1 77.930 (76.873)\tPrec@5 98.828 (98.812)\t\n",
            "TRAINING - Epoch: [12][70/97]\tTime 0.148 (0.188)\tData 0.000 (0.018)\tLoss 0.5998 (0.6541)\tPrec@1 77.930 (76.997)\tPrec@5 98.438 (98.809)\t\n",
            "TRAINING - Epoch: [12][80/97]\tTime 0.159 (0.185)\tData 0.005 (0.016)\tLoss 0.6916 (0.6567)\tPrec@1 77.148 (76.893)\tPrec@5 98.242 (98.787)\t\n",
            "TRAINING - Epoch: [12][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.014)\tLoss 0.6968 (0.6596)\tPrec@1 75.391 (76.814)\tPrec@5 98.242 (98.740)\t\n",
            "EVALUATING - Epoch: [12][0/20]\tTime 1.031 (1.031)\tData 0.979 (0.979)\tLoss 0.7283 (0.7283)\tPrec@1 72.852 (72.852)\tPrec@5 98.633 (98.633)\t\n",
            "EVALUATING - Epoch: [12][10/20]\tTime 0.047 (0.192)\tData 0.000 (0.137)\tLoss 0.7600 (0.7460)\tPrec@1 73.633 (74.165)\tPrec@5 98.828 (98.136)\t\n",
            "\n",
            "Results - Epoch: 13\n",
            "Training Loss 0.6593 \tTraining Prec@1 76.834 \tTraining Prec@5 98.740 \tValidation Loss 0.7543 \tValidation Prec@1 73.910 \tValidation Prec@5 98.220 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 14\n",
            "\n",
            "TRAINING - Epoch: [13][0/97]\tTime 0.925 (0.925)\tData 0.668 (0.668)\tLoss 0.5987 (0.5987)\tPrec@1 78.711 (78.711)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [13][10/97]\tTime 0.165 (0.326)\tData 0.000 (0.096)\tLoss 0.6147 (0.6284)\tPrec@1 79.102 (78.107)\tPrec@5 99.219 (99.006)\t\n",
            "TRAINING - Epoch: [13][20/97]\tTime 0.175 (0.250)\tData 0.011 (0.051)\tLoss 0.6706 (0.6265)\tPrec@1 76.367 (77.883)\tPrec@5 98.828 (98.903)\t\n",
            "TRAINING - Epoch: [13][30/97]\tTime 0.156 (0.221)\tData 0.000 (0.035)\tLoss 0.6013 (0.6354)\tPrec@1 77.344 (77.545)\tPrec@5 98.047 (98.803)\t\n",
            "TRAINING - Epoch: [13][40/97]\tTime 0.150 (0.207)\tData 0.000 (0.027)\tLoss 0.5827 (0.6376)\tPrec@1 80.859 (77.711)\tPrec@5 99.609 (98.866)\t\n",
            "TRAINING - Epoch: [13][50/97]\tTime 0.151 (0.197)\tData 0.000 (0.022)\tLoss 0.5834 (0.6317)\tPrec@1 79.297 (77.930)\tPrec@5 99.414 (98.832)\t\n",
            "TRAINING - Epoch: [13][60/97]\tTime 0.160 (0.192)\tData 0.000 (0.018)\tLoss 0.6882 (0.6295)\tPrec@1 77.148 (78.106)\tPrec@5 98.047 (98.822)\t\n",
            "TRAINING - Epoch: [13][70/97]\tTime 0.153 (0.188)\tData 0.000 (0.016)\tLoss 0.5542 (0.6280)\tPrec@1 80.273 (78.037)\tPrec@5 99.219 (98.858)\t\n",
            "TRAINING - Epoch: [13][80/97]\tTime 0.152 (0.184)\tData 0.000 (0.014)\tLoss 0.6250 (0.6259)\tPrec@1 80.078 (78.103)\tPrec@5 98.438 (98.840)\t\n",
            "TRAINING - Epoch: [13][90/97]\tTime 0.151 (0.181)\tData 0.000 (0.013)\tLoss 0.6270 (0.6275)\tPrec@1 78.906 (78.037)\tPrec@5 99.414 (98.852)\t\n",
            "EVALUATING - Epoch: [13][0/20]\tTime 0.984 (0.984)\tData 0.926 (0.926)\tLoss 0.7417 (0.7417)\tPrec@1 74.414 (74.414)\tPrec@5 99.023 (99.023)\t\n",
            "EVALUATING - Epoch: [13][10/20]\tTime 0.043 (0.198)\tData 0.000 (0.143)\tLoss 0.8301 (0.7733)\tPrec@1 74.219 (75.710)\tPrec@5 98.047 (98.189)\t\n",
            "\n",
            "Results - Epoch: 14\n",
            "Training Loss 0.6275 \tTraining Prec@1 78.089 \tTraining Prec@5 98.858 \tValidation Loss 0.7674 \tValidation Prec@1 75.340 \tValidation Prec@5 98.420 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 15\n",
            "\n",
            "TRAINING - Epoch: [14][0/97]\tTime 1.121 (1.121)\tData 0.874 (0.874)\tLoss 0.6056 (0.6056)\tPrec@1 78.711 (78.711)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [14][10/97]\tTime 0.177 (0.334)\tData 0.000 (0.101)\tLoss 0.6199 (0.6193)\tPrec@1 78.125 (78.214)\tPrec@5 99.219 (99.023)\t\n",
            "TRAINING - Epoch: [14][20/97]\tTime 0.163 (0.252)\tData 0.000 (0.054)\tLoss 0.6455 (0.6124)\tPrec@1 78.906 (78.646)\tPrec@5 99.023 (99.014)\t\n",
            "TRAINING - Epoch: [14][30/97]\tTime 0.158 (0.223)\tData 0.000 (0.036)\tLoss 0.7027 (0.6089)\tPrec@1 74.414 (78.604)\tPrec@5 98.438 (98.929)\t\n",
            "TRAINING - Epoch: [14][40/97]\tTime 0.164 (0.208)\tData 0.000 (0.028)\tLoss 0.6439 (0.6070)\tPrec@1 77.148 (78.563)\tPrec@5 99.219 (98.952)\t\n",
            "TRAINING - Epoch: [14][50/97]\tTime 0.173 (0.198)\tData 0.000 (0.023)\tLoss 0.5371 (0.6040)\tPrec@1 79.492 (78.588)\tPrec@5 99.219 (98.985)\t\n",
            "TRAINING - Epoch: [14][60/97]\tTime 0.167 (0.192)\tData 0.000 (0.019)\tLoss 0.5558 (0.6014)\tPrec@1 81.055 (78.749)\tPrec@5 99.023 (98.950)\t\n",
            "TRAINING - Epoch: [14][70/97]\tTime 0.168 (0.187)\tData 0.000 (0.017)\tLoss 0.6243 (0.6016)\tPrec@1 78.906 (78.804)\tPrec@5 98.438 (98.963)\t\n",
            "TRAINING - Epoch: [14][80/97]\tTime 0.161 (0.184)\tData 0.000 (0.015)\tLoss 0.5349 (0.6021)\tPrec@1 81.836 (78.872)\tPrec@5 99.023 (98.937)\t\n",
            "TRAINING - Epoch: [14][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.013)\tLoss 0.5714 (0.6053)\tPrec@1 80.078 (78.735)\tPrec@5 98.828 (98.950)\t\n",
            "EVALUATING - Epoch: [14][0/20]\tTime 1.078 (1.078)\tData 1.027 (1.027)\tLoss 0.7717 (0.7717)\tPrec@1 74.609 (74.609)\tPrec@5 98.828 (98.828)\t\n",
            "EVALUATING - Epoch: [14][10/20]\tTime 0.062 (0.202)\tData 0.000 (0.146)\tLoss 0.8157 (0.8385)\tPrec@1 73.828 (72.994)\tPrec@5 98.242 (98.065)\t\n",
            "\n",
            "Results - Epoch: 15\n",
            "Training Loss 0.6062 \tTraining Prec@1 78.661 \tTraining Prec@5 98.951 \tValidation Loss 0.8457 \tValidation Prec@1 72.350 \tValidation Prec@5 98.200 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 16\n",
            "\n",
            "TRAINING - Epoch: [15][0/97]\tTime 1.103 (1.103)\tData 0.943 (0.943)\tLoss 0.6289 (0.6289)\tPrec@1 78.516 (78.516)\tPrec@5 99.023 (99.023)\t\n",
            "TRAINING - Epoch: [15][10/97]\tTime 0.157 (0.330)\tData 0.000 (0.104)\tLoss 0.6272 (0.6113)\tPrec@1 76.953 (78.587)\tPrec@5 99.219 (98.970)\t\n",
            "TRAINING - Epoch: [15][20/97]\tTime 0.172 (0.253)\tData 0.000 (0.055)\tLoss 0.5787 (0.5941)\tPrec@1 77.539 (78.943)\tPrec@5 98.828 (98.986)\t\n",
            "TRAINING - Epoch: [15][30/97]\tTime 0.170 (0.223)\tData 0.000 (0.038)\tLoss 0.6217 (0.5964)\tPrec@1 77.539 (78.931)\tPrec@5 99.023 (98.942)\t\n",
            "TRAINING - Epoch: [15][40/97]\tTime 0.150 (0.207)\tData 0.000 (0.029)\tLoss 0.6192 (0.5931)\tPrec@1 78.125 (79.140)\tPrec@5 97.852 (98.876)\t\n",
            "TRAINING - Epoch: [15][50/97]\tTime 0.172 (0.199)\tData 0.000 (0.024)\tLoss 0.5516 (0.5884)\tPrec@1 82.031 (79.362)\tPrec@5 99.219 (98.939)\t\n",
            "TRAINING - Epoch: [15][60/97]\tTime 0.168 (0.192)\tData 0.005 (0.020)\tLoss 0.5365 (0.5835)\tPrec@1 80.469 (79.454)\tPrec@5 99.219 (98.979)\t\n",
            "TRAINING - Epoch: [15][70/97]\tTime 0.171 (0.187)\tData 0.000 (0.017)\tLoss 0.5565 (0.5832)\tPrec@1 80.273 (79.478)\tPrec@5 99.414 (98.993)\t\n",
            "TRAINING - Epoch: [15][80/97]\tTime 0.171 (0.184)\tData 0.004 (0.015)\tLoss 0.5891 (0.5831)\tPrec@1 80.078 (79.519)\tPrec@5 98.828 (99.007)\t\n",
            "TRAINING - Epoch: [15][90/97]\tTime 0.149 (0.180)\tData 0.000 (0.014)\tLoss 0.5453 (0.5803)\tPrec@1 82.617 (79.636)\tPrec@5 98.438 (99.017)\t\n",
            "EVALUATING - Epoch: [15][0/20]\tTime 1.013 (1.013)\tData 0.960 (0.960)\tLoss 0.8046 (0.8046)\tPrec@1 73.047 (73.047)\tPrec@5 98.633 (98.633)\t\n",
            "EVALUATING - Epoch: [15][10/20]\tTime 0.054 (0.191)\tData 0.000 (0.138)\tLoss 0.8960 (0.8681)\tPrec@1 73.242 (73.118)\tPrec@5 97.656 (98.100)\t\n",
            "\n",
            "Results - Epoch: 16\n",
            "Training Loss 0.5794 \tTraining Prec@1 79.671 \tTraining Prec@5 99.027 \tValidation Loss 0.8586 \tValidation Prec@1 73.180 \tValidation Prec@5 98.310 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 17\n",
            "\n",
            "TRAINING - Epoch: [16][0/97]\tTime 1.221 (1.221)\tData 0.963 (0.963)\tLoss 0.6031 (0.6031)\tPrec@1 78.906 (78.906)\tPrec@5 99.414 (99.414)\t\n",
            "TRAINING - Epoch: [16][10/97]\tTime 0.154 (0.333)\tData 0.000 (0.091)\tLoss 0.5738 (0.5553)\tPrec@1 79.883 (80.362)\tPrec@5 100.000 (99.201)\t\n",
            "TRAINING - Epoch: [16][20/97]\tTime 0.158 (0.252)\tData 0.000 (0.048)\tLoss 0.4950 (0.5558)\tPrec@1 83.984 (80.506)\tPrec@5 99.219 (99.116)\t\n",
            "TRAINING - Epoch: [16][30/97]\tTime 0.161 (0.223)\tData 0.000 (0.033)\tLoss 0.5387 (0.5623)\tPrec@1 81.445 (80.393)\tPrec@5 98.633 (98.986)\t\n",
            "TRAINING - Epoch: [16][40/97]\tTime 0.173 (0.208)\tData 0.005 (0.026)\tLoss 0.5556 (0.5609)\tPrec@1 79.297 (80.426)\tPrec@5 99.219 (99.057)\t\n",
            "TRAINING - Epoch: [16][50/97]\tTime 0.151 (0.198)\tData 0.000 (0.021)\tLoss 0.5524 (0.5577)\tPrec@1 80.078 (80.522)\tPrec@5 99.414 (99.073)\t\n",
            "TRAINING - Epoch: [16][60/97]\tTime 0.150 (0.192)\tData 0.000 (0.018)\tLoss 0.6007 (0.5587)\tPrec@1 79.688 (80.459)\tPrec@5 99.219 (99.068)\t\n",
            "TRAINING - Epoch: [16][70/97]\tTime 0.172 (0.189)\tData 0.000 (0.015)\tLoss 0.5795 (0.5552)\tPrec@1 80.273 (80.628)\tPrec@5 99.023 (99.067)\t\n",
            "TRAINING - Epoch: [16][80/97]\tTime 0.156 (0.185)\tData 0.000 (0.014)\tLoss 0.5556 (0.5562)\tPrec@1 81.250 (80.534)\tPrec@5 98.047 (99.062)\t\n",
            "TRAINING - Epoch: [16][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.012)\tLoss 0.5909 (0.5568)\tPrec@1 77.344 (80.499)\tPrec@5 99.023 (99.066)\t\n",
            "EVALUATING - Epoch: [16][0/20]\tTime 1.015 (1.015)\tData 0.954 (0.954)\tLoss 0.8124 (0.8124)\tPrec@1 72.852 (72.852)\tPrec@5 96.289 (96.289)\t\n",
            "EVALUATING - Epoch: [16][10/20]\tTime 0.061 (0.192)\tData 0.000 (0.135)\tLoss 0.8328 (0.8037)\tPrec@1 75.586 (74.716)\tPrec@5 97.461 (97.656)\t\n",
            "\n",
            "Results - Epoch: 17\n",
            "Training Loss 0.5568 \tTraining Prec@1 80.515 \tTraining Prec@5 99.076 \tValidation Loss 0.8090 \tValidation Prec@1 74.340 \tValidation Prec@5 97.790 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 18\n",
            "\n",
            "TRAINING - Epoch: [17][0/97]\tTime 1.002 (1.002)\tData 0.725 (0.725)\tLoss 0.5302 (0.5302)\tPrec@1 81.641 (81.641)\tPrec@5 98.828 (98.828)\t\n",
            "TRAINING - Epoch: [17][10/97]\tTime 0.178 (0.335)\tData 0.000 (0.098)\tLoss 0.5623 (0.5329)\tPrec@1 80.273 (81.197)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [17][20/97]\tTime 0.176 (0.255)\tData 0.005 (0.053)\tLoss 0.5829 (0.5356)\tPrec@1 82.227 (81.185)\tPrec@5 98.828 (99.163)\t\n",
            "TRAINING - Epoch: [17][30/97]\tTime 0.148 (0.224)\tData 0.000 (0.037)\tLoss 0.5647 (0.5423)\tPrec@1 81.055 (81.074)\tPrec@5 99.219 (99.149)\t\n",
            "TRAINING - Epoch: [17][40/97]\tTime 0.174 (0.210)\tData 0.000 (0.028)\tLoss 0.5723 (0.5452)\tPrec@1 81.641 (81.036)\tPrec@5 99.609 (99.128)\t\n",
            "TRAINING - Epoch: [17][50/97]\tTime 0.168 (0.200)\tData 0.000 (0.023)\tLoss 0.5352 (0.5476)\tPrec@1 81.641 (80.940)\tPrec@5 98.828 (99.085)\t\n",
            "TRAINING - Epoch: [17][60/97]\tTime 0.147 (0.194)\tData 0.000 (0.019)\tLoss 0.5110 (0.5511)\tPrec@1 82.812 (80.866)\tPrec@5 99.609 (99.091)\t\n",
            "TRAINING - Epoch: [17][70/97]\tTime 0.178 (0.189)\tData 0.000 (0.017)\tLoss 0.5347 (0.5504)\tPrec@1 81.641 (80.898)\tPrec@5 99.805 (99.103)\t\n",
            "TRAINING - Epoch: [17][80/97]\tTime 0.156 (0.186)\tData 0.000 (0.015)\tLoss 0.4938 (0.5489)\tPrec@1 82.422 (80.876)\tPrec@5 99.414 (99.108)\t\n",
            "TRAINING - Epoch: [17][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.013)\tLoss 0.5351 (0.5500)\tPrec@1 79.688 (80.789)\tPrec@5 99.609 (99.105)\t\n",
            "EVALUATING - Epoch: [17][0/20]\tTime 1.130 (1.130)\tData 1.076 (1.076)\tLoss 0.6355 (0.6355)\tPrec@1 76.562 (76.562)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [17][10/20]\tTime 0.053 (0.194)\tData 0.000 (0.141)\tLoss 0.6818 (0.6951)\tPrec@1 78.711 (76.918)\tPrec@5 98.438 (98.668)\t\n",
            "\n",
            "Results - Epoch: 18\n",
            "Training Loss 0.5511 \tTraining Prec@1 80.765 \tTraining Prec@5 99.120 \tValidation Loss 0.7013 \tValidation Prec@1 76.530 \tValidation Prec@5 98.710 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 19\n",
            "\n",
            "TRAINING - Epoch: [18][0/97]\tTime 1.436 (1.436)\tData 1.169 (1.169)\tLoss 0.5829 (0.5829)\tPrec@1 79.297 (79.297)\tPrec@5 99.023 (99.023)\t\n",
            "TRAINING - Epoch: [18][10/97]\tTime 0.168 (0.332)\tData 0.000 (0.110)\tLoss 0.4312 (0.5163)\tPrec@1 86.914 (81.676)\tPrec@5 99.414 (99.290)\t\n",
            "TRAINING - Epoch: [18][20/97]\tTime 0.177 (0.252)\tData 0.000 (0.059)\tLoss 0.4959 (0.5189)\tPrec@1 83.789 (81.780)\tPrec@5 99.414 (99.191)\t\n",
            "TRAINING - Epoch: [18][30/97]\tTime 0.149 (0.223)\tData 0.000 (0.040)\tLoss 0.5250 (0.5106)\tPrec@1 79.492 (81.937)\tPrec@5 99.414 (99.168)\t\n",
            "TRAINING - Epoch: [18][40/97]\tTime 0.175 (0.207)\tData 0.000 (0.031)\tLoss 0.5434 (0.5120)\tPrec@1 82.422 (81.960)\tPrec@5 99.023 (99.157)\t\n",
            "TRAINING - Epoch: [18][50/97]\tTime 0.176 (0.198)\tData 0.005 (0.025)\tLoss 0.5370 (0.5141)\tPrec@1 80.469 (81.916)\tPrec@5 98.633 (99.154)\t\n",
            "TRAINING - Epoch: [18][60/97]\tTime 0.161 (0.192)\tData 0.000 (0.021)\tLoss 0.6024 (0.5169)\tPrec@1 79.297 (81.839)\tPrec@5 99.023 (99.148)\t\n",
            "TRAINING - Epoch: [18][70/97]\tTime 0.166 (0.188)\tData 0.000 (0.019)\tLoss 0.4198 (0.5164)\tPrec@1 85.352 (81.778)\tPrec@5 99.805 (99.180)\t\n",
            "TRAINING - Epoch: [18][80/97]\tTime 0.168 (0.184)\tData 0.000 (0.016)\tLoss 0.5464 (0.5198)\tPrec@1 80.664 (81.662)\tPrec@5 99.805 (99.192)\t\n",
            "TRAINING - Epoch: [18][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.015)\tLoss 0.5338 (0.5203)\tPrec@1 82.422 (81.696)\tPrec@5 98.438 (99.189)\t\n",
            "EVALUATING - Epoch: [18][0/20]\tTime 1.015 (1.015)\tData 0.960 (0.960)\tLoss 0.5785 (0.5785)\tPrec@1 81.250 (81.250)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [18][10/20]\tTime 0.066 (0.191)\tData 0.000 (0.133)\tLoss 0.5853 (0.6469)\tPrec@1 80.469 (78.942)\tPrec@5 98.633 (98.668)\t\n",
            "\n",
            "Results - Epoch: 19\n",
            "Training Loss 0.5203 \tTraining Prec@1 81.729 \tTraining Prec@5 99.185 \tValidation Loss 0.6505 \tValidation Prec@1 78.430 \tValidation Prec@5 98.840 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 20\n",
            "\n",
            "TRAINING - Epoch: [19][0/97]\tTime 1.072 (1.072)\tData 0.799 (0.799)\tLoss 0.4498 (0.4498)\tPrec@1 83.398 (83.398)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [19][10/97]\tTime 0.153 (0.337)\tData 0.008 (0.098)\tLoss 0.4913 (0.4874)\tPrec@1 83.008 (83.274)\tPrec@5 99.023 (99.343)\t\n",
            "TRAINING - Epoch: [19][20/97]\tTime 0.157 (0.254)\tData 0.000 (0.052)\tLoss 0.5327 (0.4934)\tPrec@1 82.227 (83.073)\tPrec@5 99.023 (99.302)\t\n",
            "TRAINING - Epoch: [19][30/97]\tTime 0.152 (0.224)\tData 0.000 (0.036)\tLoss 0.5125 (0.4986)\tPrec@1 83.203 (82.850)\tPrec@5 99.023 (99.263)\t\n",
            "TRAINING - Epoch: [19][40/97]\tTime 0.148 (0.209)\tData 0.000 (0.027)\tLoss 0.4207 (0.5034)\tPrec@1 84.570 (82.512)\tPrec@5 99.414 (99.281)\t\n",
            "TRAINING - Epoch: [19][50/97]\tTime 0.169 (0.200)\tData 0.000 (0.022)\tLoss 0.5199 (0.5082)\tPrec@1 81.836 (82.426)\tPrec@5 99.219 (99.234)\t\n",
            "TRAINING - Epoch: [19][60/97]\tTime 0.188 (0.194)\tData 0.000 (0.019)\tLoss 0.5278 (0.5086)\tPrec@1 80.273 (82.284)\tPrec@5 99.609 (99.264)\t\n",
            "TRAINING - Epoch: [19][70/97]\tTime 0.183 (0.193)\tData 0.005 (0.017)\tLoss 0.5081 (0.5063)\tPrec@1 82.031 (82.326)\tPrec@5 99.805 (99.263)\t\n",
            "TRAINING - Epoch: [19][80/97]\tTime 0.157 (0.190)\tData 0.000 (0.015)\tLoss 0.4453 (0.5096)\tPrec@1 85.156 (82.222)\tPrec@5 100.000 (99.248)\t\n",
            "TRAINING - Epoch: [19][90/97]\tTime 0.150 (0.185)\tData 0.000 (0.013)\tLoss 0.5619 (0.5071)\tPrec@1 80.859 (82.293)\tPrec@5 99.023 (99.270)\t\n",
            "EVALUATING - Epoch: [19][0/20]\tTime 1.011 (1.011)\tData 0.962 (0.962)\tLoss 0.5751 (0.5751)\tPrec@1 79.102 (79.102)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [19][10/20]\tTime 0.045 (0.197)\tData 0.000 (0.145)\tLoss 0.6033 (0.5877)\tPrec@1 79.102 (79.883)\tPrec@5 98.828 (98.864)\t\n",
            "\n",
            "Results - Epoch: 20\n",
            "Training Loss 0.5064 \tTraining Prec@1 82.287 \tTraining Prec@5 99.269 \tValidation Loss 0.5980 \tValidation Prec@1 79.290 \tValidation Prec@5 98.970 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 21\n",
            "\n",
            "TRAINING - Epoch: [20][0/97]\tTime 1.435 (1.435)\tData 1.127 (1.127)\tLoss 0.4494 (0.4494)\tPrec@1 85.156 (85.156)\tPrec@5 99.414 (99.414)\t\n",
            "TRAINING - Epoch: [20][10/97]\tTime 0.175 (0.336)\tData 0.005 (0.107)\tLoss 0.5937 (0.4959)\tPrec@1 81.250 (83.097)\tPrec@5 98.438 (99.201)\t\n",
            "TRAINING - Epoch: [20][20/97]\tTime 0.154 (0.253)\tData 0.000 (0.057)\tLoss 0.4385 (0.4940)\tPrec@1 85.352 (83.175)\tPrec@5 99.414 (99.293)\t\n",
            "TRAINING - Epoch: [20][30/97]\tTime 0.158 (0.224)\tData 0.000 (0.039)\tLoss 0.4923 (0.4922)\tPrec@1 83.203 (83.172)\tPrec@5 99.023 (99.275)\t\n",
            "TRAINING - Epoch: [20][40/97]\tTime 0.170 (0.216)\tData 0.000 (0.030)\tLoss 0.4847 (0.4912)\tPrec@1 84.375 (83.117)\tPrec@5 99.414 (99.281)\t\n",
            "TRAINING - Epoch: [20][50/97]\tTime 0.157 (0.205)\tData 0.000 (0.024)\tLoss 0.4656 (0.4926)\tPrec@1 82.617 (83.046)\tPrec@5 99.414 (99.280)\t\n",
            "TRAINING - Epoch: [20][60/97]\tTime 0.163 (0.198)\tData 0.000 (0.020)\tLoss 0.4707 (0.4933)\tPrec@1 83.984 (82.928)\tPrec@5 99.219 (99.292)\t\n",
            "TRAINING - Epoch: [20][70/97]\tTime 0.148 (0.193)\tData 0.000 (0.018)\tLoss 0.5224 (0.4919)\tPrec@1 81.836 (82.972)\tPrec@5 99.219 (99.304)\t\n",
            "TRAINING - Epoch: [20][80/97]\tTime 0.170 (0.189)\tData 0.002 (0.016)\tLoss 0.5325 (0.4932)\tPrec@1 81.445 (82.931)\tPrec@5 99.609 (99.296)\t\n",
            "TRAINING - Epoch: [20][90/97]\tTime 0.149 (0.185)\tData 0.000 (0.014)\tLoss 0.4585 (0.4922)\tPrec@1 84.375 (82.931)\tPrec@5 99.219 (99.294)\t\n",
            "EVALUATING - Epoch: [20][0/20]\tTime 1.128 (1.128)\tData 1.075 (1.075)\tLoss 0.7080 (0.7080)\tPrec@1 73.633 (73.633)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [20][10/20]\tTime 0.044 (0.194)\tData 0.000 (0.144)\tLoss 0.7402 (0.7456)\tPrec@1 75.391 (76.278)\tPrec@5 99.023 (98.704)\t\n",
            "\n",
            "Results - Epoch: 21\n",
            "Training Loss 0.4923 \tTraining Prec@1 82.917 \tTraining Prec@5 99.285 \tValidation Loss 0.7660 \tValidation Prec@1 75.640 \tValidation Prec@5 98.780 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 22\n",
            "\n",
            "TRAINING - Epoch: [21][0/97]\tTime 1.374 (1.374)\tData 1.101 (1.101)\tLoss 0.4778 (0.4778)\tPrec@1 83.594 (83.594)\tPrec@5 98.633 (98.633)\t\n",
            "TRAINING - Epoch: [21][10/97]\tTime 0.263 (0.366)\tData 0.004 (0.106)\tLoss 0.5170 (0.4538)\tPrec@1 81.641 (84.126)\tPrec@5 99.414 (99.272)\t\n",
            "TRAINING - Epoch: [21][20/97]\tTime 0.186 (0.273)\tData 0.005 (0.058)\tLoss 0.4162 (0.4654)\tPrec@1 84.961 (84.022)\tPrec@5 99.805 (99.135)\t\n",
            "TRAINING - Epoch: [21][30/97]\tTime 0.161 (0.236)\tData 0.000 (0.039)\tLoss 0.5443 (0.4706)\tPrec@1 80.859 (83.965)\tPrec@5 99.219 (99.149)\t\n",
            "TRAINING - Epoch: [21][40/97]\tTime 0.150 (0.218)\tData 0.000 (0.030)\tLoss 0.4968 (0.4720)\tPrec@1 83.398 (83.884)\tPrec@5 98.047 (99.209)\t\n",
            "TRAINING - Epoch: [21][50/97]\tTime 0.173 (0.207)\tData 0.000 (0.024)\tLoss 0.4909 (0.4750)\tPrec@1 83.398 (83.716)\tPrec@5 99.414 (99.203)\t\n",
            "TRAINING - Epoch: [21][60/97]\tTime 0.159 (0.199)\tData 0.006 (0.020)\tLoss 0.4543 (0.4759)\tPrec@1 84.961 (83.568)\tPrec@5 99.414 (99.241)\t\n",
            "TRAINING - Epoch: [21][70/97]\tTime 0.177 (0.194)\tData 0.000 (0.018)\tLoss 0.4930 (0.4774)\tPrec@1 82.227 (83.519)\tPrec@5 98.828 (99.257)\t\n",
            "TRAINING - Epoch: [21][80/97]\tTime 0.187 (0.190)\tData 0.005 (0.016)\tLoss 0.4786 (0.4784)\tPrec@1 83.398 (83.471)\tPrec@5 99.414 (99.272)\t\n",
            "TRAINING - Epoch: [21][90/97]\tTime 0.150 (0.186)\tData 0.000 (0.014)\tLoss 0.4640 (0.4791)\tPrec@1 84.180 (83.506)\tPrec@5 99.023 (99.251)\t\n",
            "EVALUATING - Epoch: [21][0/20]\tTime 1.064 (1.064)\tData 1.017 (1.017)\tLoss 0.9279 (0.9279)\tPrec@1 69.727 (69.727)\tPrec@5 99.023 (99.023)\t\n",
            "EVALUATING - Epoch: [21][10/20]\tTime 0.048 (0.229)\tData 0.000 (0.175)\tLoss 0.8393 (0.8951)\tPrec@1 75.586 (72.976)\tPrec@5 98.633 (98.597)\t\n",
            "\n",
            "Results - Epoch: 22\n",
            "Training Loss 0.4795 \tTraining Prec@1 83.425 \tTraining Prec@5 99.261 \tValidation Loss 0.8921 \tValidation Prec@1 72.820 \tValidation Prec@5 98.620 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 23\n",
            "\n",
            "TRAINING - Epoch: [22][0/97]\tTime 1.413 (1.413)\tData 1.115 (1.115)\tLoss 0.4931 (0.4931)\tPrec@1 83.789 (83.789)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [22][10/97]\tTime 0.163 (0.336)\tData 0.000 (0.105)\tLoss 0.4394 (0.4537)\tPrec@1 84.375 (84.180)\tPrec@5 99.805 (99.467)\t\n",
            "TRAINING - Epoch: [22][20/97]\tTime 0.155 (0.255)\tData 0.000 (0.057)\tLoss 0.4152 (0.4544)\tPrec@1 86.328 (84.096)\tPrec@5 99.414 (99.516)\t\n",
            "TRAINING - Epoch: [22][30/97]\tTime 0.155 (0.224)\tData 0.000 (0.039)\tLoss 0.4279 (0.4651)\tPrec@1 83.789 (83.833)\tPrec@5 99.805 (99.502)\t\n",
            "TRAINING - Epoch: [22][40/97]\tTime 0.176 (0.210)\tData 0.000 (0.029)\tLoss 0.5230 (0.4661)\tPrec@1 82.422 (83.803)\tPrec@5 98.242 (99.438)\t\n",
            "TRAINING - Epoch: [22][50/97]\tTime 0.154 (0.200)\tData 0.000 (0.024)\tLoss 0.4387 (0.4633)\tPrec@1 84.766 (83.824)\tPrec@5 99.219 (99.437)\t\n",
            "TRAINING - Epoch: [22][60/97]\tTime 0.154 (0.194)\tData 0.000 (0.020)\tLoss 0.4456 (0.4646)\tPrec@1 84.766 (83.786)\tPrec@5 99.414 (99.411)\t\n",
            "TRAINING - Epoch: [22][70/97]\tTime 0.152 (0.189)\tData 0.000 (0.018)\tLoss 0.4387 (0.4633)\tPrec@1 84.570 (83.850)\tPrec@5 99.805 (99.395)\t\n",
            "TRAINING - Epoch: [22][80/97]\tTime 0.160 (0.186)\tData 0.001 (0.016)\tLoss 0.4490 (0.4615)\tPrec@1 84.570 (83.893)\tPrec@5 99.219 (99.397)\t\n",
            "TRAINING - Epoch: [22][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.014)\tLoss 0.4742 (0.4606)\tPrec@1 83.984 (83.937)\tPrec@5 99.414 (99.382)\t\n",
            "EVALUATING - Epoch: [22][0/20]\tTime 1.071 (1.071)\tData 1.016 (1.016)\tLoss 0.6533 (0.6533)\tPrec@1 77.734 (77.734)\tPrec@5 99.023 (99.023)\t\n",
            "EVALUATING - Epoch: [22][10/20]\tTime 0.058 (0.197)\tData 0.000 (0.139)\tLoss 0.6574 (0.6810)\tPrec@1 79.883 (78.089)\tPrec@5 98.633 (98.828)\t\n",
            "\n",
            "Results - Epoch: 23\n",
            "Training Loss 0.4599 \tTraining Prec@1 83.976 \tTraining Prec@5 99.376 \tValidation Loss 0.6772 \tValidation Prec@1 78.160 \tValidation Prec@5 98.840 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 24\n",
            "\n",
            "TRAINING - Epoch: [23][0/97]\tTime 1.560 (1.560)\tData 1.303 (1.303)\tLoss 0.4261 (0.4261)\tPrec@1 83.789 (83.789)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [23][10/97]\tTime 0.150 (0.333)\tData 0.000 (0.123)\tLoss 0.4817 (0.4444)\tPrec@1 82.812 (84.482)\tPrec@5 99.219 (99.485)\t\n",
            "TRAINING - Epoch: [23][20/97]\tTime 0.181 (0.256)\tData 0.000 (0.065)\tLoss 0.4688 (0.4472)\tPrec@1 83.398 (84.301)\tPrec@5 99.609 (99.442)\t\n",
            "TRAINING - Epoch: [23][30/97]\tTime 0.161 (0.225)\tData 0.000 (0.044)\tLoss 0.4939 (0.4501)\tPrec@1 83.594 (84.268)\tPrec@5 99.219 (99.383)\t\n",
            "TRAINING - Epoch: [23][40/97]\tTime 0.162 (0.210)\tData 0.004 (0.034)\tLoss 0.4448 (0.4475)\tPrec@1 84.375 (84.361)\tPrec@5 99.219 (99.371)\t\n",
            "TRAINING - Epoch: [23][50/97]\tTime 0.164 (0.200)\tData 0.001 (0.027)\tLoss 0.5215 (0.4479)\tPrec@1 80.273 (84.375)\tPrec@5 99.219 (99.391)\t\n",
            "TRAINING - Epoch: [23][60/97]\tTime 0.169 (0.194)\tData 0.000 (0.023)\tLoss 0.4194 (0.4475)\tPrec@1 87.695 (84.410)\tPrec@5 99.414 (99.395)\t\n",
            "TRAINING - Epoch: [23][70/97]\tTime 0.147 (0.189)\tData 0.000 (0.020)\tLoss 0.4687 (0.4509)\tPrec@1 82.812 (84.336)\tPrec@5 99.023 (99.359)\t\n",
            "TRAINING - Epoch: [23][80/97]\tTime 0.153 (0.185)\tData 0.000 (0.018)\tLoss 0.4529 (0.4488)\tPrec@1 85.352 (84.447)\tPrec@5 99.219 (99.383)\t\n",
            "TRAINING - Epoch: [23][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.016)\tLoss 0.4574 (0.4501)\tPrec@1 84.766 (84.422)\tPrec@5 98.828 (99.365)\t\n",
            "EVALUATING - Epoch: [23][0/20]\tTime 1.004 (1.004)\tData 0.958 (0.958)\tLoss 0.5353 (0.5353)\tPrec@1 82.422 (82.422)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [23][10/20]\tTime 0.053 (0.200)\tData 0.000 (0.147)\tLoss 0.5529 (0.5893)\tPrec@1 82.617 (80.078)\tPrec@5 98.828 (98.881)\t\n",
            "\n",
            "Results - Epoch: 24\n",
            "Training Loss 0.4511 \tTraining Prec@1 84.375 \tTraining Prec@5 99.374 \tValidation Loss 0.5917 \tValidation Prec@1 80.000 \tValidation Prec@5 99.050 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 25\n",
            "\n",
            "TRAINING - Epoch: [24][0/97]\tTime 1.214 (1.214)\tData 0.943 (0.943)\tLoss 0.3863 (0.3863)\tPrec@1 88.281 (88.281)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [24][10/97]\tTime 0.161 (0.335)\tData 0.000 (0.092)\tLoss 0.4669 (0.4324)\tPrec@1 83.203 (85.014)\tPrec@5 98.633 (99.414)\t\n",
            "TRAINING - Epoch: [24][20/97]\tTime 0.177 (0.256)\tData 0.005 (0.049)\tLoss 0.4911 (0.4353)\tPrec@1 81.445 (84.859)\tPrec@5 99.219 (99.442)\t\n",
            "TRAINING - Epoch: [24][30/97]\tTime 0.174 (0.225)\tData 0.000 (0.033)\tLoss 0.4599 (0.4384)\tPrec@1 83.789 (84.892)\tPrec@5 99.414 (99.420)\t\n",
            "TRAINING - Epoch: [24][40/97]\tTime 0.190 (0.209)\tData 0.000 (0.026)\tLoss 0.4639 (0.4378)\tPrec@1 83.984 (84.880)\tPrec@5 99.219 (99.443)\t\n",
            "TRAINING - Epoch: [24][50/97]\tTime 0.156 (0.200)\tData 0.000 (0.021)\tLoss 0.4488 (0.4355)\tPrec@1 83.398 (85.007)\tPrec@5 99.805 (99.429)\t\n",
            "TRAINING - Epoch: [24][60/97]\tTime 0.156 (0.193)\tData 0.000 (0.017)\tLoss 0.5100 (0.4381)\tPrec@1 83.008 (84.942)\tPrec@5 99.414 (99.417)\t\n",
            "TRAINING - Epoch: [24][70/97]\tTime 0.174 (0.189)\tData 0.005 (0.015)\tLoss 0.4288 (0.4404)\tPrec@1 85.938 (84.870)\tPrec@5 99.805 (99.403)\t\n",
            "TRAINING - Epoch: [24][80/97]\tTime 0.159 (0.185)\tData 0.000 (0.013)\tLoss 0.4600 (0.4408)\tPrec@1 83.789 (84.886)\tPrec@5 99.609 (99.409)\t\n",
            "TRAINING - Epoch: [24][90/97]\tTime 0.151 (0.181)\tData 0.000 (0.012)\tLoss 0.4023 (0.4401)\tPrec@1 86.523 (84.849)\tPrec@5 99.609 (99.416)\t\n",
            "EVALUATING - Epoch: [24][0/20]\tTime 1.052 (1.052)\tData 1.002 (1.002)\tLoss 0.5570 (0.5570)\tPrec@1 82.031 (82.031)\tPrec@5 98.828 (98.828)\t\n",
            "EVALUATING - Epoch: [24][10/20]\tTime 0.059 (0.193)\tData 0.000 (0.138)\tLoss 0.5607 (0.6007)\tPrec@1 81.445 (80.771)\tPrec@5 99.023 (98.580)\t\n",
            "\n",
            "Results - Epoch: 25\n",
            "Training Loss 0.4405 \tTraining Prec@1 84.838 \tTraining Prec@5 99.420 \tValidation Loss 0.6008 \tValidation Prec@1 80.750 \tValidation Prec@5 98.620 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 26\n",
            "\n",
            "TRAINING - Epoch: [25][0/97]\tTime 1.472 (1.472)\tData 1.196 (1.196)\tLoss 0.3694 (0.3694)\tPrec@1 87.305 (87.305)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [25][10/97]\tTime 0.180 (0.329)\tData 0.000 (0.111)\tLoss 0.3459 (0.4044)\tPrec@1 88.086 (85.653)\tPrec@5 100.000 (99.538)\t\n",
            "TRAINING - Epoch: [25][20/97]\tTime 0.149 (0.248)\tData 0.000 (0.059)\tLoss 0.4003 (0.4128)\tPrec@1 85.742 (85.398)\tPrec@5 99.023 (99.535)\t\n",
            "TRAINING - Epoch: [25][30/97]\tTime 0.158 (0.219)\tData 0.000 (0.041)\tLoss 0.3231 (0.4097)\tPrec@1 88.672 (85.761)\tPrec@5 100.000 (99.521)\t\n",
            "TRAINING - Epoch: [25][40/97]\tTime 0.165 (0.204)\tData 0.000 (0.031)\tLoss 0.4115 (0.4118)\tPrec@1 85.156 (85.737)\tPrec@5 99.805 (99.543)\t\n",
            "TRAINING - Epoch: [25][50/97]\tTime 0.160 (0.195)\tData 0.000 (0.025)\tLoss 0.4154 (0.4150)\tPrec@1 85.156 (85.585)\tPrec@5 99.805 (99.525)\t\n",
            "TRAINING - Epoch: [25][60/97]\tTime 0.153 (0.189)\tData 0.000 (0.021)\tLoss 0.4272 (0.4169)\tPrec@1 84.375 (85.537)\tPrec@5 99.219 (99.497)\t\n",
            "TRAINING - Epoch: [25][70/97]\tTime 0.165 (0.185)\tData 0.012 (0.018)\tLoss 0.4262 (0.4175)\tPrec@1 85.156 (85.550)\tPrec@5 99.414 (99.491)\t\n",
            "TRAINING - Epoch: [25][80/97]\tTime 0.148 (0.182)\tData 0.001 (0.016)\tLoss 0.4537 (0.4194)\tPrec@1 84.180 (85.528)\tPrec@5 99.023 (99.474)\t\n",
            "TRAINING - Epoch: [25][90/97]\tTime 0.149 (0.179)\tData 0.000 (0.015)\tLoss 0.4861 (0.4232)\tPrec@1 82.422 (85.349)\tPrec@5 99.219 (99.476)\t\n",
            "EVALUATING - Epoch: [25][0/20]\tTime 1.007 (1.007)\tData 0.956 (0.956)\tLoss 0.5916 (0.5916)\tPrec@1 80.859 (80.859)\tPrec@5 98.828 (98.828)\t\n",
            "EVALUATING - Epoch: [25][10/20]\tTime 0.080 (0.191)\tData 0.000 (0.133)\tLoss 0.6068 (0.6438)\tPrec@1 80.664 (78.942)\tPrec@5 98.242 (98.757)\t\n",
            "\n",
            "Results - Epoch: 26\n",
            "Training Loss 0.4261 \tTraining Prec@1 85.311 \tTraining Prec@5 99.462 \tValidation Loss 0.6399 \tValidation Prec@1 78.820 \tValidation Prec@5 98.930 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 27\n",
            "\n",
            "TRAINING - Epoch: [26][0/97]\tTime 1.606 (1.606)\tData 1.350 (1.350)\tLoss 0.3967 (0.3967)\tPrec@1 85.742 (85.742)\tPrec@5 98.828 (98.828)\t\n",
            "TRAINING - Epoch: [26][10/97]\tTime 0.146 (0.336)\tData 0.000 (0.126)\tLoss 0.3750 (0.4038)\tPrec@1 87.500 (85.866)\tPrec@5 99.414 (99.272)\t\n",
            "TRAINING - Epoch: [26][20/97]\tTime 0.158 (0.253)\tData 0.000 (0.066)\tLoss 0.4126 (0.4169)\tPrec@1 85.742 (85.724)\tPrec@5 99.219 (99.405)\t\n",
            "TRAINING - Epoch: [26][30/97]\tTime 0.157 (0.225)\tData 0.000 (0.045)\tLoss 0.4247 (0.4117)\tPrec@1 85.742 (85.843)\tPrec@5 99.219 (99.420)\t\n",
            "TRAINING - Epoch: [26][40/97]\tTime 0.145 (0.210)\tData 0.000 (0.035)\tLoss 0.4660 (0.4200)\tPrec@1 83.984 (85.595)\tPrec@5 99.023 (99.433)\t\n",
            "TRAINING - Epoch: [26][50/97]\tTime 0.165 (0.201)\tData 0.000 (0.028)\tLoss 0.4749 (0.4238)\tPrec@1 83.984 (85.451)\tPrec@5 99.023 (99.441)\t\n",
            "TRAINING - Epoch: [26][60/97]\tTime 0.158 (0.195)\tData 0.000 (0.024)\tLoss 0.3831 (0.4221)\tPrec@1 86.914 (85.508)\tPrec@5 100.000 (99.446)\t\n",
            "TRAINING - Epoch: [26][70/97]\tTime 0.155 (0.191)\tData 0.000 (0.021)\tLoss 0.3626 (0.4198)\tPrec@1 87.891 (85.572)\tPrec@5 99.414 (99.455)\t\n",
            "TRAINING - Epoch: [26][80/97]\tTime 0.150 (0.187)\tData 0.005 (0.018)\tLoss 0.3498 (0.4207)\tPrec@1 88.281 (85.523)\tPrec@5 99.414 (99.438)\t\n",
            "TRAINING - Epoch: [26][90/97]\tTime 0.150 (0.183)\tData 0.000 (0.016)\tLoss 0.4278 (0.4194)\tPrec@1 84.375 (85.532)\tPrec@5 100.000 (99.466)\t\n",
            "EVALUATING - Epoch: [26][0/20]\tTime 1.145 (1.145)\tData 1.092 (1.092)\tLoss 0.5603 (0.5603)\tPrec@1 80.078 (80.078)\tPrec@5 99.023 (99.023)\t\n",
            "EVALUATING - Epoch: [26][10/20]\tTime 0.061 (0.189)\tData 0.017 (0.136)\tLoss 0.5859 (0.6122)\tPrec@1 81.055 (80.966)\tPrec@5 98.828 (98.935)\t\n",
            "\n",
            "Results - Epoch: 27\n",
            "Training Loss 0.4186 \tTraining Prec@1 85.521 \tTraining Prec@5 99.466 \tValidation Loss 0.6091 \tValidation Prec@1 80.630 \tValidation Prec@5 99.050 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 28\n",
            "\n",
            "TRAINING - Epoch: [27][0/97]\tTime 1.323 (1.323)\tData 1.040 (1.040)\tLoss 0.4259 (0.4259)\tPrec@1 85.156 (85.156)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [27][10/97]\tTime 0.171 (0.336)\tData 0.000 (0.097)\tLoss 0.4090 (0.3964)\tPrec@1 86.328 (86.204)\tPrec@5 100.000 (99.485)\t\n",
            "TRAINING - Epoch: [27][20/97]\tTime 0.147 (0.254)\tData 0.000 (0.052)\tLoss 0.5369 (0.4028)\tPrec@1 81.445 (85.965)\tPrec@5 99.609 (99.507)\t\n",
            "TRAINING - Epoch: [27][30/97]\tTime 0.148 (0.223)\tData 0.000 (0.036)\tLoss 0.4281 (0.4083)\tPrec@1 85.742 (85.685)\tPrec@5 99.414 (99.502)\t\n",
            "TRAINING - Epoch: [27][40/97]\tTime 0.150 (0.207)\tData 0.000 (0.027)\tLoss 0.3467 (0.4096)\tPrec@1 87.305 (85.685)\tPrec@5 99.805 (99.509)\t\n",
            "TRAINING - Epoch: [27][50/97]\tTime 0.179 (0.199)\tData 0.000 (0.022)\tLoss 0.4479 (0.4089)\tPrec@1 84.570 (85.681)\tPrec@5 99.219 (99.506)\t\n",
            "TRAINING - Epoch: [27][60/97]\tTime 0.172 (0.193)\tData 0.000 (0.018)\tLoss 0.3920 (0.4109)\tPrec@1 87.109 (85.611)\tPrec@5 99.414 (99.494)\t\n",
            "TRAINING - Epoch: [27][70/97]\tTime 0.148 (0.188)\tData 0.000 (0.016)\tLoss 0.4105 (0.4107)\tPrec@1 85.938 (85.605)\tPrec@5 99.219 (99.494)\t\n",
            "TRAINING - Epoch: [27][80/97]\tTime 0.149 (0.185)\tData 0.000 (0.014)\tLoss 0.3881 (0.4114)\tPrec@1 87.891 (85.610)\tPrec@5 99.219 (99.501)\t\n",
            "TRAINING - Epoch: [27][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.013)\tLoss 0.3437 (0.4097)\tPrec@1 88.477 (85.667)\tPrec@5 100.000 (99.500)\t\n",
            "EVALUATING - Epoch: [27][0/20]\tTime 1.002 (1.002)\tData 0.950 (0.950)\tLoss 0.5007 (0.5007)\tPrec@1 82.617 (82.617)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [27][10/20]\tTime 0.055 (0.194)\tData 0.000 (0.137)\tLoss 0.5331 (0.5536)\tPrec@1 81.836 (82.085)\tPrec@5 98.828 (99.006)\t\n",
            "\n",
            "Results - Epoch: 28\n",
            "Training Loss 0.4094 \tTraining Prec@1 85.692 \tTraining Prec@5 99.507 \tValidation Loss 0.5581 \tValidation Prec@1 82.160 \tValidation Prec@5 98.980 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 29\n",
            "\n",
            "TRAINING - Epoch: [28][0/97]\tTime 1.485 (1.485)\tData 1.215 (1.215)\tLoss 0.3506 (0.3506)\tPrec@1 88.281 (88.281)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [28][10/97]\tTime 0.157 (0.335)\tData 0.000 (0.113)\tLoss 0.3569 (0.3833)\tPrec@1 86.719 (86.435)\tPrec@5 100.000 (99.592)\t\n",
            "TRAINING - Epoch: [28][20/97]\tTime 0.169 (0.254)\tData 0.000 (0.060)\tLoss 0.3878 (0.3917)\tPrec@1 87.109 (86.412)\tPrec@5 99.609 (99.581)\t\n",
            "TRAINING - Epoch: [28][30/97]\tTime 0.175 (0.225)\tData 0.000 (0.041)\tLoss 0.3858 (0.3933)\tPrec@1 87.695 (86.297)\tPrec@5 99.023 (99.572)\t\n",
            "TRAINING - Epoch: [28][40/97]\tTime 0.148 (0.210)\tData 0.000 (0.031)\tLoss 0.3922 (0.3971)\tPrec@1 85.156 (86.176)\tPrec@5 99.414 (99.581)\t\n",
            "TRAINING - Epoch: [28][50/97]\tTime 0.162 (0.201)\tData 0.005 (0.026)\tLoss 0.4191 (0.4006)\tPrec@1 83.398 (86.037)\tPrec@5 99.609 (99.560)\t\n",
            "TRAINING - Epoch: [28][60/97]\tTime 0.165 (0.194)\tData 0.000 (0.022)\tLoss 0.3565 (0.3969)\tPrec@1 88.672 (86.216)\tPrec@5 99.609 (99.561)\t\n",
            "TRAINING - Epoch: [28][70/97]\tTime 0.150 (0.189)\tData 0.000 (0.019)\tLoss 0.3761 (0.3949)\tPrec@1 87.695 (86.224)\tPrec@5 99.805 (99.571)\t\n",
            "TRAINING - Epoch: [28][80/97]\tTime 0.159 (0.187)\tData 0.000 (0.017)\tLoss 0.4379 (0.3968)\tPrec@1 85.938 (86.164)\tPrec@5 99.219 (99.564)\t\n",
            "TRAINING - Epoch: [28][90/97]\tTime 0.151 (0.183)\tData 0.000 (0.015)\tLoss 0.3787 (0.3971)\tPrec@1 85.938 (86.176)\tPrec@5 99.609 (99.556)\t\n",
            "EVALUATING - Epoch: [28][0/20]\tTime 1.223 (1.223)\tData 1.171 (1.171)\tLoss 0.6773 (0.6773)\tPrec@1 78.906 (78.906)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [28][10/20]\tTime 0.049 (0.197)\tData 0.000 (0.144)\tLoss 0.6653 (0.6843)\tPrec@1 78.320 (79.261)\tPrec@5 98.828 (98.899)\t\n",
            "\n",
            "Results - Epoch: 29\n",
            "Training Loss 0.3960 \tTraining Prec@1 86.238 \tTraining Prec@5 99.553 \tValidation Loss 0.6928 \tValidation Prec@1 78.370 \tValidation Prec@5 98.900 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 30\n",
            "\n",
            "TRAINING - Epoch: [29][0/97]\tTime 1.461 (1.461)\tData 1.155 (1.155)\tLoss 0.3621 (0.3621)\tPrec@1 87.695 (87.695)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [29][10/97]\tTime 0.152 (0.337)\tData 0.000 (0.106)\tLoss 0.4040 (0.3780)\tPrec@1 85.352 (86.737)\tPrec@5 99.609 (99.663)\t\n",
            "TRAINING - Epoch: [29][20/97]\tTime 0.158 (0.253)\tData 0.000 (0.057)\tLoss 0.4405 (0.3843)\tPrec@1 83.789 (86.579)\tPrec@5 99.609 (99.581)\t\n",
            "TRAINING - Epoch: [29][30/97]\tTime 0.169 (0.223)\tData 0.000 (0.039)\tLoss 0.3502 (0.3858)\tPrec@1 88.281 (86.618)\tPrec@5 99.414 (99.622)\t\n",
            "TRAINING - Epoch: [29][40/97]\tTime 0.164 (0.208)\tData 0.000 (0.030)\tLoss 0.4403 (0.3952)\tPrec@1 85.352 (86.381)\tPrec@5 98.828 (99.562)\t\n",
            "TRAINING - Epoch: [29][50/97]\tTime 0.171 (0.199)\tData 0.000 (0.024)\tLoss 0.3703 (0.3938)\tPrec@1 86.719 (86.405)\tPrec@5 99.609 (99.533)\t\n",
            "TRAINING - Epoch: [29][60/97]\tTime 0.165 (0.193)\tData 0.000 (0.020)\tLoss 0.3492 (0.3942)\tPrec@1 88.086 (86.405)\tPrec@5 99.805 (99.539)\t\n",
            "TRAINING - Epoch: [29][70/97]\tTime 0.155 (0.188)\tData 0.000 (0.018)\tLoss 0.3830 (0.3910)\tPrec@1 86.523 (86.397)\tPrec@5 98.438 (99.524)\t\n",
            "TRAINING - Epoch: [29][80/97]\tTime 0.171 (0.185)\tData 0.001 (0.015)\tLoss 0.4033 (0.3912)\tPrec@1 86.328 (86.432)\tPrec@5 98.828 (99.520)\t\n",
            "TRAINING - Epoch: [29][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.014)\tLoss 0.3837 (0.3915)\tPrec@1 86.914 (86.384)\tPrec@5 99.414 (99.508)\t\n",
            "EVALUATING - Epoch: [29][0/20]\tTime 1.030 (1.030)\tData 0.983 (0.983)\tLoss 0.4667 (0.4667)\tPrec@1 84.180 (84.180)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [29][10/20]\tTime 0.046 (0.201)\tData 0.000 (0.144)\tLoss 0.4499 (0.4910)\tPrec@1 86.328 (84.038)\tPrec@5 99.609 (99.272)\t\n",
            "\n",
            "Results - Epoch: 30\n",
            "Training Loss 0.3916 \tTraining Prec@1 86.364 \tTraining Prec@5 99.519 \tValidation Loss 0.4904 \tValidation Prec@1 83.910 \tValidation Prec@5 99.380 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 31\n",
            "\n",
            "TRAINING - Epoch: [30][0/97]\tTime 1.339 (1.339)\tData 1.039 (1.039)\tLoss 0.3194 (0.3194)\tPrec@1 89.648 (89.648)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [30][10/97]\tTime 0.165 (0.329)\tData 0.000 (0.100)\tLoss 0.3619 (0.3684)\tPrec@1 87.109 (87.216)\tPrec@5 99.609 (99.574)\t\n",
            "TRAINING - Epoch: [30][20/97]\tTime 0.157 (0.252)\tData 0.000 (0.053)\tLoss 0.3698 (0.3652)\tPrec@1 87.891 (87.435)\tPrec@5 99.805 (99.600)\t\n",
            "TRAINING - Epoch: [30][30/97]\tTime 0.147 (0.222)\tData 0.000 (0.037)\tLoss 0.3518 (0.3670)\tPrec@1 87.500 (87.279)\tPrec@5 99.805 (99.565)\t\n",
            "TRAINING - Epoch: [30][40/97]\tTime 0.169 (0.207)\tData 0.000 (0.028)\tLoss 0.3295 (0.3702)\tPrec@1 88.086 (87.062)\tPrec@5 99.609 (99.562)\t\n",
            "TRAINING - Epoch: [30][50/97]\tTime 0.162 (0.198)\tData 0.007 (0.023)\tLoss 0.3888 (0.3719)\tPrec@1 86.914 (87.002)\tPrec@5 99.805 (99.556)\t\n",
            "TRAINING - Epoch: [30][60/97]\tTime 0.159 (0.192)\tData 0.000 (0.019)\tLoss 0.3763 (0.3712)\tPrec@1 86.523 (87.058)\tPrec@5 99.219 (99.561)\t\n",
            "TRAINING - Epoch: [30][70/97]\tTime 0.147 (0.188)\tData 0.000 (0.017)\tLoss 0.3811 (0.3742)\tPrec@1 88.086 (86.964)\tPrec@5 99.609 (99.563)\t\n",
            "TRAINING - Epoch: [30][80/97]\tTime 0.154 (0.184)\tData 0.000 (0.015)\tLoss 0.3541 (0.3751)\tPrec@1 88.672 (86.926)\tPrec@5 99.805 (99.544)\t\n",
            "TRAINING - Epoch: [30][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.013)\tLoss 0.3246 (0.3772)\tPrec@1 88.867 (86.854)\tPrec@5 99.805 (99.541)\t\n",
            "EVALUATING - Epoch: [30][0/20]\tTime 1.265 (1.265)\tData 1.204 (1.204)\tLoss 0.6887 (0.6887)\tPrec@1 77.539 (77.539)\tPrec@5 98.633 (98.633)\t\n",
            "EVALUATING - Epoch: [30][10/20]\tTime 0.043 (0.199)\tData 0.000 (0.141)\tLoss 0.7820 (0.7433)\tPrec@1 77.344 (76.687)\tPrec@5 98.047 (98.544)\t\n",
            "\n",
            "Results - Epoch: 31\n",
            "Training Loss 0.3796 \tTraining Prec@1 86.789 \tTraining Prec@5 99.545 \tValidation Loss 0.7327 \tValidation Prec@1 76.560 \tValidation Prec@5 98.740 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 32\n",
            "\n",
            "TRAINING - Epoch: [31][0/97]\tTime 1.457 (1.457)\tData 1.216 (1.216)\tLoss 0.3315 (0.3315)\tPrec@1 87.305 (87.305)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [31][10/97]\tTime 0.149 (0.332)\tData 0.000 (0.115)\tLoss 0.2992 (0.3600)\tPrec@1 89.453 (87.340)\tPrec@5 99.414 (99.556)\t\n",
            "TRAINING - Epoch: [31][20/97]\tTime 0.174 (0.252)\tData 0.005 (0.061)\tLoss 0.3858 (0.3666)\tPrec@1 86.914 (87.156)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [31][30/97]\tTime 0.156 (0.223)\tData 0.000 (0.042)\tLoss 0.4031 (0.3717)\tPrec@1 85.547 (87.009)\tPrec@5 99.609 (99.590)\t\n",
            "TRAINING - Epoch: [31][40/97]\tTime 0.174 (0.208)\tData 0.000 (0.032)\tLoss 0.3673 (0.3719)\tPrec@1 87.695 (87.009)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [31][50/97]\tTime 0.156 (0.198)\tData 0.000 (0.026)\tLoss 0.3633 (0.3735)\tPrec@1 86.914 (86.972)\tPrec@5 99.609 (99.613)\t\n",
            "TRAINING - Epoch: [31][60/97]\tTime 0.158 (0.192)\tData 0.000 (0.022)\tLoss 0.3469 (0.3746)\tPrec@1 87.305 (87.026)\tPrec@5 99.023 (99.587)\t\n",
            "TRAINING - Epoch: [31][70/97]\tTime 0.153 (0.188)\tData 0.000 (0.019)\tLoss 0.3159 (0.3736)\tPrec@1 89.844 (87.065)\tPrec@5 99.414 (99.582)\t\n",
            "TRAINING - Epoch: [31][80/97]\tTime 0.168 (0.185)\tData 0.000 (0.017)\tLoss 0.3921 (0.3758)\tPrec@1 85.352 (86.986)\tPrec@5 99.609 (99.564)\t\n",
            "TRAINING - Epoch: [31][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.015)\tLoss 0.3786 (0.3766)\tPrec@1 87.305 (86.912)\tPrec@5 99.609 (99.560)\t\n",
            "EVALUATING - Epoch: [31][0/20]\tTime 1.020 (1.020)\tData 0.971 (0.971)\tLoss 0.6753 (0.6753)\tPrec@1 79.102 (79.102)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [31][10/20]\tTime 0.053 (0.188)\tData 0.000 (0.134)\tLoss 0.6753 (0.6978)\tPrec@1 77.930 (78.214)\tPrec@5 99.023 (99.094)\t\n",
            "\n",
            "Results - Epoch: 32\n",
            "Training Loss 0.3763 \tTraining Prec@1 86.934 \tTraining Prec@5 99.561 \tValidation Loss 0.6871 \tValidation Prec@1 78.410 \tValidation Prec@5 99.120 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 33\n",
            "\n",
            "TRAINING - Epoch: [32][0/97]\tTime 1.265 (1.265)\tData 0.985 (0.985)\tLoss 0.3289 (0.3289)\tPrec@1 88.672 (88.672)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [32][10/97]\tTime 0.183 (0.332)\tData 0.000 (0.095)\tLoss 0.3784 (0.3443)\tPrec@1 87.109 (87.962)\tPrec@5 99.219 (99.698)\t\n",
            "TRAINING - Epoch: [32][20/97]\tTime 0.181 (0.254)\tData 0.000 (0.050)\tLoss 0.2827 (0.3546)\tPrec@1 91.211 (87.844)\tPrec@5 100.000 (99.647)\t\n",
            "TRAINING - Epoch: [32][30/97]\tTime 0.175 (0.225)\tData 0.000 (0.034)\tLoss 0.3450 (0.3531)\tPrec@1 89.062 (87.897)\tPrec@5 99.609 (99.647)\t\n",
            "TRAINING - Epoch: [32][40/97]\tTime 0.159 (0.210)\tData 0.000 (0.026)\tLoss 0.3811 (0.3541)\tPrec@1 85.156 (87.657)\tPrec@5 99.805 (99.662)\t\n",
            "TRAINING - Epoch: [32][50/97]\tTime 0.157 (0.200)\tData 0.000 (0.021)\tLoss 0.4108 (0.3595)\tPrec@1 85.352 (87.531)\tPrec@5 99.414 (99.648)\t\n",
            "TRAINING - Epoch: [32][60/97]\tTime 0.165 (0.193)\tData 0.000 (0.018)\tLoss 0.4176 (0.3651)\tPrec@1 84.375 (87.369)\tPrec@5 99.805 (99.603)\t\n",
            "TRAINING - Epoch: [32][70/97]\tTime 0.167 (0.189)\tData 0.000 (0.015)\tLoss 0.3627 (0.3657)\tPrec@1 87.500 (87.332)\tPrec@5 99.805 (99.609)\t\n",
            "TRAINING - Epoch: [32][80/97]\tTime 0.160 (0.185)\tData 0.000 (0.014)\tLoss 0.3319 (0.3659)\tPrec@1 87.305 (87.285)\tPrec@5 99.805 (99.583)\t\n",
            "TRAINING - Epoch: [32][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.012)\tLoss 0.3989 (0.3649)\tPrec@1 87.695 (87.324)\tPrec@5 99.219 (99.562)\t\n",
            "EVALUATING - Epoch: [32][0/20]\tTime 1.130 (1.130)\tData 1.084 (1.084)\tLoss 0.5199 (0.5199)\tPrec@1 82.227 (82.227)\tPrec@5 98.828 (98.828)\t\n",
            "EVALUATING - Epoch: [32][10/20]\tTime 0.049 (0.192)\tData 0.000 (0.138)\tLoss 0.5509 (0.5207)\tPrec@1 82.227 (82.422)\tPrec@5 99.023 (99.130)\t\n",
            "\n",
            "Results - Epoch: 33\n",
            "Training Loss 0.3655 \tTraining Prec@1 87.303 \tTraining Prec@5 99.559 \tValidation Loss 0.5141 \tValidation Prec@1 82.830 \tValidation Prec@5 99.260 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 34\n",
            "\n",
            "TRAINING - Epoch: [33][0/97]\tTime 1.491 (1.491)\tData 1.244 (1.244)\tLoss 0.3433 (0.3433)\tPrec@1 87.500 (87.500)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [33][10/97]\tTime 0.159 (0.334)\tData 0.001 (0.116)\tLoss 0.3701 (0.3619)\tPrec@1 88.281 (87.660)\tPrec@5 99.414 (99.592)\t\n",
            "TRAINING - Epoch: [33][20/97]\tTime 0.153 (0.251)\tData 0.000 (0.061)\tLoss 0.3502 (0.3558)\tPrec@1 88.477 (87.993)\tPrec@5 99.805 (99.684)\t\n",
            "TRAINING - Epoch: [33][30/97]\tTime 0.180 (0.223)\tData 0.005 (0.042)\tLoss 0.3546 (0.3496)\tPrec@1 88.281 (88.143)\tPrec@5 99.609 (99.723)\t\n",
            "TRAINING - Epoch: [33][40/97]\tTime 0.168 (0.206)\tData 0.005 (0.032)\tLoss 0.3360 (0.3546)\tPrec@1 89.062 (87.881)\tPrec@5 99.805 (99.662)\t\n",
            "TRAINING - Epoch: [33][50/97]\tTime 0.173 (0.198)\tData 0.010 (0.026)\tLoss 0.4116 (0.3578)\tPrec@1 84.961 (87.711)\tPrec@5 99.805 (99.648)\t\n",
            "TRAINING - Epoch: [33][60/97]\tTime 0.162 (0.192)\tData 0.000 (0.022)\tLoss 0.3711 (0.3598)\tPrec@1 85.547 (87.545)\tPrec@5 100.000 (99.645)\t\n",
            "TRAINING - Epoch: [33][70/97]\tTime 0.151 (0.188)\tData 0.000 (0.019)\tLoss 0.3753 (0.3597)\tPrec@1 87.305 (87.599)\tPrec@5 99.609 (99.645)\t\n",
            "TRAINING - Epoch: [33][80/97]\tTime 0.162 (0.185)\tData 0.000 (0.017)\tLoss 0.3774 (0.3578)\tPrec@1 88.477 (87.666)\tPrec@5 99.414 (99.650)\t\n",
            "TRAINING - Epoch: [33][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.015)\tLoss 0.4301 (0.3595)\tPrec@1 85.156 (87.564)\tPrec@5 99.805 (99.637)\t\n",
            "EVALUATING - Epoch: [33][0/20]\tTime 1.005 (1.005)\tData 0.952 (0.952)\tLoss 0.4994 (0.4994)\tPrec@1 82.031 (82.031)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [33][10/20]\tTime 0.054 (0.195)\tData 0.000 (0.141)\tLoss 0.4255 (0.5140)\tPrec@1 84.375 (82.990)\tPrec@5 99.023 (99.183)\t\n",
            "\n",
            "Results - Epoch: 34\n",
            "Training Loss 0.3591 \tTraining Prec@1 87.572 \tTraining Prec@5 99.642 \tValidation Loss 0.5143 \tValidation Prec@1 83.000 \tValidation Prec@5 99.290 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 35\n",
            "\n",
            "TRAINING - Epoch: [34][0/97]\tTime 1.276 (1.276)\tData 1.010 (1.010)\tLoss 0.3069 (0.3069)\tPrec@1 88.477 (88.477)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [34][10/97]\tTime 0.192 (0.319)\tData 0.000 (0.096)\tLoss 0.3040 (0.3346)\tPrec@1 89.844 (88.281)\tPrec@5 99.805 (99.716)\t\n",
            "TRAINING - Epoch: [34][20/97]\tTime 0.158 (0.248)\tData 0.005 (0.052)\tLoss 0.2658 (0.3301)\tPrec@1 92.383 (88.486)\tPrec@5 99.414 (99.702)\t\n",
            "TRAINING - Epoch: [34][30/97]\tTime 0.165 (0.220)\tData 0.000 (0.035)\tLoss 0.3416 (0.3379)\tPrec@1 87.891 (88.225)\tPrec@5 99.609 (99.691)\t\n",
            "TRAINING - Epoch: [34][40/97]\tTime 0.149 (0.207)\tData 0.000 (0.027)\tLoss 0.3581 (0.3471)\tPrec@1 88.867 (87.853)\tPrec@5 99.805 (99.638)\t\n",
            "TRAINING - Epoch: [34][50/97]\tTime 0.169 (0.198)\tData 0.000 (0.022)\tLoss 0.3307 (0.3503)\tPrec@1 89.258 (87.818)\tPrec@5 99.805 (99.636)\t\n",
            "TRAINING - Epoch: [34][60/97]\tTime 0.161 (0.192)\tData 0.000 (0.018)\tLoss 0.3824 (0.3529)\tPrec@1 87.500 (87.737)\tPrec@5 99.805 (99.629)\t\n",
            "TRAINING - Epoch: [34][70/97]\tTime 0.159 (0.187)\tData 0.000 (0.016)\tLoss 0.3368 (0.3492)\tPrec@1 88.867 (87.841)\tPrec@5 99.805 (99.640)\t\n",
            "TRAINING - Epoch: [34][80/97]\tTime 0.170 (0.184)\tData 0.004 (0.014)\tLoss 0.3222 (0.3478)\tPrec@1 88.086 (87.847)\tPrec@5 99.609 (99.650)\t\n",
            "TRAINING - Epoch: [34][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.013)\tLoss 0.3682 (0.3469)\tPrec@1 87.109 (87.831)\tPrec@5 99.805 (99.637)\t\n",
            "EVALUATING - Epoch: [34][0/20]\tTime 0.962 (0.962)\tData 0.913 (0.913)\tLoss 0.6524 (0.6524)\tPrec@1 80.273 (80.273)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [34][10/20]\tTime 0.069 (0.190)\tData 0.000 (0.136)\tLoss 0.7071 (0.6807)\tPrec@1 79.102 (79.190)\tPrec@5 98.828 (98.846)\t\n",
            "\n",
            "Results - Epoch: 35\n",
            "Training Loss 0.3478 \tTraining Prec@1 87.786 \tTraining Prec@5 99.638 \tValidation Loss 0.6864 \tValidation Prec@1 78.560 \tValidation Prec@5 98.900 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 36\n",
            "\n",
            "TRAINING - Epoch: [35][0/97]\tTime 1.272 (1.272)\tData 0.987 (0.987)\tLoss 0.3604 (0.3604)\tPrec@1 87.695 (87.695)\tPrec@5 99.414 (99.414)\t\n",
            "TRAINING - Epoch: [35][10/97]\tTime 0.185 (0.330)\tData 0.000 (0.091)\tLoss 0.3339 (0.3690)\tPrec@1 87.891 (87.411)\tPrec@5 100.000 (99.485)\t\n",
            "TRAINING - Epoch: [35][20/97]\tTime 0.150 (0.249)\tData 0.000 (0.049)\tLoss 0.3202 (0.3495)\tPrec@1 88.672 (87.891)\tPrec@5 99.609 (99.554)\t\n",
            "TRAINING - Epoch: [35][30/97]\tTime 0.154 (0.222)\tData 0.000 (0.033)\tLoss 0.3455 (0.3556)\tPrec@1 88.477 (87.525)\tPrec@5 99.023 (99.540)\t\n",
            "TRAINING - Epoch: [35][40/97]\tTime 0.155 (0.207)\tData 0.000 (0.026)\tLoss 0.2891 (0.3528)\tPrec@1 89.844 (87.624)\tPrec@5 99.023 (99.538)\t\n",
            "TRAINING - Epoch: [35][50/97]\tTime 0.180 (0.198)\tData 0.000 (0.021)\tLoss 0.3796 (0.3497)\tPrec@1 87.305 (87.741)\tPrec@5 99.609 (99.583)\t\n",
            "TRAINING - Epoch: [35][60/97]\tTime 0.157 (0.191)\tData 0.000 (0.017)\tLoss 0.2660 (0.3492)\tPrec@1 90.234 (87.779)\tPrec@5 99.805 (99.577)\t\n",
            "TRAINING - Epoch: [35][70/97]\tTime 0.159 (0.187)\tData 0.005 (0.015)\tLoss 0.2836 (0.3463)\tPrec@1 89.453 (87.880)\tPrec@5 100.000 (99.590)\t\n",
            "TRAINING - Epoch: [35][80/97]\tTime 0.157 (0.184)\tData 0.000 (0.014)\tLoss 0.3641 (0.3469)\tPrec@1 87.500 (87.927)\tPrec@5 99.609 (99.590)\t\n",
            "TRAINING - Epoch: [35][90/97]\tTime 0.149 (0.180)\tData 0.000 (0.012)\tLoss 0.3352 (0.3477)\tPrec@1 88.867 (87.953)\tPrec@5 99.609 (99.601)\t\n",
            "EVALUATING - Epoch: [35][0/20]\tTime 1.081 (1.081)\tData 1.029 (1.029)\tLoss 0.4928 (0.4928)\tPrec@1 82.031 (82.031)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [35][10/20]\tTime 0.048 (0.190)\tData 0.000 (0.136)\tLoss 0.4651 (0.5621)\tPrec@1 84.766 (82.156)\tPrec@5 98.828 (99.112)\t\n",
            "\n",
            "Results - Epoch: 36\n",
            "Training Loss 0.3483 \tTraining Prec@1 87.925 \tTraining Prec@5 99.603 \tValidation Loss 0.5672 \tValidation Prec@1 81.810 \tValidation Prec@5 99.090 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 37\n",
            "\n",
            "TRAINING - Epoch: [36][0/97]\tTime 1.402 (1.402)\tData 1.132 (1.132)\tLoss 0.2987 (0.2987)\tPrec@1 89.258 (89.258)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [36][10/97]\tTime 0.175 (0.336)\tData 0.000 (0.107)\tLoss 0.3244 (0.3272)\tPrec@1 88.867 (88.849)\tPrec@5 99.805 (99.751)\t\n",
            "TRAINING - Epoch: [36][20/97]\tTime 0.158 (0.253)\tData 0.000 (0.057)\tLoss 0.3379 (0.3311)\tPrec@1 88.281 (88.616)\tPrec@5 99.609 (99.693)\t\n",
            "TRAINING - Epoch: [36][30/97]\tTime 0.157 (0.223)\tData 0.000 (0.039)\tLoss 0.3289 (0.3274)\tPrec@1 88.672 (88.653)\tPrec@5 99.805 (99.704)\t\n",
            "TRAINING - Epoch: [36][40/97]\tTime 0.165 (0.209)\tData 0.000 (0.030)\tLoss 0.3742 (0.3309)\tPrec@1 86.523 (88.458)\tPrec@5 99.609 (99.709)\t\n",
            "TRAINING - Epoch: [36][50/97]\tTime 0.160 (0.200)\tData 0.005 (0.024)\tLoss 0.3771 (0.3330)\tPrec@1 87.305 (88.392)\tPrec@5 99.805 (99.717)\t\n",
            "TRAINING - Epoch: [36][60/97]\tTime 0.152 (0.194)\tData 0.000 (0.020)\tLoss 0.3048 (0.3333)\tPrec@1 89.258 (88.323)\tPrec@5 99.609 (99.709)\t\n",
            "TRAINING - Epoch: [36][70/97]\tTime 0.161 (0.190)\tData 0.000 (0.018)\tLoss 0.4087 (0.3374)\tPrec@1 86.523 (88.207)\tPrec@5 99.609 (99.684)\t\n",
            "TRAINING - Epoch: [36][80/97]\tTime 0.150 (0.186)\tData 0.000 (0.016)\tLoss 0.3151 (0.3392)\tPrec@1 88.867 (88.175)\tPrec@5 99.805 (99.670)\t\n",
            "TRAINING - Epoch: [36][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.014)\tLoss 0.3625 (0.3397)\tPrec@1 87.695 (88.172)\tPrec@5 99.609 (99.667)\t\n",
            "EVALUATING - Epoch: [36][0/20]\tTime 0.986 (0.986)\tData 0.934 (0.934)\tLoss 0.5563 (0.5563)\tPrec@1 79.688 (79.688)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [36][10/20]\tTime 0.060 (0.188)\tData 0.000 (0.127)\tLoss 0.5411 (0.5658)\tPrec@1 84.766 (82.528)\tPrec@5 99.023 (99.077)\t\n",
            "\n",
            "Results - Epoch: 37\n",
            "Training Loss 0.3406 \tTraining Prec@1 88.130 \tTraining Prec@5 99.668 \tValidation Loss 0.5668 \tValidation Prec@1 82.250 \tValidation Prec@5 99.140 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 38\n",
            "\n",
            "TRAINING - Epoch: [37][0/97]\tTime 1.326 (1.326)\tData 1.047 (1.047)\tLoss 0.3201 (0.3201)\tPrec@1 88.672 (88.672)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [37][10/97]\tTime 0.197 (0.339)\tData 0.000 (0.099)\tLoss 0.3422 (0.3285)\tPrec@1 87.500 (88.317)\tPrec@5 99.609 (99.734)\t\n",
            "TRAINING - Epoch: [37][20/97]\tTime 0.200 (0.256)\tData 0.010 (0.054)\tLoss 0.3692 (0.3412)\tPrec@1 86.328 (87.993)\tPrec@5 100.000 (99.674)\t\n",
            "TRAINING - Epoch: [37][30/97]\tTime 0.165 (0.226)\tData 0.000 (0.037)\tLoss 0.4104 (0.3486)\tPrec@1 85.156 (87.739)\tPrec@5 99.414 (99.647)\t\n",
            "TRAINING - Epoch: [37][40/97]\tTime 0.170 (0.211)\tData 0.000 (0.028)\tLoss 0.3291 (0.3458)\tPrec@1 86.133 (87.905)\tPrec@5 100.000 (99.662)\t\n",
            "TRAINING - Epoch: [37][50/97]\tTime 0.159 (0.201)\tData 0.000 (0.023)\tLoss 0.3480 (0.3424)\tPrec@1 87.695 (87.944)\tPrec@5 99.805 (99.671)\t\n",
            "TRAINING - Epoch: [37][60/97]\tTime 0.166 (0.195)\tData 0.000 (0.020)\tLoss 0.3337 (0.3442)\tPrec@1 87.695 (87.887)\tPrec@5 100.000 (99.670)\t\n",
            "TRAINING - Epoch: [37][70/97]\tTime 0.192 (0.191)\tData 0.005 (0.017)\tLoss 0.3459 (0.3432)\tPrec@1 87.500 (87.979)\tPrec@5 99.219 (99.662)\t\n",
            "TRAINING - Epoch: [37][80/97]\tTime 0.154 (0.187)\tData 0.000 (0.015)\tLoss 0.2865 (0.3391)\tPrec@1 88.867 (88.074)\tPrec@5 99.609 (99.667)\t\n",
            "TRAINING - Epoch: [37][90/97]\tTime 0.150 (0.183)\tData 0.000 (0.014)\tLoss 0.3110 (0.3391)\tPrec@1 88.867 (88.062)\tPrec@5 99.414 (99.663)\t\n",
            "EVALUATING - Epoch: [37][0/20]\tTime 1.007 (1.007)\tData 0.960 (0.960)\tLoss 0.5374 (0.5374)\tPrec@1 79.883 (79.883)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [37][10/20]\tTime 0.068 (0.192)\tData 0.000 (0.135)\tLoss 0.5747 (0.5804)\tPrec@1 82.031 (81.072)\tPrec@5 98.828 (99.023)\t\n",
            "\n",
            "Results - Epoch: 38\n",
            "Training Loss 0.3381 \tTraining Prec@1 88.108 \tTraining Prec@5 99.664 \tValidation Loss 0.5784 \tValidation Prec@1 81.070 \tValidation Prec@5 99.180 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 39\n",
            "\n",
            "TRAINING - Epoch: [38][0/97]\tTime 1.494 (1.494)\tData 1.258 (1.258)\tLoss 0.3037 (0.3037)\tPrec@1 89.453 (89.453)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [38][10/97]\tTime 0.195 (0.333)\tData 0.000 (0.116)\tLoss 0.3089 (0.3226)\tPrec@1 90.234 (88.601)\tPrec@5 99.805 (99.734)\t\n",
            "TRAINING - Epoch: [38][20/97]\tTime 0.151 (0.254)\tData 0.000 (0.061)\tLoss 0.3548 (0.3225)\tPrec@1 87.305 (88.672)\tPrec@5 99.609 (99.767)\t\n",
            "TRAINING - Epoch: [38][30/97]\tTime 0.172 (0.224)\tData 0.000 (0.042)\tLoss 0.3377 (0.3244)\tPrec@1 87.109 (88.697)\tPrec@5 99.805 (99.698)\t\n",
            "TRAINING - Epoch: [38][40/97]\tTime 0.171 (0.209)\tData 0.000 (0.032)\tLoss 0.3341 (0.3241)\tPrec@1 87.305 (88.643)\tPrec@5 100.000 (99.709)\t\n",
            "TRAINING - Epoch: [38][50/97]\tTime 0.168 (0.199)\tData 0.000 (0.026)\tLoss 0.2712 (0.3231)\tPrec@1 90.234 (88.680)\tPrec@5 99.805 (99.713)\t\n",
            "TRAINING - Epoch: [38][60/97]\tTime 0.150 (0.193)\tData 0.000 (0.022)\tLoss 0.3747 (0.3219)\tPrec@1 88.672 (88.765)\tPrec@5 99.609 (99.712)\t\n",
            "TRAINING - Epoch: [38][70/97]\tTime 0.157 (0.189)\tData 0.000 (0.019)\tLoss 0.3592 (0.3242)\tPrec@1 86.328 (88.622)\tPrec@5 99.609 (99.722)\t\n",
            "TRAINING - Epoch: [38][80/97]\tTime 0.168 (0.186)\tData 0.000 (0.017)\tLoss 0.3128 (0.3247)\tPrec@1 90.039 (88.604)\tPrec@5 99.609 (99.715)\t\n",
            "TRAINING - Epoch: [38][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.015)\tLoss 0.2854 (0.3256)\tPrec@1 91.211 (88.562)\tPrec@5 99.414 (99.719)\t\n",
            "EVALUATING - Epoch: [38][0/20]\tTime 0.981 (0.981)\tData 0.930 (0.930)\tLoss 0.4083 (0.4083)\tPrec@1 85.352 (85.352)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [38][10/20]\tTime 0.057 (0.189)\tData 0.000 (0.135)\tLoss 0.4326 (0.4786)\tPrec@1 85.352 (84.517)\tPrec@5 99.023 (99.290)\t\n",
            "\n",
            "Results - Epoch: 39\n",
            "Training Loss 0.3262 \tTraining Prec@1 88.547 \tTraining Prec@5 99.712 \tValidation Loss 0.4715 \tValidation Prec@1 84.620 \tValidation Prec@5 99.300 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 40\n",
            "\n",
            "TRAINING - Epoch: [39][0/97]\tTime 1.027 (1.027)\tData 0.768 (0.768)\tLoss 0.2805 (0.2805)\tPrec@1 89.844 (89.844)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [39][10/97]\tTime 0.188 (0.334)\tData 0.000 (0.088)\tLoss 0.2938 (0.3034)\tPrec@1 90.039 (89.631)\tPrec@5 99.609 (99.716)\t\n",
            "TRAINING - Epoch: [39][20/97]\tTime 0.167 (0.253)\tData 0.000 (0.046)\tLoss 0.2480 (0.3003)\tPrec@1 92.188 (89.509)\tPrec@5 99.805 (99.712)\t\n",
            "TRAINING - Epoch: [39][30/97]\tTime 0.156 (0.221)\tData 0.007 (0.032)\tLoss 0.3237 (0.3025)\tPrec@1 88.867 (89.352)\tPrec@5 100.000 (99.742)\t\n",
            "TRAINING - Epoch: [39][40/97]\tTime 0.183 (0.207)\tData 0.000 (0.024)\tLoss 0.2918 (0.3033)\tPrec@1 90.430 (89.353)\tPrec@5 99.609 (99.757)\t\n",
            "TRAINING - Epoch: [39][50/97]\tTime 0.152 (0.198)\tData 0.005 (0.020)\tLoss 0.3295 (0.3141)\tPrec@1 89.258 (89.020)\tPrec@5 99.219 (99.717)\t\n",
            "TRAINING - Epoch: [39][60/97]\tTime 0.162 (0.192)\tData 0.000 (0.017)\tLoss 0.3776 (0.3163)\tPrec@1 87.109 (88.922)\tPrec@5 99.805 (99.725)\t\n",
            "TRAINING - Epoch: [39][70/97]\tTime 0.178 (0.188)\tData 0.008 (0.015)\tLoss 0.3098 (0.3152)\tPrec@1 90.625 (88.983)\tPrec@5 100.000 (99.728)\t\n",
            "TRAINING - Epoch: [39][80/97]\tTime 0.160 (0.185)\tData 0.000 (0.013)\tLoss 0.2918 (0.3161)\tPrec@1 89.453 (88.935)\tPrec@5 99.219 (99.725)\t\n",
            "TRAINING - Epoch: [39][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.012)\tLoss 0.3547 (0.3177)\tPrec@1 88.867 (88.891)\tPrec@5 99.805 (99.740)\t\n",
            "EVALUATING - Epoch: [39][0/20]\tTime 1.087 (1.087)\tData 1.034 (1.034)\tLoss 0.6338 (0.6338)\tPrec@1 79.688 (79.688)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [39][10/20]\tTime 0.058 (0.194)\tData 0.000 (0.138)\tLoss 0.6461 (0.6751)\tPrec@1 77.734 (78.942)\tPrec@5 98.828 (99.023)\t\n",
            "\n",
            "Results - Epoch: 40\n",
            "Training Loss 0.3199 \tTraining Prec@1 88.831 \tTraining Prec@5 99.728 \tValidation Loss 0.6837 \tValidation Prec@1 78.830 \tValidation Prec@5 98.860 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 41\n",
            "\n",
            "TRAINING - Epoch: [40][0/97]\tTime 1.258 (1.258)\tData 0.979 (0.979)\tLoss 0.2921 (0.2921)\tPrec@1 89.453 (89.453)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [40][10/97]\tTime 0.147 (0.333)\tData 0.000 (0.091)\tLoss 0.3404 (0.2981)\tPrec@1 89.844 (89.648)\tPrec@5 99.609 (99.805)\t\n",
            "TRAINING - Epoch: [40][20/97]\tTime 0.149 (0.251)\tData 0.000 (0.048)\tLoss 0.3452 (0.3105)\tPrec@1 86.328 (89.165)\tPrec@5 100.000 (99.749)\t\n",
            "TRAINING - Epoch: [40][30/97]\tTime 0.180 (0.223)\tData 0.005 (0.033)\tLoss 0.2965 (0.3092)\tPrec@1 88.477 (89.233)\tPrec@5 99.609 (99.773)\t\n",
            "TRAINING - Epoch: [40][40/97]\tTime 0.154 (0.207)\tData 0.000 (0.025)\tLoss 0.3616 (0.3065)\tPrec@1 88.672 (89.448)\tPrec@5 99.219 (99.743)\t\n",
            "TRAINING - Epoch: [40][50/97]\tTime 0.154 (0.197)\tData 0.000 (0.021)\tLoss 0.3393 (0.3081)\tPrec@1 89.258 (89.403)\tPrec@5 100.000 (99.751)\t\n",
            "TRAINING - Epoch: [40][60/97]\tTime 0.150 (0.191)\tData 0.000 (0.018)\tLoss 0.2500 (0.3087)\tPrec@1 90.430 (89.322)\tPrec@5 100.000 (99.757)\t\n",
            "TRAINING - Epoch: [40][70/97]\tTime 0.162 (0.187)\tData 0.000 (0.015)\tLoss 0.3080 (0.3115)\tPrec@1 89.844 (89.252)\tPrec@5 99.805 (99.725)\t\n",
            "TRAINING - Epoch: [40][80/97]\tTime 0.153 (0.184)\tData 0.000 (0.014)\tLoss 0.2519 (0.3108)\tPrec@1 92.578 (89.280)\tPrec@5 99.609 (99.708)\t\n",
            "TRAINING - Epoch: [40][90/97]\tTime 0.149 (0.180)\tData 0.000 (0.012)\tLoss 0.2973 (0.3120)\tPrec@1 88.281 (89.249)\tPrec@5 99.805 (99.712)\t\n",
            "EVALUATING - Epoch: [40][0/20]\tTime 1.089 (1.089)\tData 1.028 (1.028)\tLoss 0.5318 (0.5318)\tPrec@1 83.008 (83.008)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [40][10/20]\tTime 0.045 (0.195)\tData 0.000 (0.143)\tLoss 0.5164 (0.5605)\tPrec@1 84.180 (82.901)\tPrec@5 98.438 (99.094)\t\n",
            "\n",
            "Results - Epoch: 41\n",
            "Training Loss 0.3132 \tTraining Prec@1 89.207 \tTraining Prec@5 99.710 \tValidation Loss 0.5614 \tValidation Prec@1 82.600 \tValidation Prec@5 99.210 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 42\n",
            "\n",
            "TRAINING - Epoch: [41][0/97]\tTime 1.363 (1.363)\tData 1.087 (1.087)\tLoss 0.3426 (0.3426)\tPrec@1 89.648 (89.648)\tPrec@5 99.219 (99.219)\t\n",
            "TRAINING - Epoch: [41][10/97]\tTime 0.161 (0.332)\tData 0.000 (0.101)\tLoss 0.2963 (0.3034)\tPrec@1 89.258 (89.382)\tPrec@5 99.805 (99.663)\t\n",
            "TRAINING - Epoch: [41][20/97]\tTime 0.155 (0.251)\tData 0.000 (0.053)\tLoss 0.3090 (0.3083)\tPrec@1 88.672 (89.183)\tPrec@5 99.805 (99.628)\t\n",
            "TRAINING - Epoch: [41][30/97]\tTime 0.173 (0.224)\tData 0.000 (0.036)\tLoss 0.2897 (0.3115)\tPrec@1 90.234 (89.132)\tPrec@5 100.000 (99.716)\t\n",
            "TRAINING - Epoch: [41][40/97]\tTime 0.171 (0.208)\tData 0.000 (0.028)\tLoss 0.2248 (0.3131)\tPrec@1 92.773 (89.120)\tPrec@5 100.000 (99.700)\t\n",
            "TRAINING - Epoch: [41][50/97]\tTime 0.153 (0.199)\tData 0.000 (0.023)\tLoss 0.3603 (0.3159)\tPrec@1 86.914 (89.024)\tPrec@5 99.609 (99.701)\t\n",
            "TRAINING - Epoch: [41][60/97]\tTime 0.154 (0.193)\tData 0.000 (0.019)\tLoss 0.3409 (0.3184)\tPrec@1 87.500 (88.947)\tPrec@5 99.805 (99.696)\t\n",
            "TRAINING - Epoch: [41][70/97]\tTime 0.160 (0.188)\tData 0.000 (0.017)\tLoss 0.3349 (0.3183)\tPrec@1 87.891 (88.958)\tPrec@5 99.609 (99.692)\t\n",
            "TRAINING - Epoch: [41][80/97]\tTime 0.160 (0.185)\tData 0.000 (0.015)\tLoss 0.3857 (0.3193)\tPrec@1 87.305 (88.850)\tPrec@5 100.000 (99.694)\t\n",
            "TRAINING - Epoch: [41][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.013)\tLoss 0.3003 (0.3180)\tPrec@1 90.039 (88.893)\tPrec@5 99.805 (99.695)\t\n",
            "EVALUATING - Epoch: [41][0/20]\tTime 1.011 (1.011)\tData 0.960 (0.960)\tLoss 0.5795 (0.5795)\tPrec@1 80.859 (80.859)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [41][10/20]\tTime 0.059 (0.196)\tData 0.000 (0.139)\tLoss 0.5922 (0.5510)\tPrec@1 82.227 (82.653)\tPrec@5 99.219 (99.254)\t\n",
            "\n",
            "Results - Epoch: 42\n",
            "Training Loss 0.3179 \tTraining Prec@1 88.865 \tTraining Prec@5 99.704 \tValidation Loss 0.5514 \tValidation Prec@1 82.910 \tValidation Prec@5 99.280 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 43\n",
            "\n",
            "TRAINING - Epoch: [42][0/97]\tTime 1.536 (1.536)\tData 1.238 (1.238)\tLoss 0.3152 (0.3152)\tPrec@1 88.086 (88.086)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [42][10/97]\tTime 0.157 (0.339)\tData 0.000 (0.115)\tLoss 0.2749 (0.2938)\tPrec@1 90.234 (89.382)\tPrec@5 99.219 (99.698)\t\n",
            "TRAINING - Epoch: [42][20/97]\tTime 0.154 (0.255)\tData 0.000 (0.061)\tLoss 0.2695 (0.2857)\tPrec@1 90.039 (89.723)\tPrec@5 100.000 (99.767)\t\n",
            "TRAINING - Epoch: [42][30/97]\tTime 0.155 (0.225)\tData 0.005 (0.042)\tLoss 0.2972 (0.2890)\tPrec@1 89.844 (89.617)\tPrec@5 99.805 (99.735)\t\n",
            "TRAINING - Epoch: [42][40/97]\tTime 0.150 (0.210)\tData 0.000 (0.032)\tLoss 0.3237 (0.2974)\tPrec@1 89.258 (89.420)\tPrec@5 99.609 (99.719)\t\n",
            "TRAINING - Epoch: [42][50/97]\tTime 0.148 (0.200)\tData 0.000 (0.026)\tLoss 0.3276 (0.2962)\tPrec@1 88.477 (89.396)\tPrec@5 99.609 (99.736)\t\n",
            "TRAINING - Epoch: [42][60/97]\tTime 0.185 (0.194)\tData 0.005 (0.022)\tLoss 0.3469 (0.2995)\tPrec@1 87.891 (89.293)\tPrec@5 100.000 (99.741)\t\n",
            "TRAINING - Epoch: [42][70/97]\tTime 0.159 (0.189)\tData 0.005 (0.019)\tLoss 0.3681 (0.3003)\tPrec@1 86.523 (89.338)\tPrec@5 99.805 (99.736)\t\n",
            "TRAINING - Epoch: [42][80/97]\tTime 0.157 (0.186)\tData 0.000 (0.017)\tLoss 0.3054 (0.3040)\tPrec@1 90.430 (89.243)\tPrec@5 100.000 (99.735)\t\n",
            "TRAINING - Epoch: [42][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.015)\tLoss 0.3496 (0.3059)\tPrec@1 87.500 (89.204)\tPrec@5 99.805 (99.727)\t\n",
            "EVALUATING - Epoch: [42][0/20]\tTime 1.093 (1.093)\tData 1.039 (1.039)\tLoss 0.4657 (0.4657)\tPrec@1 84.766 (84.766)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [42][10/20]\tTime 0.049 (0.199)\tData 0.000 (0.142)\tLoss 0.4935 (0.4899)\tPrec@1 85.547 (84.677)\tPrec@5 99.023 (99.450)\t\n",
            "\n",
            "Results - Epoch: 43\n",
            "Training Loss 0.3056 \tTraining Prec@1 89.258 \tTraining Prec@5 99.722 \tValidation Loss 0.4942 \tValidation Prec@1 84.550 \tValidation Prec@5 99.420 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 44\n",
            "\n",
            "TRAINING - Epoch: [43][0/97]\tTime 1.513 (1.513)\tData 1.227 (1.227)\tLoss 0.2871 (0.2871)\tPrec@1 91.211 (91.211)\tPrec@5 99.414 (99.414)\t\n",
            "TRAINING - Epoch: [43][10/97]\tTime 0.156 (0.339)\tData 0.001 (0.117)\tLoss 0.3066 (0.2777)\tPrec@1 88.477 (90.643)\tPrec@5 100.000 (99.769)\t\n",
            "TRAINING - Epoch: [43][20/97]\tTime 0.151 (0.253)\tData 0.000 (0.062)\tLoss 0.3108 (0.2822)\tPrec@1 87.891 (90.030)\tPrec@5 100.000 (99.777)\t\n",
            "TRAINING - Epoch: [43][30/97]\tTime 0.177 (0.224)\tData 0.000 (0.042)\tLoss 0.2310 (0.2766)\tPrec@1 90.820 (90.272)\tPrec@5 99.805 (99.792)\t\n",
            "TRAINING - Epoch: [43][40/97]\tTime 0.153 (0.209)\tData 0.000 (0.032)\tLoss 0.3154 (0.2869)\tPrec@1 88.281 (89.853)\tPrec@5 99.805 (99.786)\t\n",
            "TRAINING - Epoch: [43][50/97]\tTime 0.150 (0.200)\tData 0.000 (0.026)\tLoss 0.2988 (0.2884)\tPrec@1 90.430 (89.828)\tPrec@5 99.609 (99.797)\t\n",
            "TRAINING - Epoch: [43][60/97]\tTime 0.154 (0.194)\tData 0.000 (0.022)\tLoss 0.3473 (0.2919)\tPrec@1 86.719 (89.693)\tPrec@5 99.609 (99.776)\t\n",
            "TRAINING - Epoch: [43][70/97]\tTime 0.152 (0.190)\tData 0.000 (0.019)\tLoss 0.3285 (0.2928)\tPrec@1 88.477 (89.668)\tPrec@5 99.414 (99.766)\t\n",
            "TRAINING - Epoch: [43][80/97]\tTime 0.181 (0.186)\tData 0.000 (0.017)\tLoss 0.3471 (0.2944)\tPrec@1 88.477 (89.624)\tPrec@5 99.609 (99.769)\t\n",
            "TRAINING - Epoch: [43][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.015)\tLoss 0.3444 (0.2952)\tPrec@1 87.891 (89.601)\tPrec@5 99.609 (99.768)\t\n",
            "EVALUATING - Epoch: [43][0/20]\tTime 0.927 (0.927)\tData 0.876 (0.876)\tLoss 0.5761 (0.5761)\tPrec@1 81.445 (81.445)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [43][10/20]\tTime 0.057 (0.197)\tData 0.000 (0.145)\tLoss 0.4837 (0.5557)\tPrec@1 84.961 (83.203)\tPrec@5 99.414 (99.254)\t\n",
            "\n",
            "Results - Epoch: 44\n",
            "Training Loss 0.2963 \tTraining Prec@1 89.562 \tTraining Prec@5 99.760 \tValidation Loss 0.5460 \tValidation Prec@1 83.290 \tValidation Prec@5 99.280 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 45\n",
            "\n",
            "TRAINING - Epoch: [44][0/97]\tTime 1.331 (1.331)\tData 1.099 (1.099)\tLoss 0.2342 (0.2342)\tPrec@1 90.820 (90.820)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [44][10/97]\tTime 0.151 (0.337)\tData 0.000 (0.102)\tLoss 0.2547 (0.2622)\tPrec@1 91.992 (91.087)\tPrec@5 100.000 (99.840)\t\n",
            "TRAINING - Epoch: [44][20/97]\tTime 0.154 (0.255)\tData 0.000 (0.054)\tLoss 0.2770 (0.2727)\tPrec@1 90.430 (90.467)\tPrec@5 99.805 (99.814)\t\n",
            "TRAINING - Epoch: [44][30/97]\tTime 0.163 (0.225)\tData 0.000 (0.037)\tLoss 0.2879 (0.2807)\tPrec@1 89.062 (90.241)\tPrec@5 100.000 (99.786)\t\n",
            "TRAINING - Epoch: [44][40/97]\tTime 0.161 (0.211)\tData 0.000 (0.028)\tLoss 0.3149 (0.2806)\tPrec@1 88.672 (90.201)\tPrec@5 99.414 (99.757)\t\n",
            "TRAINING - Epoch: [44][50/97]\tTime 0.155 (0.202)\tData 0.000 (0.023)\tLoss 0.3024 (0.2826)\tPrec@1 88.477 (90.047)\tPrec@5 100.000 (99.778)\t\n",
            "TRAINING - Epoch: [44][60/97]\tTime 0.161 (0.195)\tData 0.000 (0.019)\tLoss 0.3109 (0.2858)\tPrec@1 88.281 (89.943)\tPrec@5 100.000 (99.782)\t\n",
            "TRAINING - Epoch: [44][70/97]\tTime 0.157 (0.190)\tData 0.000 (0.017)\tLoss 0.2668 (0.2910)\tPrec@1 90.430 (89.805)\tPrec@5 99.805 (99.769)\t\n",
            "TRAINING - Epoch: [44][80/97]\tTime 0.152 (0.186)\tData 0.000 (0.015)\tLoss 0.2758 (0.2904)\tPrec@1 90.234 (89.841)\tPrec@5 99.805 (99.769)\t\n",
            "TRAINING - Epoch: [44][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.013)\tLoss 0.3079 (0.2926)\tPrec@1 88.867 (89.730)\tPrec@5 99.414 (99.760)\t\n",
            "EVALUATING - Epoch: [44][0/20]\tTime 0.972 (0.972)\tData 0.925 (0.925)\tLoss 0.4755 (0.4755)\tPrec@1 82.617 (82.617)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [44][10/20]\tTime 0.048 (0.198)\tData 0.000 (0.144)\tLoss 0.4931 (0.5590)\tPrec@1 84.570 (83.612)\tPrec@5 99.219 (99.077)\t\n",
            "\n",
            "Results - Epoch: 45\n",
            "Training Loss 0.2925 \tTraining Prec@1 89.719 \tTraining Prec@5 99.766 \tValidation Loss 0.5588 \tValidation Prec@1 83.450 \tValidation Prec@5 99.040 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 46\n",
            "\n",
            "TRAINING - Epoch: [45][0/97]\tTime 1.519 (1.519)\tData 1.224 (1.224)\tLoss 0.2966 (0.2966)\tPrec@1 87.500 (87.500)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [45][10/97]\tTime 0.184 (0.339)\tData 0.000 (0.116)\tLoss 0.3137 (0.2882)\tPrec@1 91.016 (90.004)\tPrec@5 99.609 (99.751)\t\n",
            "TRAINING - Epoch: [45][20/97]\tTime 0.172 (0.253)\tData 0.005 (0.062)\tLoss 0.2835 (0.2823)\tPrec@1 89.258 (90.179)\tPrec@5 99.805 (99.795)\t\n",
            "TRAINING - Epoch: [45][30/97]\tTime 0.153 (0.224)\tData 0.000 (0.042)\tLoss 0.2587 (0.2900)\tPrec@1 90.625 (89.737)\tPrec@5 99.414 (99.786)\t\n",
            "TRAINING - Epoch: [45][40/97]\tTime 0.163 (0.210)\tData 0.000 (0.032)\tLoss 0.2604 (0.2897)\tPrec@1 91.992 (89.791)\tPrec@5 99.805 (99.781)\t\n",
            "TRAINING - Epoch: [45][50/97]\tTime 0.176 (0.201)\tData 0.000 (0.026)\tLoss 0.2968 (0.2890)\tPrec@1 89.258 (89.817)\tPrec@5 99.414 (99.789)\t\n",
            "TRAINING - Epoch: [45][60/97]\tTime 0.155 (0.194)\tData 0.000 (0.022)\tLoss 0.2836 (0.2923)\tPrec@1 90.039 (89.677)\tPrec@5 99.805 (99.776)\t\n",
            "TRAINING - Epoch: [45][70/97]\tTime 0.149 (0.189)\tData 0.000 (0.019)\tLoss 0.3458 (0.2938)\tPrec@1 88.867 (89.643)\tPrec@5 99.609 (99.772)\t\n",
            "TRAINING - Epoch: [45][80/97]\tTime 0.153 (0.186)\tData 0.000 (0.017)\tLoss 0.3466 (0.2940)\tPrec@1 86.719 (89.581)\tPrec@5 99.414 (99.771)\t\n",
            "TRAINING - Epoch: [45][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.015)\tLoss 0.2684 (0.2937)\tPrec@1 91.797 (89.548)\tPrec@5 99.414 (99.772)\t\n",
            "EVALUATING - Epoch: [45][0/20]\tTime 1.079 (1.079)\tData 1.012 (1.012)\tLoss 0.5177 (0.5177)\tPrec@1 82.227 (82.227)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [45][10/20]\tTime 0.059 (0.187)\tData 0.000 (0.131)\tLoss 0.4774 (0.5493)\tPrec@1 84.375 (82.599)\tPrec@5 99.023 (99.059)\t\n",
            "\n",
            "Results - Epoch: 46\n",
            "Training Loss 0.2960 \tTraining Prec@1 89.479 \tTraining Prec@5 99.764 \tValidation Loss 0.5472 \tValidation Prec@1 82.550 \tValidation Prec@5 99.220 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 47\n",
            "\n",
            "TRAINING - Epoch: [46][0/97]\tTime 1.387 (1.387)\tData 1.101 (1.101)\tLoss 0.2795 (0.2795)\tPrec@1 89.062 (89.062)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [46][10/97]\tTime 0.150 (0.334)\tData 0.000 (0.104)\tLoss 0.3049 (0.2711)\tPrec@1 89.258 (90.572)\tPrec@5 99.805 (99.645)\t\n",
            "TRAINING - Epoch: [46][20/97]\tTime 0.151 (0.254)\tData 0.000 (0.055)\tLoss 0.2744 (0.2808)\tPrec@1 88.672 (90.104)\tPrec@5 99.805 (99.712)\t\n",
            "TRAINING - Epoch: [46][30/97]\tTime 0.148 (0.224)\tData 0.000 (0.038)\tLoss 0.2798 (0.2763)\tPrec@1 90.039 (90.228)\tPrec@5 99.805 (99.742)\t\n",
            "TRAINING - Epoch: [46][40/97]\tTime 0.149 (0.210)\tData 0.000 (0.029)\tLoss 0.2731 (0.2755)\tPrec@1 90.430 (90.215)\tPrec@5 100.000 (99.786)\t\n",
            "TRAINING - Epoch: [46][50/97]\tTime 0.171 (0.200)\tData 0.000 (0.024)\tLoss 0.3150 (0.2827)\tPrec@1 88.672 (90.012)\tPrec@5 99.219 (99.774)\t\n",
            "TRAINING - Epoch: [46][60/97]\tTime 0.157 (0.194)\tData 0.000 (0.020)\tLoss 0.2614 (0.2855)\tPrec@1 89.453 (89.853)\tPrec@5 100.000 (99.760)\t\n",
            "TRAINING - Epoch: [46][70/97]\tTime 0.158 (0.190)\tData 0.000 (0.017)\tLoss 0.3402 (0.2880)\tPrec@1 87.500 (89.747)\tPrec@5 99.805 (99.763)\t\n",
            "TRAINING - Epoch: [46][80/97]\tTime 0.161 (0.186)\tData 0.007 (0.015)\tLoss 0.2660 (0.2896)\tPrec@1 90.820 (89.689)\tPrec@5 99.805 (99.761)\t\n",
            "TRAINING - Epoch: [46][90/97]\tTime 0.151 (0.182)\tData 0.000 (0.014)\tLoss 0.3098 (0.2943)\tPrec@1 88.281 (89.582)\tPrec@5 100.000 (99.753)\t\n",
            "EVALUATING - Epoch: [46][0/20]\tTime 1.377 (1.377)\tData 1.326 (1.326)\tLoss 0.5247 (0.5247)\tPrec@1 82.812 (82.812)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [46][10/20]\tTime 0.044 (0.204)\tData 0.000 (0.152)\tLoss 0.4944 (0.5292)\tPrec@1 84.766 (83.345)\tPrec@5 99.414 (99.308)\t\n",
            "\n",
            "Results - Epoch: 47\n",
            "Training Loss 0.2944 \tTraining Prec@1 89.576 \tTraining Prec@5 99.764 \tValidation Loss 0.5251 \tValidation Prec@1 83.240 \tValidation Prec@5 99.350 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 48\n",
            "\n",
            "TRAINING - Epoch: [47][0/97]\tTime 1.448 (1.448)\tData 1.166 (1.166)\tLoss 0.3609 (0.3609)\tPrec@1 87.500 (87.500)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [47][10/97]\tTime 0.183 (0.339)\tData 0.000 (0.108)\tLoss 0.3300 (0.2985)\tPrec@1 88.672 (89.577)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [47][20/97]\tTime 0.168 (0.256)\tData 0.000 (0.057)\tLoss 0.3295 (0.2948)\tPrec@1 89.062 (89.872)\tPrec@5 100.000 (99.833)\t\n",
            "TRAINING - Epoch: [47][30/97]\tTime 0.149 (0.226)\tData 0.001 (0.039)\tLoss 0.2673 (0.2886)\tPrec@1 90.820 (89.945)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [47][40/97]\tTime 0.152 (0.210)\tData 0.000 (0.030)\tLoss 0.2454 (0.2841)\tPrec@1 91.211 (90.134)\tPrec@5 99.805 (99.814)\t\n",
            "TRAINING - Epoch: [47][50/97]\tTime 0.155 (0.201)\tData 0.000 (0.024)\tLoss 0.3313 (0.2859)\tPrec@1 90.039 (90.028)\tPrec@5 99.414 (99.816)\t\n",
            "TRAINING - Epoch: [47][60/97]\tTime 0.150 (0.195)\tData 0.000 (0.020)\tLoss 0.2923 (0.2886)\tPrec@1 90.430 (89.949)\tPrec@5 99.805 (99.821)\t\n",
            "TRAINING - Epoch: [47][70/97]\tTime 0.150 (0.190)\tData 0.000 (0.018)\tLoss 0.2548 (0.2876)\tPrec@1 90.430 (89.987)\tPrec@5 99.805 (99.802)\t\n",
            "TRAINING - Epoch: [47][80/97]\tTime 0.158 (0.186)\tData 0.000 (0.016)\tLoss 0.3096 (0.2857)\tPrec@1 89.844 (90.044)\tPrec@5 99.609 (99.797)\t\n",
            "TRAINING - Epoch: [47][90/97]\tTime 0.150 (0.183)\tData 0.000 (0.014)\tLoss 0.2893 (0.2861)\tPrec@1 90.039 (90.046)\tPrec@5 99.805 (99.798)\t\n",
            "EVALUATING - Epoch: [47][0/20]\tTime 1.113 (1.113)\tData 1.065 (1.065)\tLoss 0.5412 (0.5412)\tPrec@1 81.445 (81.445)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [47][10/20]\tTime 0.045 (0.196)\tData 0.000 (0.141)\tLoss 0.6485 (0.5972)\tPrec@1 81.445 (82.102)\tPrec@5 99.023 (98.810)\t\n",
            "\n",
            "Results - Epoch: 48\n",
            "Training Loss 0.2866 \tTraining Prec@1 89.993 \tTraining Prec@5 99.795 \tValidation Loss 0.6043 \tValidation Prec@1 82.220 \tValidation Prec@5 98.740 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 49\n",
            "\n",
            "TRAINING - Epoch: [48][0/97]\tTime 1.320 (1.320)\tData 1.042 (1.042)\tLoss 0.2853 (0.2853)\tPrec@1 89.648 (89.648)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [48][10/97]\tTime 0.151 (0.333)\tData 0.000 (0.098)\tLoss 0.2637 (0.2747)\tPrec@1 91.016 (90.163)\tPrec@5 99.805 (99.822)\t\n",
            "TRAINING - Epoch: [48][20/97]\tTime 0.169 (0.252)\tData 0.000 (0.052)\tLoss 0.3247 (0.2725)\tPrec@1 89.844 (90.281)\tPrec@5 99.414 (99.786)\t\n",
            "TRAINING - Epoch: [48][30/97]\tTime 0.150 (0.223)\tData 0.000 (0.036)\tLoss 0.2647 (0.2780)\tPrec@1 89.844 (90.077)\tPrec@5 100.000 (99.779)\t\n",
            "TRAINING - Epoch: [48][40/97]\tTime 0.185 (0.209)\tData 0.000 (0.028)\tLoss 0.2820 (0.2787)\tPrec@1 90.820 (90.144)\tPrec@5 99.805 (99.786)\t\n",
            "TRAINING - Epoch: [48][50/97]\tTime 0.153 (0.200)\tData 0.000 (0.022)\tLoss 0.2801 (0.2780)\tPrec@1 90.234 (90.169)\tPrec@5 99.805 (99.797)\t\n",
            "TRAINING - Epoch: [48][60/97]\tTime 0.162 (0.193)\tData 0.007 (0.019)\tLoss 0.2600 (0.2790)\tPrec@1 89.453 (90.180)\tPrec@5 99.805 (99.795)\t\n",
            "TRAINING - Epoch: [48][70/97]\tTime 0.166 (0.188)\tData 0.000 (0.017)\tLoss 0.2576 (0.2773)\tPrec@1 90.625 (90.276)\tPrec@5 99.805 (99.783)\t\n",
            "TRAINING - Epoch: [48][80/97]\tTime 0.152 (0.185)\tData 0.000 (0.015)\tLoss 0.3207 (0.2787)\tPrec@1 88.086 (90.254)\tPrec@5 99.805 (99.785)\t\n",
            "TRAINING - Epoch: [48][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.013)\tLoss 0.2319 (0.2801)\tPrec@1 90.430 (90.191)\tPrec@5 100.000 (99.779)\t\n",
            "EVALUATING - Epoch: [48][0/20]\tTime 1.400 (1.400)\tData 1.344 (1.344)\tLoss 0.4657 (0.4657)\tPrec@1 83.398 (83.398)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [48][10/20]\tTime 0.044 (0.205)\tData 0.000 (0.152)\tLoss 0.4743 (0.4926)\tPrec@1 86.523 (84.979)\tPrec@5 99.219 (99.308)\t\n",
            "\n",
            "Results - Epoch: 49\n",
            "Training Loss 0.2820 \tTraining Prec@1 90.124 \tTraining Prec@5 99.781 \tValidation Loss 0.4932 \tValidation Prec@1 85.030 \tValidation Prec@5 99.370 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 50\n",
            "\n",
            "TRAINING - Epoch: [49][0/97]\tTime 1.527 (1.527)\tData 1.246 (1.246)\tLoss 0.2889 (0.2889)\tPrec@1 89.648 (89.648)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [49][10/97]\tTime 0.152 (0.337)\tData 0.000 (0.117)\tLoss 0.2559 (0.2690)\tPrec@1 90.430 (90.661)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [49][20/97]\tTime 0.185 (0.254)\tData 0.000 (0.062)\tLoss 0.2738 (0.2634)\tPrec@1 89.062 (90.606)\tPrec@5 99.609 (99.777)\t\n",
            "TRAINING - Epoch: [49][30/97]\tTime 0.148 (0.224)\tData 0.000 (0.043)\tLoss 0.2899 (0.2660)\tPrec@1 89.648 (90.669)\tPrec@5 99.609 (99.742)\t\n",
            "TRAINING - Epoch: [49][40/97]\tTime 0.148 (0.209)\tData 0.000 (0.032)\tLoss 0.3027 (0.2678)\tPrec@1 88.086 (90.525)\tPrec@5 99.805 (99.738)\t\n",
            "TRAINING - Epoch: [49][50/97]\tTime 0.171 (0.200)\tData 0.005 (0.026)\tLoss 0.2440 (0.2699)\tPrec@1 91.992 (90.518)\tPrec@5 99.805 (99.755)\t\n",
            "TRAINING - Epoch: [49][60/97]\tTime 0.153 (0.194)\tData 0.000 (0.022)\tLoss 0.2127 (0.2720)\tPrec@1 92.969 (90.452)\tPrec@5 99.805 (99.757)\t\n",
            "TRAINING - Epoch: [49][70/97]\tTime 0.162 (0.189)\tData 0.000 (0.019)\tLoss 0.2717 (0.2741)\tPrec@1 91.211 (90.375)\tPrec@5 100.000 (99.763)\t\n",
            "TRAINING - Epoch: [49][80/97]\tTime 0.163 (0.186)\tData 0.000 (0.017)\tLoss 0.3066 (0.2755)\tPrec@1 89.062 (90.295)\tPrec@5 100.000 (99.771)\t\n",
            "TRAINING - Epoch: [49][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.015)\tLoss 0.3274 (0.2794)\tPrec@1 88.867 (90.133)\tPrec@5 99.805 (99.764)\t\n",
            "EVALUATING - Epoch: [49][0/20]\tTime 0.993 (0.993)\tData 0.947 (0.947)\tLoss 0.6519 (0.6519)\tPrec@1 80.469 (80.469)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [49][10/20]\tTime 0.057 (0.197)\tData 0.000 (0.141)\tLoss 0.6405 (0.6842)\tPrec@1 81.445 (80.717)\tPrec@5 99.023 (98.846)\t\n",
            "\n",
            "Results - Epoch: 50\n",
            "Training Loss 0.2806 \tTraining Prec@1 90.140 \tTraining Prec@5 99.758 \tValidation Loss 0.6839 \tValidation Prec@1 80.170 \tValidation Prec@5 99.020 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 51\n",
            "\n",
            "TRAINING - Epoch: [50][0/97]\tTime 1.467 (1.467)\tData 1.161 (1.161)\tLoss 0.2536 (0.2536)\tPrec@1 90.820 (90.820)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [50][10/97]\tTime 0.165 (0.341)\tData 0.000 (0.110)\tLoss 0.2321 (0.2689)\tPrec@1 90.625 (90.252)\tPrec@5 99.805 (99.840)\t\n",
            "TRAINING - Epoch: [50][20/97]\tTime 0.171 (0.255)\tData 0.006 (0.058)\tLoss 0.2900 (0.2727)\tPrec@1 89.258 (90.355)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [50][30/97]\tTime 0.154 (0.224)\tData 0.000 (0.040)\tLoss 0.2397 (0.2659)\tPrec@1 92.578 (90.568)\tPrec@5 99.805 (99.842)\t\n",
            "TRAINING - Epoch: [50][40/97]\tTime 0.156 (0.208)\tData 0.005 (0.031)\tLoss 0.2873 (0.2665)\tPrec@1 88.281 (90.454)\tPrec@5 99.805 (99.824)\t\n",
            "TRAINING - Epoch: [50][50/97]\tTime 0.157 (0.199)\tData 0.000 (0.025)\tLoss 0.2710 (0.2703)\tPrec@1 90.234 (90.349)\tPrec@5 100.000 (99.820)\t\n",
            "TRAINING - Epoch: [50][60/97]\tTime 0.152 (0.193)\tData 0.000 (0.021)\tLoss 0.2683 (0.2721)\tPrec@1 90.234 (90.398)\tPrec@5 99.609 (99.805)\t\n",
            "TRAINING - Epoch: [50][70/97]\tTime 0.149 (0.188)\tData 0.000 (0.018)\tLoss 0.2709 (0.2707)\tPrec@1 90.039 (90.372)\tPrec@5 99.805 (99.813)\t\n",
            "TRAINING - Epoch: [50][80/97]\tTime 0.159 (0.185)\tData 0.000 (0.016)\tLoss 0.2411 (0.2717)\tPrec@1 91.211 (90.357)\tPrec@5 100.000 (99.817)\t\n",
            "TRAINING - Epoch: [50][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.014)\tLoss 0.3029 (0.2736)\tPrec@1 88.281 (90.292)\tPrec@5 100.000 (99.809)\t\n",
            "EVALUATING - Epoch: [50][0/20]\tTime 1.210 (1.210)\tData 1.153 (1.153)\tLoss 0.4516 (0.4516)\tPrec@1 83.398 (83.398)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [50][10/20]\tTime 0.047 (0.196)\tData 0.000 (0.139)\tLoss 0.4632 (0.5030)\tPrec@1 86.914 (84.624)\tPrec@5 99.414 (99.272)\t\n",
            "\n",
            "Results - Epoch: 51\n",
            "Training Loss 0.2744 \tTraining Prec@1 90.259 \tTraining Prec@5 99.811 \tValidation Loss 0.4914 \tValidation Prec@1 84.520 \tValidation Prec@5 99.370 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 52\n",
            "\n",
            "TRAINING - Epoch: [51][0/97]\tTime 1.526 (1.526)\tData 1.265 (1.265)\tLoss 0.2186 (0.2186)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [51][10/97]\tTime 0.214 (0.338)\tData 0.000 (0.119)\tLoss 0.2167 (0.2510)\tPrec@1 92.188 (91.264)\tPrec@5 100.000 (99.822)\t\n",
            "TRAINING - Epoch: [51][20/97]\tTime 0.147 (0.253)\tData 0.000 (0.063)\tLoss 0.3045 (0.2582)\tPrec@1 89.844 (90.969)\tPrec@5 99.414 (99.758)\t\n",
            "TRAINING - Epoch: [51][30/97]\tTime 0.183 (0.224)\tData 0.000 (0.043)\tLoss 0.2695 (0.2575)\tPrec@1 90.430 (91.066)\tPrec@5 100.000 (99.767)\t\n",
            "TRAINING - Epoch: [51][40/97]\tTime 0.160 (0.209)\tData 0.000 (0.033)\tLoss 0.2775 (0.2621)\tPrec@1 90.820 (90.882)\tPrec@5 99.609 (99.757)\t\n",
            "TRAINING - Epoch: [51][50/97]\tTime 0.170 (0.199)\tData 0.000 (0.026)\tLoss 0.2991 (0.2675)\tPrec@1 90.625 (90.702)\tPrec@5 99.414 (99.759)\t\n",
            "TRAINING - Epoch: [51][60/97]\tTime 0.164 (0.193)\tData 0.000 (0.023)\tLoss 0.2522 (0.2696)\tPrec@1 92.578 (90.689)\tPrec@5 99.805 (99.773)\t\n",
            "TRAINING - Epoch: [51][70/97]\tTime 0.167 (0.189)\tData 0.005 (0.020)\tLoss 0.2727 (0.2699)\tPrec@1 89.648 (90.589)\tPrec@5 100.000 (99.791)\t\n",
            "TRAINING - Epoch: [51][80/97]\tTime 0.150 (0.185)\tData 0.000 (0.017)\tLoss 0.3063 (0.2707)\tPrec@1 89.844 (90.536)\tPrec@5 99.805 (99.795)\t\n",
            "TRAINING - Epoch: [51][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.015)\tLoss 0.2997 (0.2715)\tPrec@1 89.453 (90.475)\tPrec@5 99.805 (99.794)\t\n",
            "EVALUATING - Epoch: [51][0/20]\tTime 1.025 (1.025)\tData 0.966 (0.966)\tLoss 0.4995 (0.4995)\tPrec@1 83.398 (83.398)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [51][10/20]\tTime 0.062 (0.190)\tData 0.000 (0.134)\tLoss 0.5612 (0.5216)\tPrec@1 81.641 (83.434)\tPrec@5 99.219 (99.219)\t\n",
            "\n",
            "Results - Epoch: 52\n",
            "Training Loss 0.2725 \tTraining Prec@1 90.432 \tTraining Prec@5 99.789 \tValidation Loss 0.5218 \tValidation Prec@1 83.380 \tValidation Prec@5 99.350 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 53\n",
            "\n",
            "TRAINING - Epoch: [52][0/97]\tTime 1.487 (1.487)\tData 1.194 (1.194)\tLoss 0.2158 (0.2158)\tPrec@1 91.406 (91.406)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [52][10/97]\tTime 0.157 (0.334)\tData 0.000 (0.114)\tLoss 0.2403 (0.2498)\tPrec@1 90.625 (90.962)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [52][20/97]\tTime 0.181 (0.255)\tData 0.000 (0.061)\tLoss 0.2647 (0.2625)\tPrec@1 89.648 (90.699)\tPrec@5 99.414 (99.823)\t\n",
            "TRAINING - Epoch: [52][30/97]\tTime 0.158 (0.225)\tData 0.000 (0.041)\tLoss 0.2754 (0.2615)\tPrec@1 90.234 (90.789)\tPrec@5 99.609 (99.792)\t\n",
            "TRAINING - Epoch: [52][40/97]\tTime 0.172 (0.210)\tData 0.000 (0.032)\tLoss 0.2461 (0.2625)\tPrec@1 91.211 (90.749)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [52][50/97]\tTime 0.157 (0.201)\tData 0.000 (0.026)\tLoss 0.3261 (0.2637)\tPrec@1 89.062 (90.671)\tPrec@5 99.805 (99.820)\t\n",
            "TRAINING - Epoch: [52][60/97]\tTime 0.153 (0.195)\tData 0.000 (0.022)\tLoss 0.2796 (0.2627)\tPrec@1 91.016 (90.663)\tPrec@5 99.414 (99.814)\t\n",
            "TRAINING - Epoch: [52][70/97]\tTime 0.156 (0.190)\tData 0.000 (0.019)\tLoss 0.3283 (0.2628)\tPrec@1 89.258 (90.691)\tPrec@5 99.805 (99.824)\t\n",
            "TRAINING - Epoch: [52][80/97]\tTime 0.156 (0.186)\tData 0.000 (0.017)\tLoss 0.2385 (0.2619)\tPrec@1 90.820 (90.731)\tPrec@5 100.000 (99.826)\t\n",
            "TRAINING - Epoch: [52][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.015)\tLoss 0.2734 (0.2626)\tPrec@1 90.234 (90.719)\tPrec@5 99.609 (99.818)\t\n",
            "EVALUATING - Epoch: [52][0/20]\tTime 1.004 (1.004)\tData 0.954 (0.954)\tLoss 0.5493 (0.5493)\tPrec@1 83.203 (83.203)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [52][10/20]\tTime 0.064 (0.192)\tData 0.000 (0.138)\tLoss 0.6350 (0.6006)\tPrec@1 81.445 (82.457)\tPrec@5 99.023 (99.059)\t\n",
            "\n",
            "Results - Epoch: 53\n",
            "Training Loss 0.2622 \tTraining Prec@1 90.732 \tTraining Prec@5 99.813 \tValidation Loss 0.6038 \tValidation Prec@1 82.400 \tValidation Prec@5 99.140 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 54\n",
            "\n",
            "TRAINING - Epoch: [53][0/97]\tTime 1.441 (1.441)\tData 1.163 (1.163)\tLoss 0.2264 (0.2264)\tPrec@1 92.383 (92.383)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [53][10/97]\tTime 0.155 (0.340)\tData 0.000 (0.110)\tLoss 0.2585 (0.2513)\tPrec@1 90.234 (91.317)\tPrec@5 99.805 (99.787)\t\n",
            "TRAINING - Epoch: [53][20/97]\tTime 0.164 (0.256)\tData 0.000 (0.058)\tLoss 0.2429 (0.2612)\tPrec@1 91.016 (90.913)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [53][30/97]\tTime 0.160 (0.224)\tData 0.000 (0.040)\tLoss 0.2579 (0.2635)\tPrec@1 90.234 (90.915)\tPrec@5 100.000 (99.811)\t\n",
            "TRAINING - Epoch: [53][40/97]\tTime 0.170 (0.209)\tData 0.000 (0.030)\tLoss 0.2356 (0.2621)\tPrec@1 91.406 (90.916)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [53][50/97]\tTime 0.156 (0.200)\tData 0.000 (0.025)\tLoss 0.2904 (0.2625)\tPrec@1 90.430 (90.855)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [53][60/97]\tTime 0.172 (0.195)\tData 0.000 (0.021)\tLoss 0.1889 (0.2609)\tPrec@1 92.969 (90.862)\tPrec@5 99.805 (99.834)\t\n",
            "TRAINING - Epoch: [53][70/97]\tTime 0.160 (0.190)\tData 0.000 (0.018)\tLoss 0.2436 (0.2619)\tPrec@1 91.992 (90.804)\tPrec@5 99.609 (99.824)\t\n",
            "TRAINING - Epoch: [53][80/97]\tTime 0.154 (0.187)\tData 0.000 (0.016)\tLoss 0.2644 (0.2629)\tPrec@1 89.844 (90.772)\tPrec@5 99.805 (99.819)\t\n",
            "TRAINING - Epoch: [53][90/97]\tTime 0.152 (0.183)\tData 0.000 (0.014)\tLoss 0.2837 (0.2643)\tPrec@1 90.039 (90.685)\tPrec@5 99.805 (99.813)\t\n",
            "EVALUATING - Epoch: [53][0/20]\tTime 1.243 (1.243)\tData 1.194 (1.194)\tLoss 0.6212 (0.6212)\tPrec@1 81.055 (81.055)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [53][10/20]\tTime 0.052 (0.199)\tData 0.000 (0.144)\tLoss 0.6225 (0.6562)\tPrec@1 82.617 (81.197)\tPrec@5 99.023 (99.148)\t\n",
            "\n",
            "Results - Epoch: 54\n",
            "Training Loss 0.2644 \tTraining Prec@1 90.677 \tTraining Prec@5 99.815 \tValidation Loss 0.6550 \tValidation Prec@1 81.090 \tValidation Prec@5 99.190 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 55\n",
            "\n",
            "TRAINING - Epoch: [54][0/97]\tTime 1.408 (1.408)\tData 1.130 (1.130)\tLoss 0.2405 (0.2405)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [54][10/97]\tTime 0.152 (0.340)\tData 0.000 (0.106)\tLoss 0.2670 (0.2646)\tPrec@1 90.430 (90.589)\tPrec@5 99.805 (99.840)\t\n",
            "TRAINING - Epoch: [54][20/97]\tTime 0.150 (0.255)\tData 0.000 (0.056)\tLoss 0.2069 (0.2526)\tPrec@1 93.164 (91.034)\tPrec@5 99.805 (99.823)\t\n",
            "TRAINING - Epoch: [54][30/97]\tTime 0.158 (0.225)\tData 0.000 (0.038)\tLoss 0.2717 (0.2488)\tPrec@1 90.430 (91.224)\tPrec@5 99.805 (99.842)\t\n",
            "TRAINING - Epoch: [54][40/97]\tTime 0.180 (0.210)\tData 0.008 (0.030)\tLoss 0.2601 (0.2504)\tPrec@1 90.820 (91.278)\tPrec@5 100.000 (99.829)\t\n",
            "TRAINING - Epoch: [54][50/97]\tTime 0.156 (0.200)\tData 0.000 (0.024)\tLoss 0.2852 (0.2544)\tPrec@1 88.672 (91.085)\tPrec@5 99.805 (99.831)\t\n",
            "TRAINING - Epoch: [54][60/97]\tTime 0.150 (0.194)\tData 0.000 (0.020)\tLoss 0.2208 (0.2543)\tPrec@1 92.773 (91.131)\tPrec@5 99.805 (99.827)\t\n",
            "TRAINING - Epoch: [54][70/97]\tTime 0.162 (0.189)\tData 0.000 (0.018)\tLoss 0.2844 (0.2569)\tPrec@1 89.453 (90.983)\tPrec@5 99.609 (99.827)\t\n",
            "TRAINING - Epoch: [54][80/97]\tTime 0.161 (0.186)\tData 0.005 (0.016)\tLoss 0.3061 (0.2587)\tPrec@1 89.258 (90.934)\tPrec@5 99.609 (99.819)\t\n",
            "TRAINING - Epoch: [54][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.014)\tLoss 0.2513 (0.2595)\tPrec@1 90.625 (90.878)\tPrec@5 99.805 (99.811)\t\n",
            "EVALUATING - Epoch: [54][0/20]\tTime 1.058 (1.058)\tData 0.984 (0.984)\tLoss 0.4649 (0.4649)\tPrec@1 83.789 (83.789)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [54][10/20]\tTime 0.044 (0.199)\tData 0.000 (0.143)\tLoss 0.4912 (0.4943)\tPrec@1 85.742 (84.801)\tPrec@5 99.219 (99.272)\t\n",
            "\n",
            "Results - Epoch: 55\n",
            "Training Loss 0.2597 \tTraining Prec@1 90.857 \tTraining Prec@5 99.811 \tValidation Loss 0.5002 \tValidation Prec@1 84.640 \tValidation Prec@5 99.350 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 56\n",
            "\n",
            "TRAINING - Epoch: [55][0/97]\tTime 1.404 (1.404)\tData 1.086 (1.086)\tLoss 0.2130 (0.2130)\tPrec@1 93.164 (93.164)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [55][10/97]\tTime 0.182 (0.338)\tData 0.000 (0.101)\tLoss 0.2924 (0.2621)\tPrec@1 89.844 (90.980)\tPrec@5 99.805 (99.858)\t\n",
            "TRAINING - Epoch: [55][20/97]\tTime 0.148 (0.253)\tData 0.000 (0.055)\tLoss 0.2935 (0.2583)\tPrec@1 90.820 (90.997)\tPrec@5 99.805 (99.833)\t\n",
            "TRAINING - Epoch: [55][30/97]\tTime 0.198 (0.224)\tData 0.004 (0.037)\tLoss 0.2663 (0.2567)\tPrec@1 90.234 (90.896)\tPrec@5 100.000 (99.842)\t\n",
            "TRAINING - Epoch: [55][40/97]\tTime 0.158 (0.210)\tData 0.005 (0.029)\tLoss 0.2284 (0.2534)\tPrec@1 91.602 (90.982)\tPrec@5 100.000 (99.848)\t\n",
            "TRAINING - Epoch: [55][50/97]\tTime 0.185 (0.200)\tData 0.000 (0.023)\tLoss 0.2663 (0.2533)\tPrec@1 90.820 (90.920)\tPrec@5 99.805 (99.847)\t\n",
            "TRAINING - Epoch: [55][60/97]\tTime 0.162 (0.194)\tData 0.000 (0.020)\tLoss 0.2378 (0.2529)\tPrec@1 92.188 (91.009)\tPrec@5 100.000 (99.840)\t\n",
            "TRAINING - Epoch: [55][70/97]\tTime 0.149 (0.188)\tData 0.000 (0.017)\tLoss 0.2847 (0.2530)\tPrec@1 90.039 (91.032)\tPrec@5 99.805 (99.838)\t\n",
            "TRAINING - Epoch: [55][80/97]\tTime 0.167 (0.185)\tData 0.000 (0.015)\tLoss 0.2678 (0.2545)\tPrec@1 89.844 (90.967)\tPrec@5 100.000 (99.836)\t\n",
            "TRAINING - Epoch: [55][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.014)\tLoss 0.3001 (0.2559)\tPrec@1 87.500 (90.906)\tPrec@5 100.000 (99.839)\t\n",
            "EVALUATING - Epoch: [55][0/20]\tTime 0.977 (0.977)\tData 0.933 (0.933)\tLoss 0.5131 (0.5131)\tPrec@1 83.594 (83.594)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [55][10/20]\tTime 0.057 (0.180)\tData 0.000 (0.129)\tLoss 0.4910 (0.5497)\tPrec@1 86.719 (84.375)\tPrec@5 99.219 (99.254)\t\n",
            "\n",
            "Results - Epoch: 56\n",
            "Training Loss 0.2568 \tTraining Prec@1 90.893 \tTraining Prec@5 99.833 \tValidation Loss 0.5460 \tValidation Prec@1 84.350 \tValidation Prec@5 99.280 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 57\n",
            "\n",
            "TRAINING - Epoch: [56][0/97]\tTime 1.325 (1.325)\tData 1.040 (1.040)\tLoss 0.2408 (0.2408)\tPrec@1 91.211 (91.211)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [56][10/97]\tTime 0.168 (0.328)\tData 0.000 (0.099)\tLoss 0.2065 (0.2413)\tPrec@1 92.969 (91.193)\tPrec@5 100.000 (99.787)\t\n",
            "TRAINING - Epoch: [56][20/97]\tTime 0.167 (0.251)\tData 0.000 (0.052)\tLoss 0.2427 (0.2353)\tPrec@1 89.844 (91.397)\tPrec@5 99.805 (99.823)\t\n",
            "TRAINING - Epoch: [56][30/97]\tTime 0.147 (0.221)\tData 0.000 (0.036)\tLoss 0.2263 (0.2401)\tPrec@1 92.383 (91.501)\tPrec@5 100.000 (99.855)\t\n",
            "TRAINING - Epoch: [56][40/97]\tTime 0.150 (0.206)\tData 0.000 (0.027)\tLoss 0.2527 (0.2429)\tPrec@1 90.820 (91.502)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [56][50/97]\tTime 0.156 (0.197)\tData 0.000 (0.022)\tLoss 0.2226 (0.2473)\tPrec@1 92.578 (91.337)\tPrec@5 99.805 (99.831)\t\n",
            "TRAINING - Epoch: [56][60/97]\tTime 0.162 (0.191)\tData 0.000 (0.018)\tLoss 0.2558 (0.2494)\tPrec@1 90.625 (91.233)\tPrec@5 99.805 (99.834)\t\n",
            "TRAINING - Epoch: [56][70/97]\tTime 0.148 (0.186)\tData 0.000 (0.016)\tLoss 0.2612 (0.2489)\tPrec@1 90.039 (91.238)\tPrec@5 99.805 (99.835)\t\n",
            "TRAINING - Epoch: [56][80/97]\tTime 0.159 (0.183)\tData 0.000 (0.014)\tLoss 0.2524 (0.2516)\tPrec@1 90.820 (91.119)\tPrec@5 100.000 (99.838)\t\n",
            "TRAINING - Epoch: [56][90/97]\tTime 0.149 (0.179)\tData 0.000 (0.013)\tLoss 0.2239 (0.2524)\tPrec@1 92.188 (91.071)\tPrec@5 100.000 (99.843)\t\n",
            "EVALUATING - Epoch: [56][0/20]\tTime 1.019 (1.019)\tData 0.972 (0.972)\tLoss 0.4733 (0.4733)\tPrec@1 84.766 (84.766)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [56][10/20]\tTime 0.054 (0.189)\tData 0.000 (0.136)\tLoss 0.4805 (0.5362)\tPrec@1 85.938 (84.766)\tPrec@5 99.023 (99.254)\t\n",
            "\n",
            "Results - Epoch: 57\n",
            "Training Loss 0.2535 \tTraining Prec@1 91.044 \tTraining Prec@5 99.839 \tValidation Loss 0.5307 \tValidation Prec@1 84.580 \tValidation Prec@5 99.410 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 58\n",
            "\n",
            "TRAINING - Epoch: [57][0/97]\tTime 1.467 (1.467)\tData 1.132 (1.132)\tLoss 0.2228 (0.2228)\tPrec@1 91.992 (91.992)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [57][10/97]\tTime 0.152 (0.339)\tData 0.000 (0.107)\tLoss 0.2705 (0.2333)\tPrec@1 91.406 (91.921)\tPrec@5 99.805 (99.929)\t\n",
            "TRAINING - Epoch: [57][20/97]\tTime 0.145 (0.256)\tData 0.000 (0.057)\tLoss 0.3051 (0.2348)\tPrec@1 90.039 (91.955)\tPrec@5 99.805 (99.879)\t\n",
            "TRAINING - Epoch: [57][30/97]\tTime 0.150 (0.226)\tData 0.000 (0.039)\tLoss 0.2019 (0.2386)\tPrec@1 92.188 (91.816)\tPrec@5 99.805 (99.868)\t\n",
            "TRAINING - Epoch: [57][40/97]\tTime 0.172 (0.210)\tData 0.000 (0.030)\tLoss 0.2875 (0.2417)\tPrec@1 89.258 (91.597)\tPrec@5 100.000 (99.838)\t\n",
            "TRAINING - Epoch: [57][50/97]\tTime 0.182 (0.202)\tData 0.000 (0.025)\tLoss 0.2060 (0.2446)\tPrec@1 92.383 (91.483)\tPrec@5 100.000 (99.839)\t\n",
            "TRAINING - Epoch: [57][60/97]\tTime 0.153 (0.195)\tData 0.000 (0.021)\tLoss 0.2544 (0.2486)\tPrec@1 91.602 (91.301)\tPrec@5 99.805 (99.834)\t\n",
            "TRAINING - Epoch: [57][70/97]\tTime 0.149 (0.190)\tData 0.000 (0.018)\tLoss 0.2319 (0.2504)\tPrec@1 91.016 (91.214)\tPrec@5 99.609 (99.835)\t\n",
            "TRAINING - Epoch: [57][80/97]\tTime 0.160 (0.186)\tData 0.000 (0.016)\tLoss 0.3066 (0.2509)\tPrec@1 87.891 (91.151)\tPrec@5 100.000 (99.843)\t\n",
            "TRAINING - Epoch: [57][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.014)\tLoss 0.2657 (0.2527)\tPrec@1 89.453 (91.046)\tPrec@5 100.000 (99.845)\t\n",
            "EVALUATING - Epoch: [57][0/20]\tTime 1.115 (1.115)\tData 1.068 (1.068)\tLoss 0.4834 (0.4834)\tPrec@1 83.203 (83.203)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [57][10/20]\tTime 0.045 (0.194)\tData 0.000 (0.141)\tLoss 0.4654 (0.5171)\tPrec@1 85.156 (84.730)\tPrec@5 99.609 (99.361)\t\n",
            "\n",
            "Results - Epoch: 58\n",
            "Training Loss 0.2530 \tTraining Prec@1 91.032 \tTraining Prec@5 99.849 \tValidation Loss 0.5196 \tValidation Prec@1 84.650 \tValidation Prec@5 99.340 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 59\n",
            "\n",
            "TRAINING - Epoch: [58][0/97]\tTime 1.261 (1.261)\tData 0.988 (0.988)\tLoss 0.2543 (0.2543)\tPrec@1 90.820 (90.820)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [58][10/97]\tTime 0.159 (0.334)\tData 0.000 (0.093)\tLoss 0.2300 (0.2327)\tPrec@1 91.602 (91.744)\tPrec@5 99.805 (99.858)\t\n",
            "TRAINING - Epoch: [58][20/97]\tTime 0.152 (0.254)\tData 0.000 (0.050)\tLoss 0.2675 (0.2343)\tPrec@1 90.430 (91.927)\tPrec@5 99.805 (99.860)\t\n",
            "TRAINING - Epoch: [58][30/97]\tTime 0.157 (0.224)\tData 0.000 (0.034)\tLoss 0.2170 (0.2338)\tPrec@1 92.383 (91.791)\tPrec@5 100.000 (99.887)\t\n",
            "TRAINING - Epoch: [58][40/97]\tTime 0.164 (0.209)\tData 0.000 (0.026)\tLoss 0.2350 (0.2337)\tPrec@1 91.602 (91.683)\tPrec@5 100.000 (99.881)\t\n",
            "TRAINING - Epoch: [58][50/97]\tTime 0.148 (0.199)\tData 0.000 (0.021)\tLoss 0.2579 (0.2367)\tPrec@1 90.039 (91.613)\tPrec@5 99.609 (99.851)\t\n",
            "TRAINING - Epoch: [58][60/97]\tTime 0.149 (0.192)\tData 0.000 (0.018)\tLoss 0.2675 (0.2377)\tPrec@1 90.234 (91.528)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [58][70/97]\tTime 0.159 (0.189)\tData 0.000 (0.016)\tLoss 0.2211 (0.2390)\tPrec@1 91.406 (91.472)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [58][80/97]\tTime 0.149 (0.185)\tData 0.000 (0.014)\tLoss 0.2543 (0.2411)\tPrec@1 90.039 (91.442)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [58][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.013)\tLoss 0.2332 (0.2444)\tPrec@1 91.602 (91.340)\tPrec@5 99.805 (99.848)\t\n",
            "EVALUATING - Epoch: [58][0/20]\tTime 1.038 (1.038)\tData 0.984 (0.984)\tLoss 0.5082 (0.5082)\tPrec@1 82.422 (82.422)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [58][10/20]\tTime 0.061 (0.189)\tData 0.000 (0.132)\tLoss 0.5563 (0.5273)\tPrec@1 85.156 (84.162)\tPrec@5 99.414 (99.343)\t\n",
            "\n",
            "Results - Epoch: 59\n",
            "Training Loss 0.2449 \tTraining Prec@1 91.318 \tTraining Prec@5 99.847 \tValidation Loss 0.5218 \tValidation Prec@1 84.600 \tValidation Prec@5 99.380 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 60\n",
            "\n",
            "TRAINING - Epoch: [59][0/97]\tTime 1.418 (1.418)\tData 1.115 (1.115)\tLoss 0.2424 (0.2424)\tPrec@1 93.359 (93.359)\tPrec@5 99.414 (99.414)\t\n",
            "TRAINING - Epoch: [59][10/97]\tTime 0.179 (0.339)\tData 0.000 (0.103)\tLoss 0.2256 (0.2508)\tPrec@1 91.797 (91.264)\tPrec@5 100.000 (99.876)\t\n",
            "TRAINING - Epoch: [59][20/97]\tTime 0.163 (0.253)\tData 0.000 (0.054)\tLoss 0.2457 (0.2417)\tPrec@1 91.602 (91.518)\tPrec@5 100.000 (99.870)\t\n",
            "TRAINING - Epoch: [59][30/97]\tTime 0.154 (0.224)\tData 0.000 (0.037)\tLoss 0.2146 (0.2392)\tPrec@1 92.188 (91.570)\tPrec@5 99.609 (99.861)\t\n",
            "TRAINING - Epoch: [59][40/97]\tTime 0.156 (0.209)\tData 0.007 (0.028)\tLoss 0.2767 (0.2421)\tPrec@1 89.648 (91.340)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [59][50/97]\tTime 0.149 (0.201)\tData 0.000 (0.023)\tLoss 0.2437 (0.2425)\tPrec@1 90.430 (91.291)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [59][60/97]\tTime 0.153 (0.194)\tData 0.000 (0.020)\tLoss 0.3038 (0.2462)\tPrec@1 90.234 (91.198)\tPrec@5 99.609 (99.850)\t\n",
            "TRAINING - Epoch: [59][70/97]\tTime 0.158 (0.190)\tData 0.000 (0.017)\tLoss 0.2077 (0.2446)\tPrec@1 93.359 (91.255)\tPrec@5 99.805 (99.838)\t\n",
            "TRAINING - Epoch: [59][80/97]\tTime 0.148 (0.186)\tData 0.000 (0.015)\tLoss 0.2295 (0.2449)\tPrec@1 91.406 (91.254)\tPrec@5 100.000 (99.846)\t\n",
            "TRAINING - Epoch: [59][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.013)\tLoss 0.2146 (0.2461)\tPrec@1 92.773 (91.220)\tPrec@5 99.805 (99.839)\t\n",
            "EVALUATING - Epoch: [59][0/20]\tTime 1.113 (1.113)\tData 1.066 (1.066)\tLoss 0.4573 (0.4573)\tPrec@1 85.742 (85.742)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [59][10/20]\tTime 0.047 (0.193)\tData 0.000 (0.135)\tLoss 0.5627 (0.5658)\tPrec@1 84.375 (84.038)\tPrec@5 99.219 (99.148)\t\n",
            "\n",
            "Results - Epoch: 60\n",
            "Training Loss 0.2459 \tTraining Prec@1 91.227 \tTraining Prec@5 99.841 \tValidation Loss 0.5626 \tValidation Prec@1 83.760 \tValidation Prec@5 99.220 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 61\n",
            "\n",
            "TRAINING - Epoch: [60][0/97]\tTime 1.595 (1.595)\tData 1.337 (1.337)\tLoss 0.2250 (0.2250)\tPrec@1 92.773 (92.773)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [60][10/97]\tTime 0.146 (0.343)\tData 0.000 (0.124)\tLoss 0.2775 (0.2256)\tPrec@1 90.234 (91.992)\tPrec@5 100.000 (99.840)\t\n",
            "TRAINING - Epoch: [60][20/97]\tTime 0.152 (0.259)\tData 0.000 (0.066)\tLoss 0.2528 (0.2342)\tPrec@1 90.234 (91.611)\tPrec@5 99.609 (99.805)\t\n",
            "TRAINING - Epoch: [60][30/97]\tTime 0.169 (0.227)\tData 0.000 (0.045)\tLoss 0.2016 (0.2345)\tPrec@1 91.602 (91.513)\tPrec@5 100.000 (99.824)\t\n",
            "TRAINING - Epoch: [60][40/97]\tTime 0.150 (0.212)\tData 0.000 (0.034)\tLoss 0.2049 (0.2360)\tPrec@1 93.164 (91.559)\tPrec@5 100.000 (99.843)\t\n",
            "TRAINING - Epoch: [60][50/97]\tTime 0.190 (0.202)\tData 0.000 (0.027)\tLoss 0.2535 (0.2393)\tPrec@1 91.016 (91.429)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [60][60/97]\tTime 0.153 (0.196)\tData 0.000 (0.023)\tLoss 0.1673 (0.2405)\tPrec@1 94.727 (91.384)\tPrec@5 100.000 (99.837)\t\n",
            "TRAINING - Epoch: [60][70/97]\tTime 0.159 (0.191)\tData 0.000 (0.020)\tLoss 0.2629 (0.2405)\tPrec@1 91.016 (91.392)\tPrec@5 99.805 (99.838)\t\n",
            "TRAINING - Epoch: [60][80/97]\tTime 0.167 (0.187)\tData 0.000 (0.018)\tLoss 0.2789 (0.2418)\tPrec@1 91.016 (91.339)\tPrec@5 99.609 (99.838)\t\n",
            "TRAINING - Epoch: [60][90/97]\tTime 0.150 (0.183)\tData 0.000 (0.016)\tLoss 0.1674 (0.2432)\tPrec@1 94.336 (91.338)\tPrec@5 100.000 (99.835)\t\n",
            "EVALUATING - Epoch: [60][0/20]\tTime 1.003 (1.003)\tData 0.957 (0.957)\tLoss 0.5001 (0.5001)\tPrec@1 83.594 (83.594)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [60][10/20]\tTime 0.045 (0.197)\tData 0.000 (0.147)\tLoss 0.5587 (0.5692)\tPrec@1 84.766 (83.487)\tPrec@5 99.219 (99.361)\t\n",
            "\n",
            "Results - Epoch: 61\n",
            "Training Loss 0.2442 \tTraining Prec@1 91.277 \tTraining Prec@5 99.831 \tValidation Loss 0.5741 \tValidation Prec@1 83.410 \tValidation Prec@5 99.400 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 62\n",
            "\n",
            "TRAINING - Epoch: [61][0/97]\tTime 1.190 (1.190)\tData 0.937 (0.937)\tLoss 0.2130 (0.2130)\tPrec@1 92.578 (92.578)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [61][10/97]\tTime 0.162 (0.341)\tData 0.000 (0.094)\tLoss 0.2237 (0.2130)\tPrec@1 92.773 (92.667)\tPrec@5 99.805 (99.840)\t\n",
            "TRAINING - Epoch: [61][20/97]\tTime 0.155 (0.254)\tData 0.000 (0.050)\tLoss 0.2374 (0.2235)\tPrec@1 90.820 (92.215)\tPrec@5 100.000 (99.823)\t\n",
            "TRAINING - Epoch: [61][30/97]\tTime 0.204 (0.226)\tData 0.002 (0.034)\tLoss 0.2374 (0.2315)\tPrec@1 91.992 (91.872)\tPrec@5 99.609 (99.811)\t\n",
            "TRAINING - Epoch: [61][40/97]\tTime 0.157 (0.211)\tData 0.000 (0.027)\tLoss 0.2461 (0.2355)\tPrec@1 91.797 (91.721)\tPrec@5 99.609 (99.776)\t\n",
            "TRAINING - Epoch: [61][50/97]\tTime 0.153 (0.201)\tData 0.000 (0.022)\tLoss 0.1836 (0.2365)\tPrec@1 93.750 (91.678)\tPrec@5 99.805 (99.801)\t\n",
            "TRAINING - Epoch: [61][60/97]\tTime 0.154 (0.195)\tData 0.000 (0.018)\tLoss 0.2417 (0.2397)\tPrec@1 91.406 (91.489)\tPrec@5 99.609 (99.808)\t\n",
            "TRAINING - Epoch: [61][70/97]\tTime 0.151 (0.190)\tData 0.000 (0.016)\tLoss 0.2714 (0.2384)\tPrec@1 91.211 (91.566)\tPrec@5 99.609 (99.824)\t\n",
            "TRAINING - Epoch: [61][80/97]\tTime 0.163 (0.187)\tData 0.000 (0.014)\tLoss 0.2631 (0.2396)\tPrec@1 90.430 (91.532)\tPrec@5 100.000 (99.819)\t\n",
            "TRAINING - Epoch: [61][90/97]\tTime 0.149 (0.183)\tData 0.000 (0.013)\tLoss 0.2565 (0.2416)\tPrec@1 91.992 (91.458)\tPrec@5 99.609 (99.822)\t\n",
            "EVALUATING - Epoch: [61][0/20]\tTime 1.037 (1.037)\tData 0.985 (0.985)\tLoss 0.5306 (0.5306)\tPrec@1 81.250 (81.250)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [61][10/20]\tTime 0.060 (0.195)\tData 0.000 (0.140)\tLoss 0.5601 (0.5287)\tPrec@1 83.984 (83.825)\tPrec@5 99.219 (99.450)\t\n",
            "\n",
            "Results - Epoch: 62\n",
            "Training Loss 0.2428 \tTraining Prec@1 91.410 \tTraining Prec@5 99.831 \tValidation Loss 0.5343 \tValidation Prec@1 83.830 \tValidation Prec@5 99.450 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 63\n",
            "\n",
            "TRAINING - Epoch: [62][0/97]\tTime 1.502 (1.502)\tData 1.201 (1.201)\tLoss 0.2397 (0.2397)\tPrec@1 91.211 (91.211)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [62][10/97]\tTime 0.191 (0.338)\tData 0.000 (0.112)\tLoss 0.2045 (0.2250)\tPrec@1 93.555 (92.383)\tPrec@5 99.805 (99.876)\t\n",
            "TRAINING - Epoch: [62][20/97]\tTime 0.165 (0.256)\tData 0.000 (0.060)\tLoss 0.2311 (0.2277)\tPrec@1 91.602 (92.206)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [62][30/97]\tTime 0.164 (0.227)\tData 0.004 (0.041)\tLoss 0.2196 (0.2321)\tPrec@1 91.602 (91.891)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [62][40/97]\tTime 0.159 (0.211)\tData 0.000 (0.031)\tLoss 0.2327 (0.2342)\tPrec@1 92.969 (91.778)\tPrec@5 99.609 (99.871)\t\n",
            "TRAINING - Epoch: [62][50/97]\tTime 0.177 (0.201)\tData 0.000 (0.025)\tLoss 0.2621 (0.2339)\tPrec@1 90.234 (91.793)\tPrec@5 99.609 (99.862)\t\n",
            "TRAINING - Epoch: [62][60/97]\tTime 0.155 (0.195)\tData 0.005 (0.021)\tLoss 0.2277 (0.2360)\tPrec@1 92.188 (91.666)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [62][70/97]\tTime 0.156 (0.190)\tData 0.000 (0.019)\tLoss 0.2194 (0.2373)\tPrec@1 92.383 (91.643)\tPrec@5 99.805 (99.876)\t\n",
            "TRAINING - Epoch: [62][80/97]\tTime 0.153 (0.186)\tData 0.000 (0.017)\tLoss 0.2766 (0.2364)\tPrec@1 90.234 (91.664)\tPrec@5 100.000 (99.875)\t\n",
            "TRAINING - Epoch: [62][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.015)\tLoss 0.2400 (0.2391)\tPrec@1 93.164 (91.569)\tPrec@5 99.805 (99.876)\t\n",
            "EVALUATING - Epoch: [62][0/20]\tTime 1.183 (1.183)\tData 1.131 (1.131)\tLoss 0.3947 (0.3947)\tPrec@1 84.375 (84.375)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [62][10/20]\tTime 0.052 (0.194)\tData 0.000 (0.134)\tLoss 0.4316 (0.4570)\tPrec@1 88.086 (85.707)\tPrec@5 98.828 (99.379)\t\n",
            "\n",
            "Results - Epoch: 63\n",
            "Training Loss 0.2378 \tTraining Prec@1 91.630 \tTraining Prec@5 99.875 \tValidation Loss 0.4546 \tValidation Prec@1 85.870 \tValidation Prec@5 99.450 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 64\n",
            "\n",
            "TRAINING - Epoch: [63][0/97]\tTime 1.507 (1.507)\tData 1.259 (1.259)\tLoss 0.2445 (0.2445)\tPrec@1 92.383 (92.383)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [63][10/97]\tTime 0.184 (0.333)\tData 0.000 (0.118)\tLoss 0.2043 (0.2229)\tPrec@1 92.969 (92.134)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [63][20/97]\tTime 0.176 (0.255)\tData 0.000 (0.063)\tLoss 0.1733 (0.2177)\tPrec@1 93.750 (92.374)\tPrec@5 100.000 (99.907)\t\n",
            "TRAINING - Epoch: [63][30/97]\tTime 0.159 (0.225)\tData 0.000 (0.043)\tLoss 0.2112 (0.2232)\tPrec@1 93.945 (92.074)\tPrec@5 100.000 (99.899)\t\n",
            "TRAINING - Epoch: [63][40/97]\tTime 0.171 (0.209)\tData 0.000 (0.033)\tLoss 0.2658 (0.2253)\tPrec@1 91.211 (92.006)\tPrec@5 100.000 (99.881)\t\n",
            "TRAINING - Epoch: [63][50/97]\tTime 0.147 (0.200)\tData 0.000 (0.026)\tLoss 0.2085 (0.2262)\tPrec@1 92.969 (91.931)\tPrec@5 100.000 (99.889)\t\n",
            "TRAINING - Epoch: [63][60/97]\tTime 0.160 (0.193)\tData 0.000 (0.022)\tLoss 0.3052 (0.2297)\tPrec@1 91.016 (91.842)\tPrec@5 99.219 (99.875)\t\n",
            "TRAINING - Epoch: [63][70/97]\tTime 0.156 (0.189)\tData 0.000 (0.019)\tLoss 0.2613 (0.2307)\tPrec@1 90.820 (91.783)\tPrec@5 99.805 (99.873)\t\n",
            "TRAINING - Epoch: [63][80/97]\tTime 0.189 (0.186)\tData 0.005 (0.017)\tLoss 0.2313 (0.2328)\tPrec@1 92.383 (91.717)\tPrec@5 99.805 (99.863)\t\n",
            "TRAINING - Epoch: [63][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.015)\tLoss 0.2152 (0.2308)\tPrec@1 92.383 (91.801)\tPrec@5 100.000 (99.869)\t\n",
            "EVALUATING - Epoch: [63][0/20]\tTime 1.049 (1.049)\tData 0.977 (0.977)\tLoss 0.4539 (0.4539)\tPrec@1 83.984 (83.984)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [63][10/20]\tTime 0.047 (0.196)\tData 0.000 (0.140)\tLoss 0.5627 (0.5309)\tPrec@1 82.422 (84.109)\tPrec@5 99.219 (99.165)\t\n",
            "\n",
            "Results - Epoch: 64\n",
            "Training Loss 0.2309 \tTraining Prec@1 91.785 \tTraining Prec@5 99.873 \tValidation Loss 0.5378 \tValidation Prec@1 83.960 \tValidation Prec@5 99.170 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 65\n",
            "\n",
            "TRAINING - Epoch: [64][0/97]\tTime 1.375 (1.375)\tData 1.097 (1.097)\tLoss 0.2132 (0.2132)\tPrec@1 92.969 (92.969)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [64][10/97]\tTime 0.147 (0.337)\tData 0.000 (0.105)\tLoss 0.2080 (0.2015)\tPrec@1 92.578 (92.809)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [64][20/97]\tTime 0.168 (0.256)\tData 0.000 (0.056)\tLoss 0.1905 (0.2126)\tPrec@1 93.750 (92.615)\tPrec@5 99.805 (99.888)\t\n",
            "TRAINING - Epoch: [64][30/97]\tTime 0.189 (0.226)\tData 0.000 (0.038)\tLoss 0.2318 (0.2196)\tPrec@1 91.016 (92.156)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [64][40/97]\tTime 0.148 (0.209)\tData 0.000 (0.029)\tLoss 0.2278 (0.2229)\tPrec@1 91.797 (92.097)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [64][50/97]\tTime 0.150 (0.200)\tData 0.000 (0.024)\tLoss 0.2259 (0.2249)\tPrec@1 92.188 (91.977)\tPrec@5 100.000 (99.858)\t\n",
            "TRAINING - Epoch: [64][60/97]\tTime 0.150 (0.193)\tData 0.000 (0.020)\tLoss 0.1774 (0.2253)\tPrec@1 92.773 (91.973)\tPrec@5 100.000 (99.856)\t\n",
            "TRAINING - Epoch: [64][70/97]\tTime 0.150 (0.189)\tData 0.000 (0.017)\tLoss 0.2135 (0.2246)\tPrec@1 92.383 (92.017)\tPrec@5 100.000 (99.862)\t\n",
            "TRAINING - Epoch: [64][80/97]\tTime 0.155 (0.185)\tData 0.000 (0.015)\tLoss 0.1422 (0.2263)\tPrec@1 96.484 (91.932)\tPrec@5 99.805 (99.853)\t\n",
            "TRAINING - Epoch: [64][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.014)\tLoss 0.2409 (0.2270)\tPrec@1 92.383 (91.913)\tPrec@5 100.000 (99.854)\t\n",
            "EVALUATING - Epoch: [64][0/20]\tTime 1.046 (1.046)\tData 0.985 (0.985)\tLoss 0.6193 (0.6193)\tPrec@1 81.836 (81.836)\tPrec@5 99.023 (99.023)\t\n",
            "EVALUATING - Epoch: [64][10/20]\tTime 0.050 (0.194)\tData 0.000 (0.141)\tLoss 0.5939 (0.6347)\tPrec@1 84.766 (82.546)\tPrec@5 99.023 (98.828)\t\n",
            "\n",
            "Results - Epoch: 65\n",
            "Training Loss 0.2273 \tTraining Prec@1 91.877 \tTraining Prec@5 99.859 \tValidation Loss 0.6296 \tValidation Prec@1 82.610 \tValidation Prec@5 98.840 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 66\n",
            "\n",
            "TRAINING - Epoch: [65][0/97]\tTime 1.412 (1.412)\tData 1.122 (1.122)\tLoss 0.2300 (0.2300)\tPrec@1 91.406 (91.406)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [65][10/97]\tTime 0.198 (0.340)\tData 0.005 (0.108)\tLoss 0.2476 (0.2349)\tPrec@1 91.016 (91.602)\tPrec@5 99.805 (99.893)\t\n",
            "TRAINING - Epoch: [65][20/97]\tTime 0.165 (0.255)\tData 0.003 (0.057)\tLoss 0.2285 (0.2242)\tPrec@1 91.602 (92.076)\tPrec@5 100.000 (99.898)\t\n",
            "TRAINING - Epoch: [65][30/97]\tTime 0.155 (0.224)\tData 0.000 (0.039)\tLoss 0.2181 (0.2241)\tPrec@1 94.727 (92.112)\tPrec@5 99.805 (99.899)\t\n",
            "TRAINING - Epoch: [65][40/97]\tTime 0.154 (0.209)\tData 0.000 (0.029)\tLoss 0.2481 (0.2227)\tPrec@1 90.430 (92.178)\tPrec@5 99.805 (99.890)\t\n",
            "TRAINING - Epoch: [65][50/97]\tTime 0.155 (0.201)\tData 0.000 (0.024)\tLoss 0.2470 (0.2211)\tPrec@1 90.430 (92.260)\tPrec@5 99.805 (99.881)\t\n",
            "TRAINING - Epoch: [65][60/97]\tTime 0.161 (0.194)\tData 0.000 (0.020)\tLoss 0.2508 (0.2237)\tPrec@1 91.992 (92.123)\tPrec@5 100.000 (99.891)\t\n",
            "TRAINING - Epoch: [65][70/97]\tTime 0.151 (0.190)\tData 0.000 (0.018)\tLoss 0.1738 (0.2237)\tPrec@1 93.945 (92.091)\tPrec@5 99.805 (99.884)\t\n",
            "TRAINING - Epoch: [65][80/97]\tTime 0.155 (0.186)\tData 0.000 (0.016)\tLoss 0.2259 (0.2273)\tPrec@1 91.211 (91.944)\tPrec@5 100.000 (99.889)\t\n",
            "TRAINING - Epoch: [65][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.014)\tLoss 0.2653 (0.2318)\tPrec@1 90.820 (91.793)\tPrec@5 99.805 (99.888)\t\n",
            "EVALUATING - Epoch: [65][0/20]\tTime 1.180 (1.180)\tData 1.130 (1.130)\tLoss 0.4897 (0.4897)\tPrec@1 82.812 (82.812)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [65][10/20]\tTime 0.053 (0.198)\tData 0.000 (0.142)\tLoss 0.4837 (0.5091)\tPrec@1 86.328 (85.281)\tPrec@5 99.219 (99.432)\t\n",
            "\n",
            "Results - Epoch: 66\n",
            "Training Loss 0.2333 \tTraining Prec@1 91.747 \tTraining Prec@5 99.879 \tValidation Loss 0.5168 \tValidation Prec@1 84.830 \tValidation Prec@5 99.420 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 67\n",
            "\n",
            "TRAINING - Epoch: [66][0/97]\tTime 1.242 (1.242)\tData 0.990 (0.990)\tLoss 0.2691 (0.2691)\tPrec@1 91.016 (91.016)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [66][10/97]\tTime 0.170 (0.338)\tData 0.004 (0.093)\tLoss 0.2441 (0.2193)\tPrec@1 91.406 (92.383)\tPrec@5 99.805 (99.858)\t\n",
            "TRAINING - Epoch: [66][20/97]\tTime 0.154 (0.255)\tData 0.000 (0.049)\tLoss 0.2208 (0.2153)\tPrec@1 91.992 (92.448)\tPrec@5 100.000 (99.860)\t\n",
            "TRAINING - Epoch: [66][30/97]\tTime 0.156 (0.225)\tData 0.000 (0.034)\tLoss 0.2289 (0.2178)\tPrec@1 92.969 (92.295)\tPrec@5 100.000 (99.874)\t\n",
            "TRAINING - Epoch: [66][40/97]\tTime 0.152 (0.209)\tData 0.005 (0.026)\tLoss 0.2130 (0.2186)\tPrec@1 91.992 (92.283)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [66][50/97]\tTime 0.156 (0.200)\tData 0.000 (0.021)\tLoss 0.2257 (0.2214)\tPrec@1 91.797 (92.168)\tPrec@5 99.805 (99.877)\t\n",
            "TRAINING - Epoch: [66][60/97]\tTime 0.148 (0.194)\tData 0.000 (0.018)\tLoss 0.1910 (0.2212)\tPrec@1 93.359 (92.255)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [66][70/97]\tTime 0.192 (0.190)\tData 0.000 (0.016)\tLoss 0.2315 (0.2235)\tPrec@1 92.578 (92.149)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [66][80/97]\tTime 0.167 (0.186)\tData 0.000 (0.014)\tLoss 0.2114 (0.2253)\tPrec@1 93.359 (92.089)\tPrec@5 99.609 (99.877)\t\n",
            "TRAINING - Epoch: [66][90/97]\tTime 0.151 (0.182)\tData 0.000 (0.012)\tLoss 0.1645 (0.2258)\tPrec@1 92.969 (92.046)\tPrec@5 100.000 (99.871)\t\n",
            "EVALUATING - Epoch: [66][0/20]\tTime 1.117 (1.117)\tData 1.071 (1.071)\tLoss 0.4763 (0.4763)\tPrec@1 82.422 (82.422)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [66][10/20]\tTime 0.055 (0.192)\tData 0.000 (0.136)\tLoss 0.4726 (0.5346)\tPrec@1 85.938 (84.499)\tPrec@5 99.609 (99.450)\t\n",
            "\n",
            "Results - Epoch: 67\n",
            "Training Loss 0.2264 \tTraining Prec@1 92.028 \tTraining Prec@5 99.871 \tValidation Loss 0.5342 \tValidation Prec@1 84.540 \tValidation Prec@5 99.470 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 68\n",
            "\n",
            "TRAINING - Epoch: [67][0/97]\tTime 1.505 (1.505)\tData 1.240 (1.240)\tLoss 0.2132 (0.2132)\tPrec@1 93.359 (93.359)\tPrec@5 99.414 (99.414)\t\n",
            "TRAINING - Epoch: [67][10/97]\tTime 0.154 (0.340)\tData 0.000 (0.117)\tLoss 0.2688 (0.2119)\tPrec@1 89.648 (92.507)\tPrec@5 99.609 (99.840)\t\n",
            "TRAINING - Epoch: [67][20/97]\tTime 0.151 (0.254)\tData 0.000 (0.062)\tLoss 0.2436 (0.2186)\tPrec@1 91.211 (92.215)\tPrec@5 99.805 (99.833)\t\n",
            "TRAINING - Epoch: [67][30/97]\tTime 0.160 (0.224)\tData 0.000 (0.042)\tLoss 0.1884 (0.2150)\tPrec@1 94.141 (92.251)\tPrec@5 99.805 (99.861)\t\n",
            "TRAINING - Epoch: [67][40/97]\tTime 0.159 (0.209)\tData 0.000 (0.032)\tLoss 0.3038 (0.2214)\tPrec@1 89.062 (91.964)\tPrec@5 99.805 (99.862)\t\n",
            "TRAINING - Epoch: [67][50/97]\tTime 0.160 (0.199)\tData 0.000 (0.026)\tLoss 0.2308 (0.2207)\tPrec@1 91.797 (92.000)\tPrec@5 99.805 (99.866)\t\n",
            "TRAINING - Epoch: [67][60/97]\tTime 0.165 (0.193)\tData 0.000 (0.022)\tLoss 0.1707 (0.2220)\tPrec@1 92.969 (91.970)\tPrec@5 100.000 (99.878)\t\n",
            "TRAINING - Epoch: [67][70/97]\tTime 0.152 (0.188)\tData 0.000 (0.019)\tLoss 0.2933 (0.2246)\tPrec@1 88.672 (91.868)\tPrec@5 100.000 (99.873)\t\n",
            "TRAINING - Epoch: [67][80/97]\tTime 0.150 (0.185)\tData 0.000 (0.017)\tLoss 0.2224 (0.2248)\tPrec@1 91.602 (91.879)\tPrec@5 99.805 (99.877)\t\n",
            "TRAINING - Epoch: [67][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.015)\tLoss 0.2091 (0.2251)\tPrec@1 92.188 (91.908)\tPrec@5 99.805 (99.876)\t\n",
            "EVALUATING - Epoch: [67][0/20]\tTime 1.352 (1.352)\tData 1.290 (1.290)\tLoss 0.4701 (0.4701)\tPrec@1 83.789 (83.789)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [67][10/20]\tTime 0.051 (0.206)\tData 0.000 (0.151)\tLoss 0.5034 (0.5207)\tPrec@1 83.594 (84.109)\tPrec@5 99.414 (99.379)\t\n",
            "\n",
            "Results - Epoch: 68\n",
            "Training Loss 0.2256 \tTraining Prec@1 91.954 \tTraining Prec@5 99.875 \tValidation Loss 0.5185 \tValidation Prec@1 84.460 \tValidation Prec@5 99.440 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 69\n",
            "\n",
            "TRAINING - Epoch: [68][0/97]\tTime 1.522 (1.522)\tData 1.209 (1.209)\tLoss 0.1792 (0.1792)\tPrec@1 93.164 (93.164)\tPrec@5 99.609 (99.609)\t\n",
            "TRAINING - Epoch: [68][10/97]\tTime 0.148 (0.343)\tData 0.000 (0.112)\tLoss 0.2264 (0.2178)\tPrec@1 92.578 (92.383)\tPrec@5 99.805 (99.769)\t\n",
            "TRAINING - Epoch: [68][20/97]\tTime 0.165 (0.259)\tData 0.000 (0.060)\tLoss 0.2774 (0.2276)\tPrec@1 90.430 (91.983)\tPrec@5 100.000 (99.814)\t\n",
            "TRAINING - Epoch: [68][30/97]\tTime 0.183 (0.229)\tData 0.000 (0.041)\tLoss 0.2488 (0.2257)\tPrec@1 91.016 (92.017)\tPrec@5 100.000 (99.830)\t\n",
            "TRAINING - Epoch: [68][40/97]\tTime 0.156 (0.213)\tData 0.000 (0.031)\tLoss 0.2850 (0.2266)\tPrec@1 90.430 (91.983)\tPrec@5 99.805 (99.838)\t\n",
            "TRAINING - Epoch: [68][50/97]\tTime 0.174 (0.203)\tData 0.000 (0.025)\tLoss 0.2490 (0.2267)\tPrec@1 91.406 (91.954)\tPrec@5 99.805 (99.847)\t\n",
            "TRAINING - Epoch: [68][60/97]\tTime 0.161 (0.197)\tData 0.000 (0.022)\tLoss 0.2374 (0.2258)\tPrec@1 90.430 (91.979)\tPrec@5 99.609 (99.853)\t\n",
            "TRAINING - Epoch: [68][70/97]\tTime 0.157 (0.192)\tData 0.000 (0.019)\tLoss 0.1606 (0.2237)\tPrec@1 94.531 (92.009)\tPrec@5 99.805 (99.854)\t\n",
            "TRAINING - Epoch: [68][80/97]\tTime 0.169 (0.188)\tData 0.000 (0.016)\tLoss 0.1946 (0.2234)\tPrec@1 93.555 (92.036)\tPrec@5 100.000 (99.863)\t\n",
            "TRAINING - Epoch: [68][90/97]\tTime 0.150 (0.184)\tData 0.000 (0.015)\tLoss 0.2442 (0.2239)\tPrec@1 91.406 (91.988)\tPrec@5 99.805 (99.863)\t\n",
            "EVALUATING - Epoch: [68][0/20]\tTime 1.122 (1.122)\tData 1.078 (1.078)\tLoss 0.3316 (0.3316)\tPrec@1 88.477 (88.477)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [68][10/20]\tTime 0.056 (0.198)\tData 0.000 (0.144)\tLoss 0.4669 (0.4437)\tPrec@1 85.352 (86.541)\tPrec@5 99.414 (99.485)\t\n",
            "\n",
            "Results - Epoch: 69\n",
            "Training Loss 0.2247 \tTraining Prec@1 91.974 \tTraining Prec@5 99.857 \tValidation Loss 0.4491 \tValidation Prec@1 86.280 \tValidation Prec@5 99.430 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 70\n",
            "\n",
            "TRAINING - Epoch: [69][0/97]\tTime 1.428 (1.428)\tData 1.145 (1.145)\tLoss 0.2140 (0.2140)\tPrec@1 92.383 (92.383)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [69][10/97]\tTime 0.176 (0.338)\tData 0.005 (0.110)\tLoss 0.1945 (0.2022)\tPrec@1 93.750 (92.898)\tPrec@5 99.805 (99.858)\t\n",
            "TRAINING - Epoch: [69][20/97]\tTime 0.160 (0.252)\tData 0.000 (0.058)\tLoss 0.2523 (0.2038)\tPrec@1 90.820 (92.671)\tPrec@5 99.609 (99.879)\t\n",
            "TRAINING - Epoch: [69][30/97]\tTime 0.174 (0.224)\tData 0.000 (0.039)\tLoss 0.2263 (0.2040)\tPrec@1 90.625 (92.773)\tPrec@5 99.805 (99.861)\t\n",
            "TRAINING - Epoch: [69][40/97]\tTime 0.168 (0.208)\tData 0.000 (0.030)\tLoss 0.2530 (0.2081)\tPrec@1 91.211 (92.564)\tPrec@5 99.805 (99.867)\t\n",
            "TRAINING - Epoch: [69][50/97]\tTime 0.180 (0.200)\tData 0.000 (0.024)\tLoss 0.2020 (0.2094)\tPrec@1 94.727 (92.605)\tPrec@5 99.805 (99.877)\t\n",
            "TRAINING - Epoch: [69][60/97]\tTime 0.184 (0.193)\tData 0.000 (0.021)\tLoss 0.2225 (0.2102)\tPrec@1 91.602 (92.565)\tPrec@5 100.000 (99.866)\t\n",
            "TRAINING - Epoch: [69][70/97]\tTime 0.161 (0.189)\tData 0.000 (0.018)\tLoss 0.2690 (0.2128)\tPrec@1 91.016 (92.432)\tPrec@5 100.000 (99.873)\t\n",
            "TRAINING - Epoch: [69][80/97]\tTime 0.150 (0.185)\tData 0.000 (0.016)\tLoss 0.2532 (0.2137)\tPrec@1 91.211 (92.426)\tPrec@5 99.414 (99.870)\t\n",
            "TRAINING - Epoch: [69][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.014)\tLoss 0.2231 (0.2143)\tPrec@1 92.578 (92.404)\tPrec@5 99.609 (99.865)\t\n",
            "EVALUATING - Epoch: [69][0/20]\tTime 1.006 (1.006)\tData 0.958 (0.958)\tLoss 0.5168 (0.5168)\tPrec@1 84.180 (84.180)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [69][10/20]\tTime 0.043 (0.194)\tData 0.000 (0.142)\tLoss 0.6146 (0.5896)\tPrec@1 83.008 (83.487)\tPrec@5 99.023 (99.112)\t\n",
            "\n",
            "Results - Epoch: 70\n",
            "Training Loss 0.2154 \tTraining Prec@1 92.371 \tTraining Prec@5 99.867 \tValidation Loss 0.5874 \tValidation Prec@1 83.610 \tValidation Prec@5 99.090 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 71\n",
            "\n",
            "TRAINING - Epoch: [70][0/97]\tTime 1.350 (1.350)\tData 1.073 (1.073)\tLoss 0.2304 (0.2304)\tPrec@1 91.211 (91.211)\tPrec@5 99.805 (99.805)\t\n",
            "TRAINING - Epoch: [70][10/97]\tTime 0.164 (0.339)\tData 0.001 (0.102)\tLoss 0.2582 (0.2308)\tPrec@1 91.797 (92.099)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [70][20/97]\tTime 0.179 (0.255)\tData 0.005 (0.054)\tLoss 0.1445 (0.2159)\tPrec@1 95.312 (92.587)\tPrec@5 100.000 (99.879)\t\n",
            "TRAINING - Epoch: [70][30/97]\tTime 0.157 (0.225)\tData 0.000 (0.037)\tLoss 0.2091 (0.2128)\tPrec@1 92.383 (92.647)\tPrec@5 100.000 (99.880)\t\n",
            "TRAINING - Epoch: [70][40/97]\tTime 0.193 (0.211)\tData 0.000 (0.028)\tLoss 0.2044 (0.2090)\tPrec@1 91.602 (92.697)\tPrec@5 100.000 (99.895)\t\n",
            "TRAINING - Epoch: [70][50/97]\tTime 0.160 (0.201)\tData 0.000 (0.023)\tLoss 0.2168 (0.2097)\tPrec@1 92.969 (92.662)\tPrec@5 99.805 (99.885)\t\n",
            "TRAINING - Epoch: [70][60/97]\tTime 0.150 (0.194)\tData 0.000 (0.019)\tLoss 0.1913 (0.2122)\tPrec@1 92.773 (92.591)\tPrec@5 99.805 (99.888)\t\n",
            "TRAINING - Epoch: [70][70/97]\tTime 0.155 (0.190)\tData 0.000 (0.017)\tLoss 0.2196 (0.2125)\tPrec@1 91.992 (92.570)\tPrec@5 99.609 (99.890)\t\n",
            "TRAINING - Epoch: [70][80/97]\tTime 0.147 (0.186)\tData 0.000 (0.015)\tLoss 0.2253 (0.2135)\tPrec@1 92.578 (92.513)\tPrec@5 99.805 (99.887)\t\n",
            "TRAINING - Epoch: [70][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.013)\tLoss 0.2039 (0.2134)\tPrec@1 91.992 (92.449)\tPrec@5 100.000 (99.888)\t\n",
            "EVALUATING - Epoch: [70][0/20]\tTime 0.937 (0.937)\tData 0.890 (0.890)\tLoss 0.5709 (0.5709)\tPrec@1 83.008 (83.008)\tPrec@5 99.414 (99.414)\t\n",
            "EVALUATING - Epoch: [70][10/20]\tTime 0.047 (0.177)\tData 0.000 (0.122)\tLoss 0.5103 (0.5440)\tPrec@1 84.570 (84.322)\tPrec@5 99.414 (99.450)\t\n",
            "\n",
            "Results - Epoch: 71\n",
            "Training Loss 0.2148 \tTraining Prec@1 92.403 \tTraining Prec@5 99.889 \tValidation Loss 0.5354 \tValidation Prec@1 84.390 \tValidation Prec@5 99.440 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 72\n",
            "\n",
            "TRAINING - Epoch: [71][0/97]\tTime 1.212 (1.212)\tData 0.944 (0.944)\tLoss 0.1772 (0.1772)\tPrec@1 94.336 (94.336)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [71][10/97]\tTime 0.179 (0.333)\tData 0.007 (0.089)\tLoss 0.2263 (0.2034)\tPrec@1 93.359 (92.933)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [71][20/97]\tTime 0.147 (0.250)\tData 0.000 (0.047)\tLoss 0.1756 (0.2035)\tPrec@1 93.359 (92.857)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [71][30/97]\tTime 0.169 (0.221)\tData 0.000 (0.032)\tLoss 0.2138 (0.2050)\tPrec@1 91.992 (92.666)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [71][40/97]\tTime 0.161 (0.206)\tData 0.000 (0.024)\tLoss 0.2299 (0.2111)\tPrec@1 90.430 (92.321)\tPrec@5 99.805 (99.871)\t\n",
            "TRAINING - Epoch: [71][50/97]\tTime 0.170 (0.197)\tData 0.000 (0.020)\tLoss 0.2210 (0.2144)\tPrec@1 93.359 (92.310)\tPrec@5 99.805 (99.858)\t\n",
            "TRAINING - Epoch: [71][60/97]\tTime 0.153 (0.191)\tData 0.000 (0.017)\tLoss 0.2094 (0.2153)\tPrec@1 92.773 (92.328)\tPrec@5 100.000 (99.872)\t\n",
            "TRAINING - Epoch: [71][70/97]\tTime 0.157 (0.186)\tData 0.000 (0.014)\tLoss 0.2290 (0.2158)\tPrec@1 92.969 (92.325)\tPrec@5 100.000 (99.871)\t\n",
            "TRAINING - Epoch: [71][80/97]\tTime 0.168 (0.183)\tData 0.000 (0.013)\tLoss 0.2596 (0.2164)\tPrec@1 91.211 (92.298)\tPrec@5 100.000 (99.867)\t\n",
            "TRAINING - Epoch: [71][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.012)\tLoss 0.2510 (0.2179)\tPrec@1 91.992 (92.260)\tPrec@5 100.000 (99.873)\t\n",
            "EVALUATING - Epoch: [71][0/20]\tTime 1.109 (1.109)\tData 1.058 (1.058)\tLoss 0.4460 (0.4460)\tPrec@1 86.328 (86.328)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [71][10/20]\tTime 0.053 (0.195)\tData 0.000 (0.141)\tLoss 0.5609 (0.5388)\tPrec@1 84.766 (84.712)\tPrec@5 99.414 (99.201)\t\n",
            "\n",
            "Results - Epoch: 72\n",
            "Training Loss 0.2180 \tTraining Prec@1 92.244 \tTraining Prec@5 99.877 \tValidation Loss 0.5223 \tValidation Prec@1 84.940 \tValidation Prec@5 99.320 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 73\n",
            "\n",
            "TRAINING - Epoch: [72][0/97]\tTime 0.939 (0.939)\tData 0.677 (0.677)\tLoss 0.2268 (0.2268)\tPrec@1 91.602 (91.602)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [72][10/97]\tTime 0.193 (0.336)\tData 0.000 (0.094)\tLoss 0.1904 (0.2097)\tPrec@1 92.969 (92.649)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [72][20/97]\tTime 0.160 (0.253)\tData 0.000 (0.050)\tLoss 0.1910 (0.2030)\tPrec@1 92.969 (92.727)\tPrec@5 100.000 (99.926)\t\n",
            "TRAINING - Epoch: [72][30/97]\tTime 0.158 (0.224)\tData 0.000 (0.034)\tLoss 0.2487 (0.2041)\tPrec@1 91.016 (92.654)\tPrec@5 99.805 (99.912)\t\n",
            "TRAINING - Epoch: [72][40/97]\tTime 0.156 (0.208)\tData 0.000 (0.026)\tLoss 0.1916 (0.2075)\tPrec@1 92.773 (92.530)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [72][50/97]\tTime 0.160 (0.199)\tData 0.000 (0.021)\tLoss 0.2325 (0.2090)\tPrec@1 91.992 (92.440)\tPrec@5 100.000 (99.885)\t\n",
            "TRAINING - Epoch: [72][60/97]\tTime 0.161 (0.193)\tData 0.000 (0.018)\tLoss 0.2199 (0.2129)\tPrec@1 92.578 (92.332)\tPrec@5 99.609 (99.872)\t\n",
            "TRAINING - Epoch: [72][70/97]\tTime 0.150 (0.188)\tData 0.000 (0.015)\tLoss 0.2324 (0.2160)\tPrec@1 92.383 (92.229)\tPrec@5 99.609 (99.862)\t\n",
            "TRAINING - Epoch: [72][80/97]\tTime 0.163 (0.186)\tData 0.000 (0.014)\tLoss 0.1950 (0.2166)\tPrec@1 92.773 (92.224)\tPrec@5 100.000 (99.851)\t\n",
            "TRAINING - Epoch: [72][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.012)\tLoss 0.2743 (0.2199)\tPrec@1 90.625 (92.106)\tPrec@5 99.805 (99.850)\t\n",
            "EVALUATING - Epoch: [72][0/20]\tTime 1.319 (1.319)\tData 1.268 (1.268)\tLoss 0.5735 (0.5735)\tPrec@1 81.250 (81.250)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [72][10/20]\tTime 0.063 (0.198)\tData 0.019 (0.144)\tLoss 0.5485 (0.6254)\tPrec@1 84.961 (82.440)\tPrec@5 99.414 (99.201)\t\n",
            "\n",
            "Results - Epoch: 73\n",
            "Training Loss 0.2199 \tTraining Prec@1 92.155 \tTraining Prec@5 99.849 \tValidation Loss 0.6082 \tValidation Prec@1 82.420 \tValidation Prec@5 99.270 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 74\n",
            "\n",
            "TRAINING - Epoch: [73][0/97]\tTime 1.445 (1.445)\tData 1.140 (1.140)\tLoss 0.2082 (0.2082)\tPrec@1 93.359 (93.359)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [73][10/97]\tTime 0.178 (0.338)\tData 0.000 (0.107)\tLoss 0.2418 (0.1935)\tPrec@1 91.992 (93.235)\tPrec@5 99.609 (99.876)\t\n",
            "TRAINING - Epoch: [73][20/97]\tTime 0.168 (0.255)\tData 0.000 (0.056)\tLoss 0.1630 (0.1912)\tPrec@1 94.336 (93.341)\tPrec@5 99.805 (99.888)\t\n",
            "TRAINING - Epoch: [73][30/97]\tTime 0.165 (0.228)\tData 0.000 (0.038)\tLoss 0.2369 (0.1978)\tPrec@1 92.969 (93.076)\tPrec@5 99.805 (99.880)\t\n",
            "TRAINING - Epoch: [73][40/97]\tTime 0.179 (0.212)\tData 0.000 (0.029)\tLoss 0.2003 (0.1962)\tPrec@1 93.359 (93.059)\tPrec@5 100.000 (99.895)\t\n",
            "TRAINING - Epoch: [73][50/97]\tTime 0.154 (0.202)\tData 0.000 (0.024)\tLoss 0.2366 (0.1976)\tPrec@1 91.992 (93.049)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [73][60/97]\tTime 0.180 (0.196)\tData 0.000 (0.020)\tLoss 0.1840 (0.2006)\tPrec@1 93.945 (92.930)\tPrec@5 99.805 (99.901)\t\n",
            "TRAINING - Epoch: [73][70/97]\tTime 0.174 (0.192)\tData 0.000 (0.018)\tLoss 0.2341 (0.2017)\tPrec@1 91.211 (92.922)\tPrec@5 100.000 (99.890)\t\n",
            "TRAINING - Epoch: [73][80/97]\tTime 0.161 (0.188)\tData 0.000 (0.016)\tLoss 0.2743 (0.2038)\tPrec@1 89.648 (92.814)\tPrec@5 99.609 (99.887)\t\n",
            "TRAINING - Epoch: [73][90/97]\tTime 0.150 (0.184)\tData 0.000 (0.014)\tLoss 0.2146 (0.2045)\tPrec@1 92.969 (92.812)\tPrec@5 100.000 (99.882)\t\n",
            "EVALUATING - Epoch: [73][0/20]\tTime 1.021 (1.021)\tData 0.975 (0.975)\tLoss 0.4840 (0.4840)\tPrec@1 83.594 (83.594)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [73][10/20]\tTime 0.064 (0.195)\tData 0.000 (0.143)\tLoss 0.4718 (0.5136)\tPrec@1 85.938 (85.227)\tPrec@5 99.609 (99.308)\t\n",
            "\n",
            "Results - Epoch: 74\n",
            "Training Loss 0.2060 \tTraining Prec@1 92.753 \tTraining Prec@5 99.879 \tValidation Loss 0.5046 \tValidation Prec@1 85.520 \tValidation Prec@5 99.380 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 75\n",
            "\n",
            "TRAINING - Epoch: [74][0/97]\tTime 1.394 (1.394)\tData 1.080 (1.080)\tLoss 0.1961 (0.1961)\tPrec@1 93.359 (93.359)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [74][10/97]\tTime 0.212 (0.338)\tData 0.005 (0.101)\tLoss 0.2025 (0.1862)\tPrec@1 92.188 (93.501)\tPrec@5 99.805 (99.893)\t\n",
            "TRAINING - Epoch: [74][20/97]\tTime 0.160 (0.254)\tData 0.000 (0.054)\tLoss 0.1988 (0.1914)\tPrec@1 93.555 (93.313)\tPrec@5 99.805 (99.907)\t\n",
            "TRAINING - Epoch: [74][30/97]\tTime 0.154 (0.225)\tData 0.000 (0.037)\tLoss 0.1589 (0.1924)\tPrec@1 93.164 (93.145)\tPrec@5 100.000 (99.912)\t\n",
            "TRAINING - Epoch: [74][40/97]\tTime 0.182 (0.210)\tData 0.000 (0.028)\tLoss 0.2049 (0.1995)\tPrec@1 93.945 (92.926)\tPrec@5 99.805 (99.905)\t\n",
            "TRAINING - Epoch: [74][50/97]\tTime 0.147 (0.201)\tData 0.000 (0.023)\tLoss 0.2472 (0.2014)\tPrec@1 90.625 (92.785)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [74][60/97]\tTime 0.192 (0.194)\tData 0.000 (0.019)\tLoss 0.2152 (0.2047)\tPrec@1 93.945 (92.706)\tPrec@5 100.000 (99.914)\t\n",
            "TRAINING - Epoch: [74][70/97]\tTime 0.162 (0.190)\tData 0.000 (0.016)\tLoss 0.2422 (0.2074)\tPrec@1 91.992 (92.586)\tPrec@5 99.609 (99.912)\t\n",
            "TRAINING - Epoch: [74][80/97]\tTime 0.181 (0.186)\tData 0.005 (0.015)\tLoss 0.2314 (0.2090)\tPrec@1 91.406 (92.549)\tPrec@5 100.000 (99.913)\t\n",
            "TRAINING - Epoch: [74][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.013)\tLoss 0.2168 (0.2119)\tPrec@1 92.188 (92.484)\tPrec@5 100.000 (99.908)\t\n",
            "EVALUATING - Epoch: [74][0/20]\tTime 1.066 (1.066)\tData 1.011 (1.011)\tLoss 0.5636 (0.5636)\tPrec@1 83.594 (83.594)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [74][10/20]\tTime 0.046 (0.187)\tData 0.000 (0.137)\tLoss 0.5091 (0.5691)\tPrec@1 83.008 (83.842)\tPrec@5 99.609 (99.254)\t\n",
            "\n",
            "Results - Epoch: 75\n",
            "Training Loss 0.2121 \tTraining Prec@1 92.508 \tTraining Prec@5 99.905 \tValidation Loss 0.5624 \tValidation Prec@1 83.880 \tValidation Prec@5 99.340 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 76\n",
            "\n",
            "TRAINING - Epoch: [75][0/97]\tTime 1.565 (1.565)\tData 1.259 (1.259)\tLoss 0.2142 (0.2142)\tPrec@1 92.188 (92.188)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [75][10/97]\tTime 0.149 (0.345)\tData 0.000 (0.118)\tLoss 0.2087 (0.2112)\tPrec@1 92.188 (92.347)\tPrec@5 99.609 (99.947)\t\n",
            "TRAINING - Epoch: [75][20/97]\tTime 0.173 (0.258)\tData 0.000 (0.062)\tLoss 0.1893 (0.2004)\tPrec@1 93.945 (93.015)\tPrec@5 99.805 (99.944)\t\n",
            "TRAINING - Epoch: [75][30/97]\tTime 0.159 (0.227)\tData 0.000 (0.043)\tLoss 0.2155 (0.2052)\tPrec@1 92.969 (92.786)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [75][40/97]\tTime 0.155 (0.211)\tData 0.005 (0.033)\tLoss 0.2290 (0.2029)\tPrec@1 92.578 (92.854)\tPrec@5 99.609 (99.919)\t\n",
            "TRAINING - Epoch: [75][50/97]\tTime 0.150 (0.201)\tData 0.000 (0.027)\tLoss 0.1619 (0.2031)\tPrec@1 94.141 (92.800)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [75][60/97]\tTime 0.149 (0.194)\tData 0.000 (0.023)\tLoss 0.2538 (0.2028)\tPrec@1 91.406 (92.725)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [75][70/97]\tTime 0.168 (0.190)\tData 0.000 (0.020)\tLoss 0.2242 (0.2025)\tPrec@1 92.383 (92.749)\tPrec@5 99.609 (99.895)\t\n",
            "TRAINING - Epoch: [75][80/97]\tTime 0.149 (0.187)\tData 0.000 (0.018)\tLoss 0.2253 (0.2033)\tPrec@1 91.211 (92.737)\tPrec@5 100.000 (99.896)\t\n",
            "TRAINING - Epoch: [75][90/97]\tTime 0.152 (0.183)\tData 0.000 (0.016)\tLoss 0.2032 (0.2052)\tPrec@1 92.969 (92.660)\tPrec@5 100.000 (99.901)\t\n",
            "EVALUATING - Epoch: [75][0/20]\tTime 1.045 (1.045)\tData 0.987 (0.987)\tLoss 0.5903 (0.5903)\tPrec@1 82.617 (82.617)\tPrec@5 99.219 (99.219)\t\n",
            "EVALUATING - Epoch: [75][10/20]\tTime 0.062 (0.194)\tData 0.000 (0.139)\tLoss 0.5416 (0.5501)\tPrec@1 81.836 (84.606)\tPrec@5 98.828 (99.272)\t\n",
            "\n",
            "Results - Epoch: 76\n",
            "Training Loss 0.2068 \tTraining Prec@1 92.578 \tTraining Prec@5 99.893 \tValidation Loss 0.5485 \tValidation Prec@1 84.450 \tValidation Prec@5 99.420 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 77\n",
            "\n",
            "TRAINING - Epoch: [76][0/97]\tTime 1.504 (1.504)\tData 1.213 (1.213)\tLoss 0.2129 (0.2129)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [76][10/97]\tTime 0.148 (0.337)\tData 0.000 (0.113)\tLoss 0.1973 (0.1913)\tPrec@1 93.555 (93.288)\tPrec@5 99.805 (99.840)\t\n",
            "TRAINING - Epoch: [76][20/97]\tTime 0.182 (0.258)\tData 0.007 (0.060)\tLoss 0.1977 (0.2042)\tPrec@1 92.188 (92.801)\tPrec@5 100.000 (99.860)\t\n",
            "TRAINING - Epoch: [76][30/97]\tTime 0.158 (0.227)\tData 0.000 (0.041)\tLoss 0.2143 (0.2003)\tPrec@1 93.555 (93.051)\tPrec@5 99.609 (99.880)\t\n",
            "TRAINING - Epoch: [76][40/97]\tTime 0.165 (0.212)\tData 0.005 (0.032)\tLoss 0.2110 (0.2018)\tPrec@1 92.383 (93.031)\tPrec@5 100.000 (99.895)\t\n",
            "TRAINING - Epoch: [76][50/97]\tTime 0.150 (0.201)\tData 0.000 (0.026)\tLoss 0.1732 (0.2002)\tPrec@1 94.141 (93.064)\tPrec@5 99.805 (99.893)\t\n",
            "TRAINING - Epoch: [76][60/97]\tTime 0.146 (0.195)\tData 0.000 (0.022)\tLoss 0.1962 (0.2010)\tPrec@1 92.773 (92.982)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [76][70/97]\tTime 0.180 (0.191)\tData 0.005 (0.019)\tLoss 0.2239 (0.2015)\tPrec@1 93.359 (92.927)\tPrec@5 99.805 (99.901)\t\n",
            "TRAINING - Epoch: [76][80/97]\tTime 0.151 (0.188)\tData 0.000 (0.017)\tLoss 0.2033 (0.2019)\tPrec@1 93.359 (92.901)\tPrec@5 100.000 (99.908)\t\n",
            "TRAINING - Epoch: [76][90/97]\tTime 0.150 (0.184)\tData 0.000 (0.015)\tLoss 0.1815 (0.2016)\tPrec@1 93.945 (92.870)\tPrec@5 99.805 (99.914)\t\n",
            "EVALUATING - Epoch: [76][0/20]\tTime 1.024 (1.024)\tData 0.974 (0.974)\tLoss 0.5748 (0.5748)\tPrec@1 83.398 (83.398)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [76][10/20]\tTime 0.068 (0.195)\tData 0.000 (0.137)\tLoss 0.5051 (0.5914)\tPrec@1 84.766 (83.612)\tPrec@5 99.219 (99.094)\t\n",
            "\n",
            "Results - Epoch: 77\n",
            "Training Loss 0.2014 \tTraining Prec@1 92.870 \tTraining Prec@5 99.911 \tValidation Loss 0.5945 \tValidation Prec@1 83.160 \tValidation Prec@5 99.170 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 78\n",
            "\n",
            "TRAINING - Epoch: [77][0/97]\tTime 1.171 (1.171)\tData 0.910 (0.910)\tLoss 0.1810 (0.1810)\tPrec@1 91.797 (91.797)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [77][10/97]\tTime 0.174 (0.335)\tData 0.000 (0.092)\tLoss 0.2566 (0.1950)\tPrec@1 90.625 (92.898)\tPrec@5 100.000 (99.893)\t\n",
            "TRAINING - Epoch: [77][20/97]\tTime 0.156 (0.252)\tData 0.000 (0.049)\tLoss 0.1719 (0.1990)\tPrec@1 93.750 (92.755)\tPrec@5 99.805 (99.916)\t\n",
            "TRAINING - Epoch: [77][30/97]\tTime 0.154 (0.223)\tData 0.000 (0.033)\tLoss 0.2107 (0.1962)\tPrec@1 92.383 (92.868)\tPrec@5 100.000 (99.931)\t\n",
            "TRAINING - Epoch: [77][40/97]\tTime 0.163 (0.209)\tData 0.000 (0.025)\tLoss 0.2143 (0.1977)\tPrec@1 92.773 (92.802)\tPrec@5 99.414 (99.900)\t\n",
            "TRAINING - Epoch: [77][50/97]\tTime 0.171 (0.200)\tData 0.000 (0.021)\tLoss 0.1600 (0.1991)\tPrec@1 94.531 (92.793)\tPrec@5 100.000 (99.897)\t\n",
            "TRAINING - Epoch: [77][60/97]\tTime 0.195 (0.200)\tData 0.000 (0.018)\tLoss 0.1883 (0.1998)\tPrec@1 92.773 (92.754)\tPrec@5 100.000 (99.901)\t\n",
            "TRAINING - Epoch: [77][70/97]\tTime 0.148 (0.195)\tData 0.000 (0.016)\tLoss 0.2356 (0.2035)\tPrec@1 91.016 (92.633)\tPrec@5 100.000 (99.909)\t\n",
            "TRAINING - Epoch: [77][80/97]\tTime 0.149 (0.191)\tData 0.000 (0.014)\tLoss 0.2353 (0.2051)\tPrec@1 91.406 (92.561)\tPrec@5 99.414 (99.894)\t\n",
            "TRAINING - Epoch: [77][90/97]\tTime 0.150 (0.187)\tData 0.000 (0.012)\tLoss 0.2198 (0.2072)\tPrec@1 91.602 (92.507)\tPrec@5 100.000 (99.893)\t\n",
            "EVALUATING - Epoch: [77][0/20]\tTime 1.084 (1.084)\tData 1.031 (1.031)\tLoss 0.4322 (0.4322)\tPrec@1 86.133 (86.133)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [77][10/20]\tTime 0.062 (0.195)\tData 0.000 (0.142)\tLoss 0.4214 (0.4870)\tPrec@1 87.305 (86.346)\tPrec@5 99.414 (99.290)\t\n",
            "\n",
            "Results - Epoch: 78\n",
            "Training Loss 0.2089 \tTraining Prec@1 92.455 \tTraining Prec@5 99.891 \tValidation Loss 0.4878 \tValidation Prec@1 86.100 \tValidation Prec@5 99.340 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 79\n",
            "\n",
            "TRAINING - Epoch: [78][0/97]\tTime 1.150 (1.150)\tData 0.878 (0.878)\tLoss 0.1617 (0.1617)\tPrec@1 93.945 (93.945)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [78][10/97]\tTime 0.183 (0.334)\tData 0.000 (0.091)\tLoss 0.2168 (0.1893)\tPrec@1 91.602 (93.395)\tPrec@5 99.805 (99.947)\t\n",
            "TRAINING - Epoch: [78][20/97]\tTime 0.180 (0.255)\tData 0.000 (0.049)\tLoss 0.1782 (0.1915)\tPrec@1 94.727 (93.313)\tPrec@5 100.000 (99.935)\t\n",
            "TRAINING - Epoch: [78][30/97]\tTime 0.181 (0.235)\tData 0.000 (0.034)\tLoss 0.1860 (0.1964)\tPrec@1 93.164 (93.126)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [78][40/97]\tTime 0.175 (0.218)\tData 0.000 (0.026)\tLoss 0.2163 (0.1977)\tPrec@1 91.797 (93.097)\tPrec@5 99.805 (99.948)\t\n",
            "TRAINING - Epoch: [78][50/97]\tTime 0.153 (0.206)\tData 0.005 (0.021)\tLoss 0.2390 (0.1993)\tPrec@1 91.211 (93.015)\tPrec@5 99.805 (99.943)\t\n",
            "TRAINING - Epoch: [78][60/97]\tTime 0.151 (0.199)\tData 0.000 (0.018)\tLoss 0.2476 (0.2044)\tPrec@1 91.992 (92.821)\tPrec@5 99.609 (99.926)\t\n",
            "TRAINING - Epoch: [78][70/97]\tTime 0.210 (0.195)\tData 0.002 (0.015)\tLoss 0.1876 (0.2046)\tPrec@1 94.336 (92.831)\tPrec@5 99.805 (99.915)\t\n",
            "TRAINING - Epoch: [78][80/97]\tTime 0.160 (0.190)\tData 0.000 (0.013)\tLoss 0.2158 (0.2069)\tPrec@1 91.602 (92.740)\tPrec@5 99.805 (99.913)\t\n",
            "TRAINING - Epoch: [78][90/97]\tTime 0.150 (0.186)\tData 0.000 (0.012)\tLoss 0.2028 (0.2072)\tPrec@1 93.359 (92.658)\tPrec@5 99.805 (99.912)\t\n",
            "EVALUATING - Epoch: [78][0/20]\tTime 0.923 (0.923)\tData 0.870 (0.870)\tLoss 0.5548 (0.5548)\tPrec@1 83.203 (83.203)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [78][10/20]\tTime 0.068 (0.194)\tData 0.000 (0.139)\tLoss 0.6108 (0.6133)\tPrec@1 83.984 (83.043)\tPrec@5 99.219 (99.343)\t\n",
            "\n",
            "Results - Epoch: 79\n",
            "Training Loss 0.2079 \tTraining Prec@1 92.610 \tTraining Prec@5 99.915 \tValidation Loss 0.6134 \tValidation Prec@1 82.870 \tValidation Prec@5 99.440 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 80\n",
            "\n",
            "TRAINING - Epoch: [79][0/97]\tTime 1.449 (1.449)\tData 1.141 (1.141)\tLoss 0.1927 (0.1927)\tPrec@1 92.773 (92.773)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [79][10/97]\tTime 0.179 (0.343)\tData 0.000 (0.109)\tLoss 0.2082 (0.2006)\tPrec@1 92.773 (92.685)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [79][20/97]\tTime 0.167 (0.257)\tData 0.000 (0.057)\tLoss 0.1756 (0.1911)\tPrec@1 93.750 (93.118)\tPrec@5 100.000 (99.916)\t\n",
            "TRAINING - Epoch: [79][30/97]\tTime 0.160 (0.226)\tData 0.000 (0.039)\tLoss 0.2199 (0.1960)\tPrec@1 91.992 (92.918)\tPrec@5 99.609 (99.905)\t\n",
            "TRAINING - Epoch: [79][40/97]\tTime 0.155 (0.210)\tData 0.000 (0.030)\tLoss 0.1621 (0.1952)\tPrec@1 94.727 (93.031)\tPrec@5 100.000 (99.905)\t\n",
            "TRAINING - Epoch: [79][50/97]\tTime 0.176 (0.201)\tData 0.006 (0.024)\tLoss 0.1797 (0.1980)\tPrec@1 93.555 (92.862)\tPrec@5 100.000 (99.904)\t\n",
            "TRAINING - Epoch: [79][60/97]\tTime 0.147 (0.195)\tData 0.000 (0.020)\tLoss 0.2200 (0.1975)\tPrec@1 91.602 (92.886)\tPrec@5 99.609 (99.894)\t\n",
            "TRAINING - Epoch: [79][70/97]\tTime 0.180 (0.191)\tData 0.000 (0.018)\tLoss 0.1381 (0.1968)\tPrec@1 95.117 (92.905)\tPrec@5 100.000 (99.887)\t\n",
            "TRAINING - Epoch: [79][80/97]\tTime 0.165 (0.187)\tData 0.000 (0.016)\tLoss 0.2042 (0.1980)\tPrec@1 91.992 (92.851)\tPrec@5 99.805 (99.889)\t\n",
            "TRAINING - Epoch: [79][90/97]\tTime 0.149 (0.183)\tData 0.000 (0.014)\tLoss 0.2293 (0.2007)\tPrec@1 91.797 (92.763)\tPrec@5 99.414 (99.888)\t\n",
            "EVALUATING - Epoch: [79][0/20]\tTime 0.726 (0.726)\tData 0.672 (0.672)\tLoss 0.4336 (0.4336)\tPrec@1 84.961 (84.961)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [79][10/20]\tTime 0.085 (0.207)\tData 0.019 (0.150)\tLoss 0.5140 (0.5222)\tPrec@1 85.156 (84.304)\tPrec@5 99.805 (99.379)\t\n",
            "\n",
            "Results - Epoch: 80\n",
            "Training Loss 0.2023 \tTraining Prec@1 92.705 \tTraining Prec@5 99.889 \tValidation Loss 0.5262 \tValidation Prec@1 84.330 \tValidation Prec@5 99.340 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 81\n",
            "\n",
            "TRAINING - Epoch: [80][0/97]\tTime 1.485 (1.485)\tData 1.218 (1.218)\tLoss 0.2069 (0.2069)\tPrec@1 92.578 (92.578)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [80][10/97]\tTime 0.217 (0.337)\tData 0.000 (0.113)\tLoss 0.2096 (0.2058)\tPrec@1 92.773 (92.472)\tPrec@5 99.805 (99.964)\t\n",
            "TRAINING - Epoch: [80][20/97]\tTime 0.160 (0.254)\tData 0.000 (0.060)\tLoss 0.1989 (0.2002)\tPrec@1 92.578 (92.885)\tPrec@5 99.805 (99.963)\t\n",
            "TRAINING - Epoch: [80][30/97]\tTime 0.176 (0.225)\tData 0.000 (0.041)\tLoss 0.1971 (0.2025)\tPrec@1 91.992 (92.698)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [80][40/97]\tTime 0.155 (0.210)\tData 0.000 (0.031)\tLoss 0.1697 (0.1982)\tPrec@1 93.945 (92.816)\tPrec@5 100.000 (99.938)\t\n",
            "TRAINING - Epoch: [80][50/97]\tTime 0.168 (0.201)\tData 0.000 (0.026)\tLoss 0.2357 (0.1998)\tPrec@1 92.773 (92.743)\tPrec@5 99.805 (99.912)\t\n",
            "TRAINING - Epoch: [80][60/97]\tTime 0.154 (0.194)\tData 0.000 (0.022)\tLoss 0.2358 (0.2020)\tPrec@1 91.406 (92.709)\tPrec@5 99.805 (99.901)\t\n",
            "TRAINING - Epoch: [80][70/97]\tTime 0.177 (0.190)\tData 0.000 (0.019)\tLoss 0.2309 (0.2021)\tPrec@1 92.578 (92.718)\tPrec@5 99.805 (99.906)\t\n",
            "TRAINING - Epoch: [80][80/97]\tTime 0.168 (0.191)\tData 0.000 (0.017)\tLoss 0.1756 (0.2021)\tPrec@1 93.945 (92.766)\tPrec@5 99.805 (99.908)\t\n",
            "TRAINING - Epoch: [80][90/97]\tTime 0.150 (0.186)\tData 0.000 (0.015)\tLoss 0.1915 (0.2029)\tPrec@1 93.750 (92.748)\tPrec@5 100.000 (99.897)\t\n",
            "EVALUATING - Epoch: [80][0/20]\tTime 0.989 (0.989)\tData 0.940 (0.940)\tLoss 0.5085 (0.5085)\tPrec@1 82.617 (82.617)\tPrec@5 99.609 (99.609)\t\n",
            "EVALUATING - Epoch: [80][10/20]\tTime 0.072 (0.188)\tData 0.000 (0.132)\tLoss 0.5199 (0.5522)\tPrec@1 84.570 (83.949)\tPrec@5 99.609 (99.343)\t\n",
            "\n",
            "Results - Epoch: 81\n",
            "Training Loss 0.2038 \tTraining Prec@1 92.693 \tTraining Prec@5 99.893 \tValidation Loss 0.5474 \tValidation Prec@1 84.020 \tValidation Prec@5 99.400 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 82\n",
            "\n",
            "TRAINING - Epoch: [81][0/97]\tTime 1.580 (1.580)\tData 1.311 (1.311)\tLoss 0.1676 (0.1676)\tPrec@1 93.945 (93.945)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [81][10/97]\tTime 0.161 (0.333)\tData 0.005 (0.122)\tLoss 0.1812 (0.1762)\tPrec@1 93.359 (93.839)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [81][20/97]\tTime 0.176 (0.253)\tData 0.014 (0.065)\tLoss 0.1443 (0.1695)\tPrec@1 95.117 (93.964)\tPrec@5 99.805 (99.944)\t\n",
            "TRAINING - Epoch: [81][30/97]\tTime 0.166 (0.225)\tData 0.000 (0.045)\tLoss 0.1552 (0.1655)\tPrec@1 93.750 (94.109)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [81][40/97]\tTime 0.153 (0.208)\tData 0.000 (0.034)\tLoss 0.1671 (0.1618)\tPrec@1 94.727 (94.293)\tPrec@5 100.000 (99.943)\t\n",
            "TRAINING - Epoch: [81][50/97]\tTime 0.209 (0.204)\tData 0.016 (0.028)\tLoss 0.1562 (0.1594)\tPrec@1 93.945 (94.413)\tPrec@5 100.000 (99.939)\t\n",
            "TRAINING - Epoch: [81][60/97]\tTime 0.165 (0.200)\tData 0.000 (0.024)\tLoss 0.1333 (0.1544)\tPrec@1 96.094 (94.682)\tPrec@5 100.000 (99.933)\t\n",
            "TRAINING - Epoch: [81][70/97]\tTime 0.155 (0.195)\tData 0.000 (0.021)\tLoss 0.1224 (0.1518)\tPrec@1 96.875 (94.773)\tPrec@5 99.805 (99.939)\t\n",
            "TRAINING - Epoch: [81][80/97]\tTime 0.171 (0.190)\tData 0.000 (0.018)\tLoss 0.1606 (0.1506)\tPrec@1 94.141 (94.825)\tPrec@5 100.000 (99.937)\t\n",
            "TRAINING - Epoch: [81][90/97]\tTime 0.150 (0.186)\tData 0.000 (0.016)\tLoss 0.1121 (0.1486)\tPrec@1 96.484 (94.892)\tPrec@5 100.000 (99.940)\t\n",
            "EVALUATING - Epoch: [81][0/20]\tTime 0.974 (0.974)\tData 0.923 (0.923)\tLoss 0.2776 (0.2776)\tPrec@1 90.430 (90.430)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [81][10/20]\tTime 0.055 (0.188)\tData 0.000 (0.133)\tLoss 0.3384 (0.3700)\tPrec@1 90.625 (89.009)\tPrec@5 99.414 (99.592)\t\n",
            "\n",
            "Results - Epoch: 82\n",
            "Training Loss 0.1481 \tTraining Prec@1 94.934 \tTraining Prec@5 99.938 \tValidation Loss 0.3677 \tValidation Prec@1 88.980 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 83\n",
            "\n",
            "TRAINING - Epoch: [82][0/97]\tTime 1.392 (1.392)\tData 1.097 (1.097)\tLoss 0.1223 (0.1223)\tPrec@1 95.508 (95.508)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [82][10/97]\tTime 0.159 (0.334)\tData 0.000 (0.103)\tLoss 0.1277 (0.1329)\tPrec@1 95.508 (95.455)\tPrec@5 99.805 (99.982)\t\n",
            "TRAINING - Epoch: [82][20/97]\tTime 0.192 (0.272)\tData 0.000 (0.055)\tLoss 0.1428 (0.1314)\tPrec@1 95.898 (95.564)\tPrec@5 100.000 (99.944)\t\n",
            "TRAINING - Epoch: [82][30/97]\tTime 0.153 (0.238)\tData 0.000 (0.038)\tLoss 0.1382 (0.1317)\tPrec@1 95.117 (95.520)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [82][40/97]\tTime 0.180 (0.220)\tData 0.000 (0.029)\tLoss 0.1211 (0.1310)\tPrec@1 96.289 (95.455)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [82][50/97]\tTime 0.162 (0.209)\tData 0.000 (0.024)\tLoss 0.1103 (0.1289)\tPrec@1 96.680 (95.554)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [82][60/97]\tTime 0.150 (0.200)\tData 0.000 (0.020)\tLoss 0.1544 (0.1316)\tPrec@1 94.922 (95.489)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [82][70/97]\tTime 0.149 (0.195)\tData 0.000 (0.017)\tLoss 0.1664 (0.1299)\tPrec@1 95.117 (95.568)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [82][80/97]\tTime 0.159 (0.191)\tData 0.000 (0.015)\tLoss 0.1332 (0.1306)\tPrec@1 95.703 (95.534)\tPrec@5 100.000 (99.957)\t\n",
            "TRAINING - Epoch: [82][90/97]\tTime 0.150 (0.187)\tData 0.000 (0.014)\tLoss 0.1698 (0.1316)\tPrec@1 93.945 (95.473)\tPrec@5 99.805 (99.957)\t\n",
            "EVALUATING - Epoch: [82][0/20]\tTime 1.106 (1.106)\tData 1.057 (1.057)\tLoss 0.2857 (0.2857)\tPrec@1 89.453 (89.453)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [82][10/20]\tTime 0.069 (0.195)\tData 0.024 (0.137)\tLoss 0.3349 (0.3705)\tPrec@1 89.453 (88.707)\tPrec@5 99.414 (99.609)\t\n",
            "\n",
            "Results - Epoch: 83\n",
            "Training Loss 0.1312 \tTraining Prec@1 95.486 \tTraining Prec@5 99.958 \tValidation Loss 0.3667 \tValidation Prec@1 88.740 \tValidation Prec@5 99.660 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 84\n",
            "\n",
            "TRAINING - Epoch: [83][0/97]\tTime 1.585 (1.585)\tData 1.384 (1.384)\tLoss 0.1368 (0.1368)\tPrec@1 94.531 (94.531)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [83][10/97]\tTime 0.184 (0.382)\tData 0.000 (0.151)\tLoss 0.1293 (0.1281)\tPrec@1 96.484 (95.455)\tPrec@5 99.805 (99.982)\t\n",
            "TRAINING - Epoch: [83][20/97]\tTime 0.149 (0.276)\tData 0.000 (0.079)\tLoss 0.1075 (0.1233)\tPrec@1 96.484 (95.750)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [83][30/97]\tTime 0.158 (0.240)\tData 0.000 (0.054)\tLoss 0.1348 (0.1231)\tPrec@1 95.117 (95.728)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [83][40/97]\tTime 0.157 (0.221)\tData 0.000 (0.041)\tLoss 0.1114 (0.1230)\tPrec@1 95.508 (95.698)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [83][50/97]\tTime 0.166 (0.209)\tData 0.000 (0.033)\tLoss 0.0976 (0.1243)\tPrec@1 97.070 (95.669)\tPrec@5 100.000 (99.977)\t\n",
            "TRAINING - Epoch: [83][60/97]\tTime 0.165 (0.201)\tData 0.000 (0.028)\tLoss 0.1069 (0.1239)\tPrec@1 96.094 (95.719)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [83][70/97]\tTime 0.163 (0.195)\tData 0.000 (0.024)\tLoss 0.1210 (0.1236)\tPrec@1 95.703 (95.772)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [83][80/97]\tTime 0.152 (0.191)\tData 0.000 (0.021)\tLoss 0.1202 (0.1253)\tPrec@1 95.703 (95.730)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [83][90/97]\tTime 0.149 (0.186)\tData 0.000 (0.019)\tLoss 0.1574 (0.1255)\tPrec@1 93.555 (95.714)\tPrec@5 100.000 (99.974)\t\n",
            "EVALUATING - Epoch: [83][0/20]\tTime 1.538 (1.538)\tData 1.482 (1.482)\tLoss 0.2731 (0.2731)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [83][10/20]\tTime 0.047 (0.243)\tData 0.000 (0.186)\tLoss 0.3280 (0.3682)\tPrec@1 89.453 (89.080)\tPrec@5 99.609 (99.645)\t\n",
            "\n",
            "Results - Epoch: 84\n",
            "Training Loss 0.1251 \tTraining Prec@1 95.743 \tTraining Prec@5 99.976 \tValidation Loss 0.3637 \tValidation Prec@1 89.200 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 85\n",
            "\n",
            "TRAINING - Epoch: [84][0/97]\tTime 1.370 (1.370)\tData 1.070 (1.070)\tLoss 0.1310 (0.1310)\tPrec@1 95.898 (95.898)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [84][10/97]\tTime 0.148 (0.334)\tData 0.000 (0.099)\tLoss 0.1213 (0.1132)\tPrec@1 95.898 (96.129)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [84][20/97]\tTime 0.165 (0.250)\tData 0.000 (0.052)\tLoss 0.1167 (0.1138)\tPrec@1 95.508 (96.280)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [84][30/97]\tTime 0.147 (0.223)\tData 0.000 (0.036)\tLoss 0.1255 (0.1170)\tPrec@1 95.898 (96.119)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [84][40/97]\tTime 0.178 (0.209)\tData 0.000 (0.028)\tLoss 0.0973 (0.1165)\tPrec@1 97.461 (96.099)\tPrec@5 99.805 (99.957)\t\n",
            "TRAINING - Epoch: [84][50/97]\tTime 0.150 (0.199)\tData 0.000 (0.022)\tLoss 0.1539 (0.1183)\tPrec@1 95.117 (96.032)\tPrec@5 99.805 (99.950)\t\n",
            "TRAINING - Epoch: [84][60/97]\tTime 0.150 (0.193)\tData 0.000 (0.019)\tLoss 0.1067 (0.1178)\tPrec@1 95.898 (96.017)\tPrec@5 100.000 (99.949)\t\n",
            "TRAINING - Epoch: [84][70/97]\tTime 0.152 (0.189)\tData 0.000 (0.017)\tLoss 0.1123 (0.1173)\tPrec@1 96.094 (96.019)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [84][80/97]\tTime 0.167 (0.185)\tData 0.013 (0.015)\tLoss 0.0980 (0.1175)\tPrec@1 96.680 (96.024)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [84][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.013)\tLoss 0.0799 (0.1176)\tPrec@1 98.242 (96.042)\tPrec@5 100.000 (99.955)\t\n",
            "EVALUATING - Epoch: [84][0/20]\tTime 1.032 (1.032)\tData 0.947 (0.947)\tLoss 0.2774 (0.2774)\tPrec@1 91.016 (91.016)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [84][10/20]\tTime 0.052 (0.195)\tData 0.000 (0.137)\tLoss 0.3223 (0.3694)\tPrec@1 90.820 (89.080)\tPrec@5 99.219 (99.538)\t\n",
            "\n",
            "Results - Epoch: 85\n",
            "Training Loss 0.1178 \tTraining Prec@1 96.007 \tTraining Prec@5 99.958 \tValidation Loss 0.3629 \tValidation Prec@1 89.080 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 86\n",
            "\n",
            "TRAINING - Epoch: [85][0/97]\tTime 1.495 (1.495)\tData 1.199 (1.199)\tLoss 0.0822 (0.0822)\tPrec@1 97.656 (97.656)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [85][10/97]\tTime 0.178 (0.334)\tData 0.000 (0.113)\tLoss 0.0989 (0.1085)\tPrec@1 97.070 (96.378)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [85][20/97]\tTime 0.150 (0.254)\tData 0.000 (0.060)\tLoss 0.1203 (0.1128)\tPrec@1 95.312 (96.150)\tPrec@5 100.000 (99.972)\t\n",
            "TRAINING - Epoch: [85][30/97]\tTime 0.172 (0.226)\tData 0.000 (0.041)\tLoss 0.1189 (0.1161)\tPrec@1 96.484 (96.113)\tPrec@5 99.805 (99.943)\t\n",
            "TRAINING - Epoch: [85][40/97]\tTime 0.166 (0.209)\tData 0.000 (0.031)\tLoss 0.1214 (0.1175)\tPrec@1 94.531 (95.965)\tPrec@5 100.000 (99.948)\t\n",
            "TRAINING - Epoch: [85][50/97]\tTime 0.165 (0.200)\tData 0.000 (0.025)\tLoss 0.1506 (0.1160)\tPrec@1 94.727 (95.979)\tPrec@5 100.000 (99.954)\t\n",
            "TRAINING - Epoch: [85][60/97]\tTime 0.162 (0.193)\tData 0.000 (0.021)\tLoss 0.0906 (0.1159)\tPrec@1 97.070 (95.985)\tPrec@5 100.000 (99.958)\t\n",
            "TRAINING - Epoch: [85][70/97]\tTime 0.150 (0.188)\tData 0.000 (0.018)\tLoss 0.1307 (0.1162)\tPrec@1 93.945 (95.953)\tPrec@5 100.000 (99.961)\t\n",
            "TRAINING - Epoch: [85][80/97]\tTime 0.155 (0.184)\tData 0.001 (0.016)\tLoss 0.1247 (0.1167)\tPrec@1 96.289 (95.942)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [85][90/97]\tTime 0.148 (0.180)\tData 0.000 (0.014)\tLoss 0.1231 (0.1159)\tPrec@1 95.898 (95.984)\tPrec@5 100.000 (99.959)\t\n",
            "EVALUATING - Epoch: [85][0/20]\tTime 1.324 (1.324)\tData 1.273 (1.273)\tLoss 0.2671 (0.2671)\tPrec@1 90.625 (90.625)\tPrec@5 100.000 (100.000)\t\n",
            "EVALUATING - Epoch: [85][10/20]\tTime 0.050 (0.199)\tData 0.000 (0.146)\tLoss 0.3177 (0.3656)\tPrec@1 90.430 (89.045)\tPrec@5 99.414 (99.556)\t\n",
            "\n",
            "Results - Epoch: 86\n",
            "Training Loss 0.1158 \tTraining Prec@1 95.997 \tTraining Prec@5 99.958 \tValidation Loss 0.3596 \tValidation Prec@1 89.150 \tValidation Prec@5 99.580 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 87\n",
            "\n",
            "TRAINING - Epoch: [86][0/97]\tTime 1.384 (1.384)\tData 1.100 (1.100)\tLoss 0.1019 (0.1019)\tPrec@1 97.461 (97.461)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [86][10/97]\tTime 0.162 (0.329)\tData 0.005 (0.103)\tLoss 0.1109 (0.1037)\tPrec@1 96.875 (96.715)\tPrec@5 99.805 (99.964)\t\n",
            "TRAINING - Epoch: [86][20/97]\tTime 0.157 (0.247)\tData 0.000 (0.055)\tLoss 0.0935 (0.1063)\tPrec@1 96.094 (96.512)\tPrec@5 100.000 (99.972)\t\n",
            "TRAINING - Epoch: [86][30/97]\tTime 0.149 (0.218)\tData 0.000 (0.038)\tLoss 0.1154 (0.1067)\tPrec@1 95.898 (96.447)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [86][40/97]\tTime 0.189 (0.205)\tData 0.000 (0.029)\tLoss 0.0989 (0.1076)\tPrec@1 97.070 (96.446)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [86][50/97]\tTime 0.153 (0.196)\tData 0.000 (0.024)\tLoss 0.0973 (0.1085)\tPrec@1 97.461 (96.442)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [86][60/97]\tTime 0.154 (0.190)\tData 0.000 (0.020)\tLoss 0.1308 (0.1099)\tPrec@1 94.922 (96.382)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [86][70/97]\tTime 0.156 (0.186)\tData 0.000 (0.017)\tLoss 0.1248 (0.1116)\tPrec@1 95.312 (96.300)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [86][80/97]\tTime 0.169 (0.183)\tData 0.000 (0.015)\tLoss 0.1304 (0.1120)\tPrec@1 95.117 (96.296)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [86][90/97]\tTime 0.150 (0.179)\tData 0.000 (0.014)\tLoss 0.1059 (0.1129)\tPrec@1 96.484 (96.263)\tPrec@5 100.000 (99.972)\t\n",
            "EVALUATING - Epoch: [86][0/20]\tTime 1.082 (1.082)\tData 1.028 (1.028)\tLoss 0.2804 (0.2804)\tPrec@1 90.820 (90.820)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [86][10/20]\tTime 0.048 (0.187)\tData 0.000 (0.132)\tLoss 0.3205 (0.3751)\tPrec@1 90.234 (88.920)\tPrec@5 99.414 (99.574)\t\n",
            "\n",
            "Results - Epoch: 87\n",
            "Training Loss 0.1130 \tTraining Prec@1 96.277 \tTraining Prec@5 99.970 \tValidation Loss 0.3691 \tValidation Prec@1 88.800 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 88\n",
            "\n",
            "TRAINING - Epoch: [87][0/97]\tTime 1.160 (1.160)\tData 0.894 (0.894)\tLoss 0.1060 (0.1060)\tPrec@1 95.898 (95.898)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [87][10/97]\tTime 0.146 (0.332)\tData 0.000 (0.093)\tLoss 0.0998 (0.1050)\tPrec@1 97.070 (96.254)\tPrec@5 100.000 (99.982)\t\n",
            "TRAINING - Epoch: [87][20/97]\tTime 0.151 (0.251)\tData 0.000 (0.049)\tLoss 0.0913 (0.1098)\tPrec@1 97.461 (96.289)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [87][30/97]\tTime 0.148 (0.222)\tData 0.000 (0.034)\tLoss 0.0969 (0.1086)\tPrec@1 97.070 (96.339)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [87][40/97]\tTime 0.155 (0.208)\tData 0.000 (0.026)\tLoss 0.1113 (0.1082)\tPrec@1 96.680 (96.442)\tPrec@5 100.000 (99.967)\t\n",
            "TRAINING - Epoch: [87][50/97]\tTime 0.165 (0.198)\tData 0.000 (0.021)\tLoss 0.1356 (0.1085)\tPrec@1 95.312 (96.431)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [87][60/97]\tTime 0.169 (0.193)\tData 0.000 (0.018)\tLoss 0.1411 (0.1092)\tPrec@1 94.531 (96.372)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [87][70/97]\tTime 0.154 (0.188)\tData 0.005 (0.015)\tLoss 0.1177 (0.1090)\tPrec@1 95.898 (96.369)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [87][80/97]\tTime 0.150 (0.185)\tData 0.000 (0.014)\tLoss 0.1092 (0.1104)\tPrec@1 96.680 (96.311)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [87][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.012)\tLoss 0.1305 (0.1105)\tPrec@1 95.508 (96.304)\tPrec@5 100.000 (99.976)\t\n",
            "EVALUATING - Epoch: [87][0/20]\tTime 1.105 (1.105)\tData 1.054 (1.054)\tLoss 0.2828 (0.2828)\tPrec@1 91.016 (91.016)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [87][10/20]\tTime 0.052 (0.190)\tData 0.000 (0.134)\tLoss 0.3268 (0.3764)\tPrec@1 90.234 (89.080)\tPrec@5 99.609 (99.645)\t\n",
            "\n",
            "Results - Epoch: 88\n",
            "Training Loss 0.1096 \tTraining Prec@1 96.333 \tTraining Prec@5 99.978 \tValidation Loss 0.3682 \tValidation Prec@1 89.100 \tValidation Prec@5 99.680 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 89\n",
            "\n",
            "TRAINING - Epoch: [88][0/97]\tTime 1.414 (1.414)\tData 1.123 (1.123)\tLoss 0.1027 (0.1027)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [88][10/97]\tTime 0.159 (0.332)\tData 0.000 (0.104)\tLoss 0.0952 (0.1017)\tPrec@1 97.266 (96.680)\tPrec@5 100.000 (99.982)\t\n",
            "TRAINING - Epoch: [88][20/97]\tTime 0.154 (0.252)\tData 0.005 (0.055)\tLoss 0.1394 (0.1087)\tPrec@1 95.508 (96.522)\tPrec@5 100.000 (99.963)\t\n",
            "TRAINING - Epoch: [88][30/97]\tTime 0.178 (0.223)\tData 0.000 (0.038)\tLoss 0.1205 (0.1090)\tPrec@1 95.898 (96.421)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [88][40/97]\tTime 0.164 (0.208)\tData 0.000 (0.029)\tLoss 0.0834 (0.1059)\tPrec@1 97.461 (96.542)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [88][50/97]\tTime 0.168 (0.199)\tData 0.000 (0.023)\tLoss 0.1065 (0.1052)\tPrec@1 96.875 (96.569)\tPrec@5 100.000 (99.977)\t\n",
            "TRAINING - Epoch: [88][60/97]\tTime 0.154 (0.193)\tData 0.000 (0.020)\tLoss 0.1223 (0.1069)\tPrec@1 95.508 (96.507)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [88][70/97]\tTime 0.150 (0.188)\tData 0.000 (0.017)\tLoss 0.1209 (0.1061)\tPrec@1 95.312 (96.517)\tPrec@5 100.000 (99.972)\t\n",
            "TRAINING - Epoch: [88][80/97]\tTime 0.167 (0.185)\tData 0.000 (0.015)\tLoss 0.1191 (0.1072)\tPrec@1 96.289 (96.484)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [88][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.013)\tLoss 0.1287 (0.1076)\tPrec@1 95.117 (96.437)\tPrec@5 100.000 (99.970)\t\n",
            "EVALUATING - Epoch: [88][0/20]\tTime 1.067 (1.067)\tData 1.009 (1.009)\tLoss 0.2919 (0.2919)\tPrec@1 90.039 (90.039)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [88][10/20]\tTime 0.045 (0.194)\tData 0.000 (0.141)\tLoss 0.3305 (0.3784)\tPrec@1 90.039 (89.240)\tPrec@5 99.219 (99.663)\t\n",
            "\n",
            "Results - Epoch: 89\n",
            "Training Loss 0.1078 \tTraining Prec@1 96.450 \tTraining Prec@5 99.968 \tValidation Loss 0.3698 \tValidation Prec@1 89.270 \tValidation Prec@5 99.660 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 90\n",
            "\n",
            "TRAINING - Epoch: [89][0/97]\tTime 1.378 (1.378)\tData 1.102 (1.102)\tLoss 0.0897 (0.0897)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [89][10/97]\tTime 0.175 (0.336)\tData 0.000 (0.104)\tLoss 0.1046 (0.0975)\tPrec@1 96.680 (96.946)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [89][20/97]\tTime 0.161 (0.253)\tData 0.000 (0.055)\tLoss 0.0815 (0.1002)\tPrec@1 97.852 (96.689)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [89][30/97]\tTime 0.165 (0.222)\tData 0.000 (0.037)\tLoss 0.1136 (0.1019)\tPrec@1 96.289 (96.617)\tPrec@5 99.805 (99.968)\t\n",
            "TRAINING - Epoch: [89][40/97]\tTime 0.156 (0.207)\tData 0.000 (0.029)\tLoss 0.1151 (0.1063)\tPrec@1 96.094 (96.446)\tPrec@5 100.000 (99.967)\t\n",
            "TRAINING - Epoch: [89][50/97]\tTime 0.160 (0.198)\tData 0.000 (0.023)\tLoss 0.1090 (0.1069)\tPrec@1 96.680 (96.438)\tPrec@5 100.000 (99.973)\t\n",
            "TRAINING - Epoch: [89][60/97]\tTime 0.167 (0.192)\tData 0.009 (0.020)\tLoss 0.1308 (0.1075)\tPrec@1 94.531 (96.376)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [89][70/97]\tTime 0.148 (0.187)\tData 0.000 (0.017)\tLoss 0.1100 (0.1071)\tPrec@1 97.070 (96.391)\tPrec@5 99.805 (99.975)\t\n",
            "TRAINING - Epoch: [89][80/97]\tTime 0.163 (0.185)\tData 0.005 (0.015)\tLoss 0.1061 (0.1068)\tPrec@1 96.289 (96.424)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [89][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.013)\tLoss 0.1190 (0.1066)\tPrec@1 96.289 (96.414)\tPrec@5 100.000 (99.976)\t\n",
            "EVALUATING - Epoch: [89][0/20]\tTime 1.374 (1.374)\tData 1.315 (1.315)\tLoss 0.2832 (0.2832)\tPrec@1 90.625 (90.625)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [89][10/20]\tTime 0.044 (0.201)\tData 0.000 (0.150)\tLoss 0.3262 (0.3807)\tPrec@1 90.430 (89.364)\tPrec@5 99.414 (99.609)\t\n",
            "\n",
            "Results - Epoch: 90\n",
            "Training Loss 0.1069 \tTraining Prec@1 96.390 \tTraining Prec@5 99.976 \tValidation Loss 0.3717 \tValidation Prec@1 89.240 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 91\n",
            "\n",
            "TRAINING - Epoch: [90][0/97]\tTime 1.385 (1.385)\tData 1.134 (1.134)\tLoss 0.1087 (0.1087)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [90][10/97]\tTime 0.185 (0.330)\tData 0.000 (0.107)\tLoss 0.1046 (0.1003)\tPrec@1 96.484 (96.573)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [90][20/97]\tTime 0.169 (0.253)\tData 0.000 (0.057)\tLoss 0.1327 (0.1001)\tPrec@1 95.508 (96.689)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [90][30/97]\tTime 0.153 (0.223)\tData 0.000 (0.039)\tLoss 0.0931 (0.0999)\tPrec@1 96.289 (96.648)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [90][40/97]\tTime 0.150 (0.207)\tData 0.000 (0.030)\tLoss 0.1525 (0.1001)\tPrec@1 94.141 (96.646)\tPrec@5 99.609 (99.962)\t\n",
            "TRAINING - Epoch: [90][50/97]\tTime 0.156 (0.198)\tData 0.000 (0.024)\tLoss 0.1136 (0.1017)\tPrec@1 95.898 (96.592)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [90][60/97]\tTime 0.161 (0.191)\tData 0.000 (0.020)\tLoss 0.0860 (0.1019)\tPrec@1 96.680 (96.577)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [90][70/97]\tTime 0.148 (0.187)\tData 0.000 (0.018)\tLoss 0.1041 (0.1031)\tPrec@1 96.094 (96.515)\tPrec@5 99.805 (99.972)\t\n",
            "TRAINING - Epoch: [90][80/97]\tTime 0.162 (0.184)\tData 0.000 (0.016)\tLoss 0.1105 (0.1034)\tPrec@1 96.094 (96.499)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [90][90/97]\tTime 0.151 (0.180)\tData 0.000 (0.014)\tLoss 0.0680 (0.1030)\tPrec@1 98.242 (96.504)\tPrec@5 100.000 (99.979)\t\n",
            "EVALUATING - Epoch: [90][0/20]\tTime 1.081 (1.081)\tData 1.034 (1.034)\tLoss 0.2902 (0.2902)\tPrec@1 89.648 (89.648)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [90][10/20]\tTime 0.065 (0.187)\tData 0.020 (0.134)\tLoss 0.3351 (0.3892)\tPrec@1 90.820 (88.867)\tPrec@5 99.414 (99.556)\t\n",
            "\n",
            "Results - Epoch: 91\n",
            "Training Loss 0.1032 \tTraining Prec@1 96.507 \tTraining Prec@5 99.978 \tValidation Loss 0.3797 \tValidation Prec@1 89.050 \tValidation Prec@5 99.620 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 92\n",
            "\n",
            "TRAINING - Epoch: [91][0/97]\tTime 1.545 (1.545)\tData 1.244 (1.244)\tLoss 0.0904 (0.0904)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [91][10/97]\tTime 0.150 (0.332)\tData 0.000 (0.117)\tLoss 0.0824 (0.0999)\tPrec@1 97.461 (96.733)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [91][20/97]\tTime 0.155 (0.254)\tData 0.000 (0.062)\tLoss 0.0827 (0.0989)\tPrec@1 97.070 (96.661)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [91][30/97]\tTime 0.147 (0.224)\tData 0.000 (0.042)\tLoss 0.1094 (0.1025)\tPrec@1 95.898 (96.528)\tPrec@5 100.000 (99.956)\t\n",
            "TRAINING - Epoch: [91][40/97]\tTime 0.155 (0.208)\tData 0.000 (0.032)\tLoss 0.1227 (0.1027)\tPrec@1 95.508 (96.537)\tPrec@5 100.000 (99.967)\t\n",
            "TRAINING - Epoch: [91][50/97]\tTime 0.190 (0.200)\tData 0.004 (0.026)\tLoss 0.1138 (0.1034)\tPrec@1 95.703 (96.484)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [91][60/97]\tTime 0.150 (0.194)\tData 0.000 (0.022)\tLoss 0.1086 (0.1036)\tPrec@1 96.094 (96.456)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [91][70/97]\tTime 0.148 (0.189)\tData 0.000 (0.019)\tLoss 0.0964 (0.1036)\tPrec@1 96.680 (96.462)\tPrec@5 100.000 (99.972)\t\n",
            "TRAINING - Epoch: [91][80/97]\tTime 0.180 (0.186)\tData 0.000 (0.017)\tLoss 0.0849 (0.1031)\tPrec@1 97.070 (96.516)\tPrec@5 100.000 (99.973)\t\n",
            "TRAINING - Epoch: [91][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.015)\tLoss 0.0878 (0.1031)\tPrec@1 96.875 (96.523)\tPrec@5 100.000 (99.974)\t\n",
            "EVALUATING - Epoch: [91][0/20]\tTime 1.047 (1.047)\tData 0.997 (0.997)\tLoss 0.2880 (0.2880)\tPrec@1 90.234 (90.234)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [91][10/20]\tTime 0.055 (0.188)\tData 0.000 (0.133)\tLoss 0.3197 (0.3781)\tPrec@1 90.625 (89.116)\tPrec@5 99.414 (99.609)\t\n",
            "\n",
            "Results - Epoch: 92\n",
            "Training Loss 0.1031 \tTraining Prec@1 96.523 \tTraining Prec@5 99.974 \tValidation Loss 0.3718 \tValidation Prec@1 89.170 \tValidation Prec@5 99.650 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 93\n",
            "\n",
            "TRAINING - Epoch: [92][0/97]\tTime 0.901 (0.901)\tData 0.636 (0.636)\tLoss 0.1090 (0.1090)\tPrec@1 96.094 (96.094)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [92][10/97]\tTime 0.198 (0.334)\tData 0.000 (0.093)\tLoss 0.1029 (0.0992)\tPrec@1 97.266 (96.875)\tPrec@5 100.000 (99.964)\t\n",
            "TRAINING - Epoch: [92][20/97]\tTime 0.166 (0.252)\tData 0.000 (0.049)\tLoss 0.1198 (0.0991)\tPrec@1 95.703 (96.819)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [92][30/97]\tTime 0.149 (0.222)\tData 0.000 (0.034)\tLoss 0.0899 (0.0997)\tPrec@1 97.266 (96.743)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [92][40/97]\tTime 0.149 (0.206)\tData 0.000 (0.026)\tLoss 0.1268 (0.0998)\tPrec@1 95.508 (96.670)\tPrec@5 100.000 (99.990)\t\n",
            "TRAINING - Epoch: [92][50/97]\tTime 0.161 (0.197)\tData 0.000 (0.021)\tLoss 0.0945 (0.1001)\tPrec@1 96.289 (96.630)\tPrec@5 100.000 (99.992)\t\n",
            "TRAINING - Epoch: [92][60/97]\tTime 0.167 (0.192)\tData 0.000 (0.018)\tLoss 0.1114 (0.1002)\tPrec@1 96.289 (96.644)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [92][70/97]\tTime 0.155 (0.187)\tData 0.000 (0.015)\tLoss 0.1097 (0.1006)\tPrec@1 96.680 (96.614)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [92][80/97]\tTime 0.171 (0.184)\tData 0.002 (0.014)\tLoss 0.0822 (0.1009)\tPrec@1 97.852 (96.605)\tPrec@5 100.000 (99.993)\t\n",
            "TRAINING - Epoch: [92][90/97]\tTime 0.150 (0.180)\tData 0.000 (0.012)\tLoss 0.0660 (0.1005)\tPrec@1 98.828 (96.611)\tPrec@5 100.000 (99.994)\t\n",
            "EVALUATING - Epoch: [92][0/20]\tTime 1.254 (1.254)\tData 1.202 (1.202)\tLoss 0.2875 (0.2875)\tPrec@1 90.039 (90.039)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [92][10/20]\tTime 0.048 (0.201)\tData 0.000 (0.148)\tLoss 0.3343 (0.3817)\tPrec@1 90.820 (89.062)\tPrec@5 99.609 (99.663)\t\n",
            "\n",
            "Results - Epoch: 93\n",
            "Training Loss 0.0998 \tTraining Prec@1 96.637 \tTraining Prec@5 99.994 \tValidation Loss 0.3762 \tValidation Prec@1 89.140 \tValidation Prec@5 99.690 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 94\n",
            "\n",
            "TRAINING - Epoch: [93][0/97]\tTime 1.503 (1.503)\tData 1.209 (1.209)\tLoss 0.1017 (0.1017)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [93][10/97]\tTime 0.146 (0.334)\tData 0.000 (0.113)\tLoss 0.0771 (0.0912)\tPrec@1 97.461 (96.804)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [93][20/97]\tTime 0.173 (0.252)\tData 0.005 (0.060)\tLoss 0.1012 (0.0936)\tPrec@1 96.484 (96.717)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [93][30/97]\tTime 0.153 (0.222)\tData 0.000 (0.041)\tLoss 0.1084 (0.0958)\tPrec@1 96.289 (96.717)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [93][40/97]\tTime 0.152 (0.207)\tData 0.000 (0.031)\tLoss 0.1051 (0.0960)\tPrec@1 95.703 (96.708)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [93][50/97]\tTime 0.169 (0.198)\tData 0.000 (0.025)\tLoss 0.0711 (0.0971)\tPrec@1 97.852 (96.706)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [93][60/97]\tTime 0.147 (0.192)\tData 0.000 (0.022)\tLoss 0.0761 (0.0958)\tPrec@1 97.266 (96.757)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [93][70/97]\tTime 0.179 (0.188)\tData 0.000 (0.019)\tLoss 0.0965 (0.0970)\tPrec@1 96.680 (96.715)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [93][80/97]\tTime 0.151 (0.184)\tData 0.000 (0.016)\tLoss 0.1186 (0.0973)\tPrec@1 95.703 (96.706)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [93][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.015)\tLoss 0.1265 (0.0974)\tPrec@1 95.508 (96.735)\tPrec@5 100.000 (99.976)\t\n",
            "EVALUATING - Epoch: [93][0/20]\tTime 1.002 (1.002)\tData 0.954 (0.954)\tLoss 0.2925 (0.2925)\tPrec@1 89.453 (89.453)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [93][10/20]\tTime 0.050 (0.191)\tData 0.000 (0.136)\tLoss 0.3347 (0.3869)\tPrec@1 90.039 (88.849)\tPrec@5 99.609 (99.592)\t\n",
            "\n",
            "Results - Epoch: 94\n",
            "Training Loss 0.0977 \tTraining Prec@1 96.760 \tTraining Prec@5 99.976 \tValidation Loss 0.3789 \tValidation Prec@1 88.940 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 95\n",
            "\n",
            "TRAINING - Epoch: [94][0/97]\tTime 1.478 (1.478)\tData 1.239 (1.239)\tLoss 0.1090 (0.1090)\tPrec@1 97.070 (97.070)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [94][10/97]\tTime 0.165 (0.334)\tData 0.000 (0.118)\tLoss 0.0972 (0.0942)\tPrec@1 97.070 (97.141)\tPrec@5 100.000 (99.947)\t\n",
            "TRAINING - Epoch: [94][20/97]\tTime 0.165 (0.253)\tData 0.006 (0.063)\tLoss 0.0812 (0.0959)\tPrec@1 97.461 (96.977)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [94][30/97]\tTime 0.182 (0.225)\tData 0.000 (0.043)\tLoss 0.0993 (0.0961)\tPrec@1 97.266 (96.888)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [94][40/97]\tTime 0.147 (0.208)\tData 0.000 (0.032)\tLoss 0.0761 (0.0956)\tPrec@1 97.656 (96.885)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [94][50/97]\tTime 0.157 (0.198)\tData 0.000 (0.026)\tLoss 0.0839 (0.0963)\tPrec@1 97.266 (96.844)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [94][60/97]\tTime 0.189 (0.193)\tData 0.000 (0.022)\tLoss 0.0886 (0.0967)\tPrec@1 96.875 (96.814)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [94][70/97]\tTime 0.159 (0.188)\tData 0.000 (0.019)\tLoss 0.1102 (0.0968)\tPrec@1 95.508 (96.776)\tPrec@5 100.000 (99.972)\t\n",
            "TRAINING - Epoch: [94][80/97]\tTime 0.149 (0.185)\tData 0.000 (0.017)\tLoss 0.0993 (0.0976)\tPrec@1 96.094 (96.711)\tPrec@5 100.000 (99.969)\t\n",
            "TRAINING - Epoch: [94][90/97]\tTime 0.149 (0.181)\tData 0.000 (0.015)\tLoss 0.0924 (0.0984)\tPrec@1 97.070 (96.678)\tPrec@5 100.000 (99.970)\t\n",
            "EVALUATING - Epoch: [94][0/20]\tTime 1.299 (1.299)\tData 1.238 (1.238)\tLoss 0.2763 (0.2763)\tPrec@1 90.234 (90.234)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [94][10/20]\tTime 0.067 (0.200)\tData 0.023 (0.140)\tLoss 0.3452 (0.3869)\tPrec@1 90.625 (88.956)\tPrec@5 99.414 (99.627)\t\n",
            "\n",
            "Results - Epoch: 95\n",
            "Training Loss 0.0989 \tTraining Prec@1 96.645 \tTraining Prec@5 99.968 \tValidation Loss 0.3780 \tValidation Prec@1 89.110 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 96\n",
            "\n",
            "TRAINING - Epoch: [95][0/97]\tTime 1.471 (1.471)\tData 1.186 (1.186)\tLoss 0.0856 (0.0856)\tPrec@1 97.070 (97.070)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [95][10/97]\tTime 0.210 (0.335)\tData 0.000 (0.111)\tLoss 0.1130 (0.1032)\tPrec@1 96.094 (96.626)\tPrec@5 100.000 (99.929)\t\n",
            "TRAINING - Epoch: [95][20/97]\tTime 0.183 (0.252)\tData 0.007 (0.059)\tLoss 0.1239 (0.1021)\tPrec@1 96.289 (96.680)\tPrec@5 100.000 (99.953)\t\n",
            "TRAINING - Epoch: [95][30/97]\tTime 0.151 (0.224)\tData 0.000 (0.040)\tLoss 0.1087 (0.0989)\tPrec@1 96.484 (96.667)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [95][40/97]\tTime 0.173 (0.209)\tData 0.007 (0.031)\tLoss 0.0996 (0.0976)\tPrec@1 97.070 (96.708)\tPrec@5 100.000 (99.962)\t\n",
            "TRAINING - Epoch: [95][50/97]\tTime 0.156 (0.199)\tData 0.000 (0.025)\tLoss 0.0686 (0.0974)\tPrec@1 97.852 (96.703)\tPrec@5 100.000 (99.966)\t\n",
            "TRAINING - Epoch: [95][60/97]\tTime 0.156 (0.193)\tData 0.000 (0.021)\tLoss 0.0949 (0.0981)\tPrec@1 97.070 (96.654)\tPrec@5 100.000 (99.971)\t\n",
            "TRAINING - Epoch: [95][70/97]\tTime 0.149 (0.188)\tData 0.000 (0.018)\tLoss 0.1056 (0.0988)\tPrec@1 96.289 (96.641)\tPrec@5 100.000 (99.972)\t\n",
            "TRAINING - Epoch: [95][80/97]\tTime 0.153 (0.185)\tData 0.000 (0.016)\tLoss 0.0978 (0.0987)\tPrec@1 97.070 (96.658)\tPrec@5 100.000 (99.976)\t\n",
            "TRAINING - Epoch: [95][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.015)\tLoss 0.0926 (0.0992)\tPrec@1 97.266 (96.652)\tPrec@5 100.000 (99.979)\t\n",
            "EVALUATING - Epoch: [95][0/20]\tTime 0.675 (0.675)\tData 0.623 (0.623)\tLoss 0.2818 (0.2818)\tPrec@1 90.430 (90.430)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [95][10/20]\tTime 0.094 (0.196)\tData 0.050 (0.147)\tLoss 0.3376 (0.3840)\tPrec@1 90.234 (89.276)\tPrec@5 99.609 (99.663)\t\n",
            "\n",
            "Results - Epoch: 96\n",
            "Training Loss 0.0989 \tTraining Prec@1 96.656 \tTraining Prec@5 99.980 \tValidation Loss 0.3761 \tValidation Prec@1 89.220 \tValidation Prec@5 99.700 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 97\n",
            "\n",
            "TRAINING - Epoch: [96][0/97]\tTime 1.572 (1.572)\tData 1.337 (1.337)\tLoss 0.1179 (0.1179)\tPrec@1 95.117 (95.117)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [96][10/97]\tTime 0.149 (0.337)\tData 0.000 (0.124)\tLoss 0.0648 (0.0927)\tPrec@1 98.633 (96.804)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [96][20/97]\tTime 0.170 (0.256)\tData 0.000 (0.065)\tLoss 0.0876 (0.0910)\tPrec@1 96.484 (96.875)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [96][30/97]\tTime 0.155 (0.224)\tData 0.000 (0.045)\tLoss 0.0881 (0.0942)\tPrec@1 97.070 (96.774)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [96][40/97]\tTime 0.160 (0.209)\tData 0.000 (0.034)\tLoss 0.0938 (0.0952)\tPrec@1 96.484 (96.770)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [96][50/97]\tTime 0.150 (0.199)\tData 0.000 (0.028)\tLoss 0.0983 (0.0953)\tPrec@1 96.289 (96.714)\tPrec@5 100.000 (99.985)\t\n",
            "TRAINING - Epoch: [96][60/97]\tTime 0.154 (0.193)\tData 0.000 (0.023)\tLoss 0.1059 (0.0954)\tPrec@1 95.703 (96.705)\tPrec@5 100.000 (99.984)\t\n",
            "TRAINING - Epoch: [96][70/97]\tTime 0.152 (0.188)\tData 0.000 (0.020)\tLoss 0.0888 (0.0956)\tPrec@1 96.289 (96.688)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [96][80/97]\tTime 0.153 (0.186)\tData 0.000 (0.018)\tLoss 0.0860 (0.0964)\tPrec@1 97.266 (96.665)\tPrec@5 100.000 (99.983)\t\n",
            "TRAINING - Epoch: [96][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.016)\tLoss 0.0995 (0.0967)\tPrec@1 96.875 (96.639)\tPrec@5 100.000 (99.983)\t\n",
            "EVALUATING - Epoch: [96][0/20]\tTime 1.094 (1.094)\tData 1.038 (1.038)\tLoss 0.2965 (0.2965)\tPrec@1 90.234 (90.234)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [96][10/20]\tTime 0.056 (0.191)\tData 0.000 (0.138)\tLoss 0.3361 (0.3877)\tPrec@1 90.430 (89.258)\tPrec@5 99.414 (99.609)\t\n",
            "\n",
            "Results - Epoch: 97\n",
            "Training Loss 0.0962 \tTraining Prec@1 96.660 \tTraining Prec@5 99.984 \tValidation Loss 0.3805 \tValidation Prec@1 89.180 \tValidation Prec@5 99.670 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 98\n",
            "\n",
            "TRAINING - Epoch: [97][0/97]\tTime 1.263 (1.263)\tData 0.996 (0.996)\tLoss 0.1034 (0.1034)\tPrec@1 96.484 (96.484)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [97][10/97]\tTime 0.164 (0.341)\tData 0.000 (0.093)\tLoss 0.0934 (0.0877)\tPrec@1 97.266 (97.053)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [97][20/97]\tTime 0.155 (0.254)\tData 0.000 (0.050)\tLoss 0.0976 (0.0910)\tPrec@1 95.117 (96.884)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [97][30/97]\tTime 0.156 (0.225)\tData 0.000 (0.034)\tLoss 0.0766 (0.0913)\tPrec@1 97.461 (96.869)\tPrec@5 100.000 (99.975)\t\n",
            "TRAINING - Epoch: [97][40/97]\tTime 0.153 (0.209)\tData 0.000 (0.026)\tLoss 0.0613 (0.0906)\tPrec@1 98.242 (96.894)\tPrec@5 99.805 (99.976)\t\n",
            "TRAINING - Epoch: [97][50/97]\tTime 0.154 (0.200)\tData 0.000 (0.021)\tLoss 0.0678 (0.0925)\tPrec@1 98.242 (96.798)\tPrec@5 100.000 (99.977)\t\n",
            "TRAINING - Epoch: [97][60/97]\tTime 0.170 (0.194)\tData 0.002 (0.018)\tLoss 0.1100 (0.0937)\tPrec@1 95.898 (96.817)\tPrec@5 100.000 (99.974)\t\n",
            "TRAINING - Epoch: [97][70/97]\tTime 0.150 (0.189)\tData 0.000 (0.016)\tLoss 0.0950 (0.0940)\tPrec@1 96.680 (96.765)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [97][80/97]\tTime 0.152 (0.185)\tData 0.000 (0.014)\tLoss 0.0878 (0.0952)\tPrec@1 97.266 (96.740)\tPrec@5 100.000 (99.973)\t\n",
            "TRAINING - Epoch: [97][90/97]\tTime 0.150 (0.182)\tData 0.000 (0.013)\tLoss 0.0789 (0.0949)\tPrec@1 97.266 (96.746)\tPrec@5 100.000 (99.970)\t\n",
            "EVALUATING - Epoch: [97][0/20]\tTime 1.029 (1.029)\tData 0.976 (0.976)\tLoss 0.2897 (0.2897)\tPrec@1 90.234 (90.234)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [97][10/20]\tTime 0.050 (0.183)\tData 0.000 (0.130)\tLoss 0.3308 (0.3929)\tPrec@1 90.430 (89.240)\tPrec@5 99.609 (99.574)\t\n",
            "\n",
            "Results - Epoch: 98\n",
            "Training Loss 0.0946 \tTraining Prec@1 96.754 \tTraining Prec@5 99.970 \tValidation Loss 0.3842 \tValidation Prec@1 89.160 \tValidation Prec@5 99.600 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 99\n",
            "\n",
            "TRAINING - Epoch: [98][0/97]\tTime 1.459 (1.459)\tData 1.159 (1.159)\tLoss 0.0841 (0.0841)\tPrec@1 97.266 (97.266)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [98][10/97]\tTime 0.176 (0.335)\tData 0.000 (0.109)\tLoss 0.0995 (0.0959)\tPrec@1 97.070 (96.680)\tPrec@5 100.000 (99.982)\t\n",
            "TRAINING - Epoch: [98][20/97]\tTime 0.148 (0.252)\tData 0.000 (0.058)\tLoss 0.0763 (0.0918)\tPrec@1 98.047 (96.949)\tPrec@5 100.000 (99.991)\t\n",
            "TRAINING - Epoch: [98][30/97]\tTime 0.159 (0.223)\tData 0.005 (0.039)\tLoss 0.0966 (0.0933)\tPrec@1 95.898 (96.888)\tPrec@5 100.000 (99.994)\t\n",
            "TRAINING - Epoch: [98][40/97]\tTime 0.169 (0.208)\tData 0.000 (0.030)\tLoss 0.0853 (0.0929)\tPrec@1 96.484 (96.865)\tPrec@5 100.000 (99.995)\t\n",
            "TRAINING - Epoch: [98][50/97]\tTime 0.169 (0.199)\tData 0.010 (0.024)\tLoss 0.1120 (0.0936)\tPrec@1 96.094 (96.856)\tPrec@5 99.805 (99.985)\t\n",
            "TRAINING - Epoch: [98][60/97]\tTime 0.154 (0.193)\tData 0.000 (0.021)\tLoss 0.0765 (0.0939)\tPrec@1 97.656 (96.859)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [98][70/97]\tTime 0.160 (0.189)\tData 0.000 (0.018)\tLoss 0.0751 (0.0941)\tPrec@1 97.461 (96.842)\tPrec@5 100.000 (99.986)\t\n",
            "TRAINING - Epoch: [98][80/97]\tTime 0.155 (0.186)\tData 0.000 (0.016)\tLoss 0.1157 (0.0952)\tPrec@1 96.289 (96.771)\tPrec@5 99.805 (99.983)\t\n",
            "TRAINING - Epoch: [98][90/97]\tTime 0.149 (0.182)\tData 0.000 (0.014)\tLoss 0.0905 (0.0956)\tPrec@1 98.047 (96.789)\tPrec@5 100.000 (99.983)\t\n",
            "EVALUATING - Epoch: [98][0/20]\tTime 1.034 (1.034)\tData 0.983 (0.983)\tLoss 0.2923 (0.2923)\tPrec@1 90.234 (90.234)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [98][10/20]\tTime 0.050 (0.194)\tData 0.000 (0.136)\tLoss 0.3418 (0.3975)\tPrec@1 89.844 (89.169)\tPrec@5 99.609 (99.609)\t\n",
            "\n",
            "Results - Epoch: 99\n",
            "Training Loss 0.0961 \tTraining Prec@1 96.774 \tTraining Prec@5 99.984 \tValidation Loss 0.3884 \tValidation Prec@1 89.110 \tValidation Prec@5 99.630 \t\n",
            "\n",
            "\n",
            "Starting Epoch: 100\n",
            "\n",
            "TRAINING - Epoch: [99][0/97]\tTime 1.329 (1.329)\tData 1.039 (1.039)\tLoss 0.0872 (0.0872)\tPrec@1 96.875 (96.875)\tPrec@5 100.000 (100.000)\t\n",
            "TRAINING - Epoch: [99][10/97]\tTime 0.150 (0.336)\tData 0.000 (0.097)\tLoss 0.0806 (0.0941)\tPrec@1 97.266 (96.839)\tPrec@5 99.805 (99.964)\t\n",
            "TRAINING - Epoch: [99][20/97]\tTime 0.163 (0.253)\tData 0.000 (0.052)\tLoss 0.0765 (0.0904)\tPrec@1 97.070 (97.033)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [99][30/97]\tTime 0.163 (0.225)\tData 0.000 (0.035)\tLoss 0.1364 (0.0939)\tPrec@1 95.312 (96.925)\tPrec@5 100.000 (99.987)\t\n",
            "TRAINING - Epoch: [99][40/97]\tTime 0.196 (0.210)\tData 0.000 (0.027)\tLoss 0.0974 (0.0919)\tPrec@1 97.266 (96.994)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [99][50/97]\tTime 0.180 (0.200)\tData 0.000 (0.022)\tLoss 0.1257 (0.0925)\tPrec@1 95.703 (96.975)\tPrec@5 100.000 (99.981)\t\n",
            "TRAINING - Epoch: [99][60/97]\tTime 0.150 (0.194)\tData 0.000 (0.019)\tLoss 0.0905 (0.0930)\tPrec@1 97.266 (96.945)\tPrec@5 100.000 (99.984)\t\n",
            "TRAINING - Epoch: [99][70/97]\tTime 0.150 (0.189)\tData 0.000 (0.016)\tLoss 0.1126 (0.0936)\tPrec@1 95.508 (96.869)\tPrec@5 99.805 (99.983)\t\n",
            "TRAINING - Epoch: [99][80/97]\tTime 0.159 (0.185)\tData 0.000 (0.014)\tLoss 0.1079 (0.0933)\tPrec@1 95.703 (96.865)\tPrec@5 100.000 (99.978)\t\n",
            "TRAINING - Epoch: [99][90/97]\tTime 0.150 (0.181)\tData 0.000 (0.013)\tLoss 0.0903 (0.0941)\tPrec@1 97.461 (96.821)\tPrec@5 100.000 (99.979)\t\n",
            "EVALUATING - Epoch: [99][0/20]\tTime 1.281 (1.281)\tData 1.229 (1.229)\tLoss 0.2836 (0.2836)\tPrec@1 90.430 (90.430)\tPrec@5 99.805 (99.805)\t\n",
            "EVALUATING - Epoch: [99][10/20]\tTime 0.082 (0.193)\tData 0.038 (0.140)\tLoss 0.3362 (0.3935)\tPrec@1 90.430 (89.134)\tPrec@5 99.414 (99.574)\t\n",
            "\n",
            "Results - Epoch: 100\n",
            "Training Loss 0.0936 \tTraining Prec@1 96.837 \tTraining Prec@5 99.980 \tValidation Loss 0.3848 \tValidation Prec@1 89.200 \tValidation Prec@5 99.620 \t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jwAj_8gZkkhc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## View Results"
      ]
    },
    {
      "metadata": {
        "id": "PfbCuRpSQ-H4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1297
        },
        "outputId": "d6b355f5-b568-4c25-f717-56ad70bd07c5"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(filename=\"./results/resnet18_test/results.html\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "  \n",
              "  <head>\n",
              "    \n",
              "      <meta charset=\"utf-8\">\n",
              "      <title>Training Results - resnet18_test</title>\n",
              "      \n",
              "      \n",
              "        \n",
              "          \n",
              "        <link rel=\"stylesheet\" href=\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\" type=\"text/css\" />\n",
              "        <link rel=\"stylesheet\" href=\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\" type=\"text/css\" />\n",
              "        \n",
              "        \n",
              "          \n",
              "        <script type=\"text/javascript\" src=\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\"></script>\n",
              "        <script type=\"text/javascript\" src=\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\"></script>\n",
              "        <script type=\"text/javascript\">\n",
              "            Bokeh.set_log_level(\"info\");\n",
              "        </script>\n",
              "        \n",
              "      \n",
              "      \n",
              "    \n",
              "  </head>\n",
              "  \n",
              "  \n",
              "  <body>\n",
              "    \n",
              "      \n",
              "        \n",
              "          \n",
              "          \n",
              "            <div class=\"bk-root\" id=\"35b1a588-9075-4ea1-9f98-9250b914f1e6\"></div>\n",
              "          \n",
              "        \n",
              "      \n",
              "      \n",
              "        <script type=\"application/json\" id=\"60858516-1046-4c09-8871-465170aad63c\">\n",
              "          {\"8fb5e072-f80b-4e0e-beeb-6585e15f7613\":{\"roots\":{\"references\":[{\"attributes\":{\"callback\":null,\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":{\"__ndarray__\":\"LPaXPQqHUEArGJUUrodNQAfwFkjhukpAArwFUrh+RkCwA+fMzMxHQNSa5j0K10RAvlKW4Xq0QUDpJjFI4RpEQOJYF9ejkEBAiNLe4HqUPkDsc7UVrkc/QGDl0KJwfTtAQKTfPgoXOkBAE2HD9ag4QOgdp2hmpjtASJT2huvROkCoE9DE9ag5QAhoIuxReDdAaG/wheuRNUAYBFaOwrU0QAAi/fYoXDhA6NmsehQuO0DYo3A9Ctc1QIC3QAIAADRAsLZi//8/M0CkI7l8FC41QMAXJlO4XjNAWFuxPwrXMUBgMlWwR6E1QCjtDT4KFzBAiPTb16NwN0AQNjw9Cpc1QHgtIR+FKzFASCV1AgAAMUAshxbZo3A1QNg9edijMDJAGLfRAADAMUA4I0p7FO4yQDgawFuPwi5AyHa+H4UrNUBQr5RlZmYxQPBaQj4KFzFAwEKtaWbmLkBgKcuQwrUwQMCopM7MjDBAYKHWNDNzMUAUP8Zcj8IwQCQGgRWuxzFAQM9m1aPwLUCgibDhetQzQFAFo5LC9S5AWBe3UbieMECQdXGbmZkxQNgS8sH16DJAoGez6lG4LkBA8WPMzEwvQDiAt0AK1y5ASOoENDOzLkBYqDXNzMwuQLAubqNwPTBAKO0NPgqXMEAcwFsghSswQFDRkVyPQixAdNcScj0KMECMuWsJ12MxQDiAt0AKVy5A6MA5I4XrLkDQ91PjehQvQNCqz9WjcCtADHGsC9djMEBwaJHtUTgvQDg8vVK4Hi5AUEAT4XqUMUCABMWPwvUsQNjO91O4HjBAKOSDnpkZL0BApN8+CtcwQFioNc3MzCtANMSxrkchMUDwWkI+ClcvQPiX3ZPC9S9AmCGOdT0KJkCwWfW5HoUmQGiad5yZmSVAeDarPgrXJUDYxW00M7MlQPCwUGtmZiZA0DtO0czMJUBoTfOOwnUlQPgP6bcehSVAmNQJaGbmJUDI7snD9aglQDBDHOtRuCVAIPRsVrgeJkDoc7UVrsclQDBVMCpcjyVASAN4C9ejJUBQ2ht8FK4lQMAFEhSuxyVAQCzUmpmZJUA=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"df54e998-f36b-454c-b558-638f5824cb84\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"54c551ff-7b89-40f7-956d-3d1673cff9dd\",\"type\":\"UnionRenderers\"}},\"id\":\"b68987a5-aa41-468e-9e2a-236bf80ddc7d\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"dbf998df-a968-419b-973d-582fae01500a\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"100ce5ed-bdab-4dc1-8fce-4937775258b0\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"8e32baa7-fcd6-4e42-8c7e-5177412fbe94\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"c37054fb-20ed-4596-94b9-69bc229202a6\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"95724dae-3f6f-4137-9470-6b6828b23cef\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"af8ae069-872d-4a34-a37c-49eb3847a019\",\"type\":\"BasicTicker\"}},\"id\":\"945a31b3-c289-4ea7-a900-b09fd2a59001\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":{\"__ndarray__\":\"A19c/SBcUkBSgS+uflBPQDfLk8g0hkpAnkSmYbtFR0BSgS+ufvxDQHH1g44KPEJAikzDdrPrQEC8WZ5EpiM/QPQkMg3bJT1AeLM8iUxRO0CEjgp8cec5QIAvrn7QlThAcJYnkWkqN0DAuPpBR+k1QAgdFfjiVjVAVOCLqx9UNEAM283yJHwzQPDF1Q86PDNAMK5+0FFFMkDEdrM8ibYxQNzN8iQyFTFAeLM8iUyTMEAs8MXVDwYwQAAAAAAAQC9ACB0V+OJSLkCoYbtZnmAtQBCZhu1m9SxAEDoq8MWdLEC4m+VJZIYrQICOCnxxRStAIBX44uprKkAwTyLTsCEqQBj44uoHZSlACB0V+OLaKEBIZBq2m20oQJiG7WZ5JihAMK5+0FG9J0AYVz/oqMgnQCAV+OLq5yZAgHH1g45WJkAQOirwxZUlQBj44uoHRSZAAAAAAAB8JUCIqx90VOAkQCAV+OLqjyRA8GZ5EpkKJUD44uoHHdkkQOhJZBq2AyRAiEzDdrPAI0Dgi6sfdLgjQABfXP2geyNA6AcdFfgiI0CgowJfXIkiQNjN8iQypSJAgI4KfHFJIkAIHRX44jYiQNhulieR6SFAWD/oqMDvIUCgowJfXF0hQFg/6KjAiyFASAW+uPpxIUDYDzoq8C0hQNhulieRvSBAgNBRgS9uIECwPIlMwz4gQBA6KvDFgSBAAB0V+OLiH0CQadhulhcgQMC4+kFHDSBAAKGjAl+EHkBgnkSmYWMeQGC7WZ5EBh9AoAJfXP1gH0CgYbtZnvwcQMDVDzoq+B1AAAAAAACwHUAQ+OLqB4UcQBA6KvDFLR5AYP2gowKPHUCg5UlkGi4dQKCG7WZ5Oh1AAF9c/aBDFEDQUYEvrg4SQLA8iUzDBhFAIK5+0FHxD0DwBx0V+AIQQABCRwW+yA1AwLj6QUdVDUCg5UlkGmYMQIAvrn7Q4QxAYFz9oKPyC0DAWZ5EptELQOBmeRKZ5gpAwPIkMg3rCUCg5UlkGtYKQACEjgp8wQpAQMN2szy5CkDAk8g0bPcJQIDQUYEvzglAQKZhu1lOCUA=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"a29b4203-7311-4c44-9094-23bb088c9d9f\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"77da4078-990b-445b-b18e-0b0eff122bcb\",\"type\":\"UnionRenderers\"}},\"id\":\"598db0dc-0197-4a7f-b407-1ff4e97c5a5c\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"children\":[{\"id\":\"6b28cdd7-8a53-4ba7-bf9d-a67e266ea4e6\",\"type\":\"WidgetBox\"},{\"id\":\"efa634a2-9f51-4c48-abf0-8b0941e4ecdf\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"id\":\"39c76116-1a45-47c0-ba63-5d5431a0a045\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"id\":\"95724dae-3f6f-4137-9470-6b6828b23cef\",\"subtype\":\"Figure\",\"type\":\"Plot\"}]},\"id\":\"01deb12a-9068-4da0-b445-c6f6f35d648d\",\"type\":\"Column\"},{\"attributes\":{\"plot\":null,\"text\":\"Loss\"},\"id\":\"1d785381-a7e8-4bd0-843c-e2e6db492995\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"d597cd7a-2a72-48af-9780-0eb30e0eb184\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"c492b0ab-22b0-440d-897b-9187c7f4b411\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"54c551ff-7b89-40f7-956d-3d1673cff9dd\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"a29b4203-7311-4c44-9094-23bb088c9d9f\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"df54e998-f36b-454c-b558-638f5824cb84\",\"type\":\"Selection\"},{\"attributes\":{\"axis_label\":\"epoch\",\"formatter\":{\"id\":\"c6677a7f-dbcb-413e-9b3e-63f831d020fd\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"efa634a2-9f51-4c48-abf0-8b0941e4ecdf\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"d597cd7a-2a72-48af-9780-0eb30e0eb184\",\"type\":\"BasicTicker\"}},\"id\":\"bcf89a57-72b0-4606-92f9-60d60b0ecb48\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"7905b2af-4e24-409b-8f87-0f7ccb39e0fb\",\"type\":\"ResetTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"6be26ffe-1371-42c9-9e1c-c60698392c24\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"text\":\"&lt;h1 align=\\\"center\\\"&gt;Training Results - resnet18_test&lt;/h1&gt;\"},\"id\":\"77dc6db8-98db-4aa6-be7c-20aaa5f170ea\",\"type\":\"Div\"},{\"attributes\":{\"plot\":{\"id\":\"efa634a2-9f51-4c48-abf0-8b0941e4ecdf\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"d597cd7a-2a72-48af-9780-0eb30e0eb184\",\"type\":\"BasicTicker\"}},\"id\":\"77a3b899-c215-4a9d-abdb-c8c351100698\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"overlay\":{\"id\":\"73e4c421-85b1-4894-88c6-5d1227f405fe\",\"type\":\"BoxAnnotation\"}},\"id\":\"3a28cb9f-3035-4664-a438-09cca382df3f\",\"type\":\"BoxSelectTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":{\"__ndarray__\":\"SAW+uPotNEBQgS+ufmAkQDAN283yxBxAcJYnkWloFUCgadhulrcPQAAAAAAAAAlAoCeRadg+BkDgbpYnkekBQEBPItOw/f8/gHkSmYbN+z+Au1meRMb4P0BPItOwnfY/AB0V+OIq9D8AtpvlSUTyP8AXVz/oyPA/gP2gowIf7z+A3SxPIpPtP4DAF1c/KOw/gJYnkWkY6j8AX1z9oGPnP4BU4Iur3+Y/gGQatpul5z8AmYbtZvnjP4AatpvlCeQ/AHxx9YOO4j+A4IurHzThP4DdLE8iE+E/AIftZnmS3z8ASmQatpvcPwB3szyJzN4/AFTgi6sf3T8AP+iowBfcPwBCRwW+ONw/ANYPOirw1j8A283yJDLXPwAIHRX4Ytk/ALM8iUxD1T8AufpBR4XVPwB5EpmGbdI/AGQatptl0T8AfHH1g47SPwCEjgp88dI/AGw3y5PI0T8AdFTgi6vOPwBkGrab5c0/AGrYbpYnzj8AathulifOPwAatpvlSco/AEDoqMAXzD8AehKZhu3OPwDwxdUPOsg/ACrwxdUPyz8A6gcdFfjHPwDmSWQatsc/APDF1Q86yD8AtpvlSWTFPwCmYbtZnsQ/AIyrH3RUwz8AkmnYbpbDPwCgowJfXMQ/ALxZnkSmxT8AvFmeRKbFPwCQCnxx9b8/AEzDdrM8wD8AcvWDjgrCPwB4EpmG7b4/AFKBL65+wD8AkAp8cfW/PwB2szyJTMI/AFz9oKMCwT8ARKZhu1m8PwCEjgp8cb8/AIyrH3RUwz8AeBKZhu2+PwDwxdUPOrg/ADCuftBRuz8A0FGBL662PwA8KvDF1bs/ALxZnkSmtT8ARKZhu1m8PwAwrn7QUbs/AJAKfHH1rz8AuFmeRKalPwAAQkcFvpg/ALhZnkSmpT8AuFmeRKalPwCAEpmG7Z4/ANBRgS+ulj8AUIEvrn6gPwAAQkcFvpg/ANBRgS+ulj8AIDIN282aPwAAQkcFvng/AABCRwW+mD8AUIEvrn6gPwCgYbtZnpQ/AFCBL65+kD8AgBKZhu2ePwBQgS+ufpA/AKBhu1melD8=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"4d787361-802c-4dab-8a35-263401e3349a\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"5392d9e5-a749-4c4d-bb7d-74a2f0e00f85\",\"type\":\"UnionRenderers\"}},\"id\":\"1c0b16e4-d03b-4998-864f-e564c8d631fc\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"798d72f5-5cdd-47d5-adb2-f738f77e2ddb\",\"type\":\"LinearScale\"},{\"attributes\":{\"label\":{\"value\":\"validation\"},\"renderers\":[{\"id\":\"e628d7ca-0a47-4b73-8a18-46d6cb00e302\",\"type\":\"GlyphRenderer\"}]},\"id\":\"1acd5b91-a3d6-499a-906e-020c5498e9fb\",\"type\":\"LegendItem\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"73e4c421-85b1-4894-88c6-5d1227f405fe\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"axis_label\":\"loss\",\"formatter\":{\"id\":\"5f0c402e-e3b0-4ebe-9fad-708748daa347\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"efa634a2-9f51-4c48-abf0-8b0941e4ecdf\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"684e1398-4c33-448b-9866-2434853196c0\",\"type\":\"BasicTicker\"}},\"id\":\"bc93324e-acb8-4f75-82db-fb251b4b2089\",\"type\":\"LinearAxis\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"c6568e5e-a476-4569-b3a3-849fac46bcfc\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"c3622c05-be9d-4a7e-b752-11bb6585516f\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"684e1398-4c33-448b-9866-2434853196c0\",\"type\":\"BasicTicker\"},{\"attributes\":{\"line_color\":\"green\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"eb64cde1-b520-4586-a02e-3eb37027a020\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"5392d9e5-a749-4c4d-bb7d-74a2f0e00f85\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"callback\":null,\"renderers\":\"auto\"},\"id\":\"51a63b63-8c35-4d55-8699-53b5bc6d08d9\",\"type\":\"HoverTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"efa634a2-9f51-4c48-abf0-8b0941e4ecdf\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"684e1398-4c33-448b-9866-2434853196c0\",\"type\":\"BasicTicker\"}},\"id\":\"061cff52-8111-4499-be44-9c96cb6482ff\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"c1ba3ed3-5293-4b9f-87ff-c38164329d50\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"83febb0c-03e1-4c20-9e48-258ecd67b9ac\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"overlay\":{\"id\":\"c6568e5e-a476-4569-b3a3-849fac46bcfc\",\"type\":\"BoxAnnotation\"}},\"id\":\"166208e0-66b6-4587-bfeb-5b839230e10e\",\"type\":\"BoxSelectTool\"},{\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"id\":\"48e9ad29-896f-44d0-8a9b-a2b3e6841a3d\",\"type\":\"LegendItem\"},{\"id\":\"8a841f84-05c4-4ebd-b6e6-4e2eaaa894d0\",\"type\":\"LegendItem\"}],\"plot\":{\"id\":\"95724dae-3f6f-4137-9470-6b6828b23cef\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"ed6b417f-89a8-4eba-8b31-a2ce221c4fd9\",\"type\":\"Legend\"},{\"attributes\":{\"callback\":null,\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":{\"__ndarray__\":\"6wcdtSk+/z+x3Sxvtin6P7M8iawm2vY/4+oH/TBL9D/zJDJN3sjxPzVsN4sQPvA/jwp8UdUn7j90VOCrx7jrPwgdFfidA+o/EDoqsN+j6D/TsN3sUEnnP4ftZnlsKuY/oaMCv5sY5T98cfUjqBTkP6GjAp83ZuM/PYlMA16K4j+eRKaR5tDhP/WDjnqsouE/ItOwTYym4D9FpmFLmjTgP+5mebKAgt8/nkSmYZ6w3j9neRLZ8m7dP6nAF9eO3tw/PYlMY7kw3D+7WZ6E80XbPwt8cdUEyto/N8uTKP4z2j+BL66eZ1fZPxA6KrAYENk/JTINe99K2D+x3SxPvxXYP1c/6MhLZNc/C3xx1dv71j/BF1e/FUPWP1z9oAPnSdY/6KjARxHN1T8dFfiCKaTVP9vN8oQV4dQ/yTRsp2t51D9/0FFRjQvUP9BRgT/mWNQ/nkSmsVeP0z8SmYZdXPbSP55EphEFuNI/Wp5EBufx0j+Ejgo8KtjSP8N2swxrWNI/LU8iE9IL0j8lMg27l/TRP6GjAh/5jtE/rB90hOhw0T8q8MX1g8jQP+PqB03y69A/6KjA502e0D8gdFQAvG7QP4lMw8arONA/KvDFZb8w0D+Mqx/UEVjPP2Qathu/es8/FfjiKmJDzz9ankQmchTPPx0V+CIBcM4/IHRUQIWMzT/zJDJtgxnNPxKZhs373M0/wRdX3/H6zD8FvrgaAt/MP764+gGjwcw/dFTgy2eSyz8AAABgEX3LP6GjAj9B58s/jwp8MWskzD+eRKaB0V7KP5TINKyhJMs/A19cfex3yj8wrn7wm8jJP0JHBd4Uvco/07Dd7Amcyj8YVz+IkOTJP4ftZtmnFso/eRKZJpT0wj+uftDBRMvAP9YPOgq0A8A/NWw3i3Apvj9Nw3bTu6K9PxA6KvAS8Lw/IHRUQN0OvD9HBb6YKJa7P+CLq193X7s/2G6W18hquj8atpvlIme6P3RU4Kt5j7k/7mZ5Eq4BuT+pwBcXflO5P8uTyNSlTrk/KvDF1XCiuD/7QUcF2zm4P8k0bNc+mrg/Bb64ShT5tz8=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"d5564027-79bc-4160-a249-085ffcbf6c82\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"40fe148f-f6c2-49b7-99dd-6c5523e42e33\",\"type\":\"UnionRenderers\"}},\"id\":\"14a6216d-7ff0-441b-b852-f5999403b279\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"4d787361-802c-4dab-8a35-263401e3349a\",\"type\":\"Selection\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"26cda962-45f0-4396-b374-ecb15d85f496\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"a301dc96-0e9e-42b2-97fb-e7fa447efb4e\",\"type\":\"Line\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"82ae50e6-bf9c-41ce-bdab-a7477d24a6e7\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"725044d0-22d8-4f7a-803d-22f1f05fbc37\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"2bbf73a2-c1b5-4156-b738-d70399f85781\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"fb2a1608-3a2e-48c1-9687-a8af0c1ec372\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"id\":\"571f4af9-b376-4b89-abb3-a1a8fd861373\",\"type\":\"LegendItem\"},{\"id\":\"1acd5b91-a3d6-499a-906e-020c5498e9fb\",\"type\":\"LegendItem\"}],\"plot\":{\"id\":\"39c76116-1a45-47c0-ba63-5d5431a0a045\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"d6dc2f58-03ea-456d-bf41-b2c1818fafce\",\"type\":\"Legend\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"8e32baa7-fcd6-4e42-8c7e-5177412fbe94\",\"type\":\"PanTool\"},{\"id\":\"25f7009a-2d25-41d3-90de-68a4936acfcb\",\"type\":\"BoxZoomTool\"},{\"id\":\"dbf998df-a968-419b-973d-582fae01500a\",\"type\":\"WheelZoomTool\"},{\"id\":\"3a28cb9f-3035-4664-a438-09cca382df3f\",\"type\":\"BoxSelectTool\"},{\"id\":\"51a63b63-8c35-4d55-8699-53b5bc6d08d9\",\"type\":\"HoverTool\"},{\"id\":\"83febb0c-03e1-4c20-9e48-258ecd67b9ac\",\"type\":\"ResetTool\"},{\"id\":\"f52ea0c9-6fbb-49e1-bc75-f4d1be3bdd46\",\"type\":\"SaveTool\"}]},\"id\":\"7cab60f3-39d9-4691-a8ec-be5d2e5cb116\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"f52ea0c9-6fbb-49e1-bc75-f4d1be3bdd46\",\"type\":\"SaveTool\"},{\"attributes\":{\"data_source\":{\"id\":\"b68987a5-aa41-468e-9e2a-236bf80ddc7d\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"eb64cde1-b520-4586-a02e-3eb37027a020\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"82ae50e6-bf9c-41ce-bdab-a7477d24a6e7\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"c2c3db4b-8266-4121-a931-30a07abd8ce3\",\"type\":\"CDSView\"}},\"id\":\"e628d7ca-0a47-4b73-8a18-46d6cb00e302\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"78e2c447-7eba-4375-ac28-1d4f7e5208fd\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"fafdb790-8c49-4aac-b90b-9934d1953340\",\"type\":\"BasicTicker\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"95225fb0-d431-4a69-9b97-9757e419a852\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"training\"},\"renderers\":[{\"id\":\"c4a13218-a5d7-40ea-871e-750491d0cd04\",\"type\":\"GlyphRenderer\"}]},\"id\":\"48e9ad29-896f-44d0-8a9b-a2b3e6841a3d\",\"type\":\"LegendItem\"},{\"attributes\":{\"overlay\":{\"id\":\"2bbf73a2-c1b5-4156-b738-d70399f85781\",\"type\":\"BoxAnnotation\"}},\"id\":\"aee6ded5-905a-4488-8607-9553100f46e4\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"e8327286-b0f2-4251-9547-ff7633afd9ee\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"source\":{\"id\":\"598db0dc-0197-4a7f-b407-1ff4e97c5a5c\",\"type\":\"ColumnDataSource\"}},\"id\":\"bd01e185-c3f2-4ab3-a8c3-55d40991fe75\",\"type\":\"CDSView\"},{\"attributes\":{\"below\":[{\"id\":\"bcf89a57-72b0-4606-92f9-60d60b0ecb48\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"bc93324e-acb8-4f75-82db-fb251b4b2089\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":800,\"renderers\":[{\"id\":\"bcf89a57-72b0-4606-92f9-60d60b0ecb48\",\"type\":\"LinearAxis\"},{\"id\":\"77a3b899-c215-4a9d-abdb-c8c351100698\",\"type\":\"Grid\"},{\"id\":\"bc93324e-acb8-4f75-82db-fb251b4b2089\",\"type\":\"LinearAxis\"},{\"id\":\"061cff52-8111-4499-be44-9c96cb6482ff\",\"type\":\"Grid\"},{\"id\":\"2bbf73a2-c1b5-4156-b738-d70399f85781\",\"type\":\"BoxAnnotation\"},{\"id\":\"8cdea252-0c51-423b-a62f-ef2ea8b43665\",\"type\":\"BoxAnnotation\"},{\"id\":\"9d8fea86-6baf-4108-8809-951fc8988941\",\"type\":\"Legend\"},{\"id\":\"69dfddb3-f419-4740-b733-a9343e3a9b3b\",\"type\":\"GlyphRenderer\"},{\"id\":\"de29c889-0723-444e-8213-7f7dd031b6c4\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1d785381-a7e8-4bd0-843c-e2e6db492995\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"83b26e1d-aeee-4a94-9e66-f9a30ed5a6af\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"cc67db39-1683-40f0-8ee1-e0c3ab5a933b\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"798d72f5-5cdd-47d5-adb2-f738f77e2ddb\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"c8c36dd9-5fe9-4b82-979a-c3b330e5cde0\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"100ce5ed-bdab-4dc1-8fce-4937775258b0\",\"type\":\"LinearScale\"}},\"id\":\"efa634a2-9f51-4c48-abf0-8b0941e4ecdf\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"label\":{\"value\":\"validation\"},\"renderers\":[{\"id\":\"de29c889-0723-444e-8213-7f7dd031b6c4\",\"type\":\"GlyphRenderer\"}]},\"id\":\"d3b1b151-e0f3-4dc9-bc6c-45ab4c2562ed\",\"type\":\"LegendItem\"},{\"attributes\":{\"children\":[{\"id\":\"77dc6db8-98db-4aa6-be7c-20aaa5f170ea\",\"type\":\"Div\"}]},\"id\":\"6b28cdd7-8a53-4ba7-bf9d-a67e266ea4e6\",\"type\":\"WidgetBox\"},{\"attributes\":{\"callback\":null,\"overlay\":{\"id\":\"8cdea252-0c51-423b-a62f-ef2ea8b43665\",\"type\":\"BoxAnnotation\"}},\"id\":\"b414c594-bfb4-4db0-8717-8dbec16b3adc\",\"type\":\"BoxSelectTool\"},{\"attributes\":{\"plot\":null,\"text\":\"Error@5\"},\"id\":\"442ca243-0f85-4960-b4fc-da393e6b4bd0\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"b85d22a7-4001-4ae1-ad0a-87c5341795c4\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"7e874580-b14b-45ad-877f-5de8914b2080\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"84ec8551-2b47-4119-9683-3cf0049a3bc1\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"c3622c05-be9d-4a7e-b752-11bb6585516f\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"d8e79595-70c8-435f-8ffc-acface32ac24\",\"type\":\"CDSView\"}},\"id\":\"466aafb3-cd18-48d4-a823-89a691fec850\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"renderers\":\"auto\"},\"id\":\"ca6c0c79-0430-47ec-9ccd-105a788d3f1a\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null},\"id\":\"cc67db39-1683-40f0-8ee1-e0c3ab5a933b\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"83b46df2-996e-4c76-904c-1196ae59b0fd\",\"type\":\"ResetTool\"},{\"attributes\":{\"source\":{\"id\":\"7e874580-b14b-45ad-877f-5de8914b2080\",\"type\":\"ColumnDataSource\"}},\"id\":\"d8e79595-70c8-435f-8ffc-acface32ac24\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"a148e887-c784-4192-ba69-50433e52e473\",\"type\":\"SaveTool\"},{\"attributes\":{\"axis_label\":\"error %\",\"formatter\":{\"id\":\"67c9bcf6-8f6e-40d2-903c-ad2db4d03b7d\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"95724dae-3f6f-4137-9470-6b6828b23cef\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"af8ae069-872d-4a34-a37c-49eb3847a019\",\"type\":\"BasicTicker\"}},\"id\":\"713d83b8-e4a2-45c4-aa6a-682ab1c71766\",\"type\":\"LinearAxis\"},{\"attributes\":{\"line_color\":\"green\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"84ec8551-2b47-4119-9683-3cf0049a3bc1\",\"type\":\"Line\"},{\"attributes\":{\"click_policy\":\"hide\",\"items\":[{\"id\":\"862d6a77-fc4e-4c1f-b8e3-bbbfadf293af\",\"type\":\"LegendItem\"},{\"id\":\"d3b1b151-e0f3-4dc9-bc6c-45ab4c2562ed\",\"type\":\"LegendItem\"}],\"plot\":{\"id\":\"efa634a2-9f51-4c48-abf0-8b0941e4ecdf\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"9d8fea86-6baf-4108-8809-951fc8988941\",\"type\":\"Legend\"},{\"attributes\":{\"data_source\":{\"id\":\"14a6216d-7ff0-441b-b852-f5999403b279\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"ab1911a8-ab56-40d4-aa50-10a9d0f50151\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"95225fb0-d431-4a69-9b97-9757e419a852\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"658f0dca-17c9-4c16-b999-ca958eff381c\",\"type\":\"CDSView\"}},\"id\":\"69dfddb3-f419-4740-b733-a9343e3a9b3b\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1c0b16e4-d03b-4998-864f-e564c8d631fc\",\"type\":\"ColumnDataSource\"}},\"id\":\"f19639a9-e804-4915-a48b-2d94788f10da\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"red\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"ab1911a8-ab56-40d4-aa50-10a9d0f50151\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"14a6216d-7ff0-441b-b852-f5999403b279\",\"type\":\"ColumnDataSource\"}},\"id\":\"658f0dca-17c9-4c16-b999-ca958eff381c\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"5f0c402e-e3b0-4ebe-9fad-708748daa347\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"0c90ed29-5b2e-4b96-b5fa-c115f9abb2da\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_color\":\"red\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"7a463858-4d59-4dd1-b7d2-2f06ffd2a76d\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"c6677a7f-dbcb-413e-9b3e-63f831d020fd\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"callback\":null,\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":{\"__ndarray__\":\"A3gLJIs1/D8awFtggQ/5P4NRSb0Kufg/7MA5Awad9D+94xRdSiH4P09AE4EH9vI/duCcUTBP8D/0/dTYFGz0PxniWFdxZu8/ObTINoa07D+aCBveWkPvPyfChkcqKuo/fGEyVdUi6D+28/0UPI7oP3zysLDND+s/TRWMqsR56z+U9gb/mePpP+XyHzIrceY/nMQgkKjQ5D9xGw0gziLjPw+cMyIUg+g/EHo2SwGM7D9PQBNhSKvlP4ts57sW7+I/P1dbMR864z+1pnnH33nkP5m7lpDdfeM/eqUsQ+vb4T/TvON0rSvmP6UsQ5wiYt8/G55eCeVx5z+YTBWMePzlPxb7y64dc+A/guLHeOJ04D91AprIYvflP33Qs5l7JuI/o5I6gR0j4j+0WfWZnYLiP1yPwrWyLd4/tRX7K73g5T/2l93zKPfhP/Xb12HLpOE/j1N05AKh3z9R2ht8JHnhP2TMXSui4eE/lIeFWgqD4T8GEhSPP83gPxZqTXOtVuM/duCcEeCP3z/cRgN41OLlPx04ZwQNc98/uB6Fa0+y4D99PzVeR1LjP0dy+W+19eQ/LSEfNHgB4D/YgXMmu3jhP6H4MQbN++A/Xf5DOreg4D+94xT9OLLgPxlz10IbAeI/NxrA2/xe4j8ibHia7hjhP2Kh1jSeF90/JCh+TMc14T9Ke4PP1CXkP+0NvvDnieA/RGlvsEEY4T90JJcfz5fgP7hAgiJ0vdw/LUMcS1DM4j+0yHYeJiLhP3DOiEKXtuA/T0ATIbV24z8pyxDnAibgPx3J5d/b/uE/FYxKSl+N4T+cM6LUWgbjP9xoAO97N98/9wZf+MOg4z+F61E4X9bgP2+BBOWPhOE/t2J/ucCI1z+8dJOYLnjXPzPEsa5GRtc/xf6y20g61z8ep+hoXQTXP2wJ+aDSn9c/WRe3MeeQ1z9/+zrQTavXP7AD5+wyytc/g1FJXXFM2D9QjZeuJMzXP/LSTUJTFNg/uB6F68Y/2D99PzX+zDDYP0SLbIeYEtg/07zjNFJZ2D/caADvZJfYP921hBx/29g/9wZfGAOg2D8=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"76f4e99f-f45a-49dc-8918-aa25174472ac\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"21f3f29a-074a-42d3-a837-8fa473899810\",\"type\":\"UnionRenderers\"}},\"id\":\"36badff3-36b9-47af-8206-0bf008f378b3\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"line_color\":\"red\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"88974bf4-20e0-4f9d-bb78-30b03074da57\",\"type\":\"Line\"},{\"attributes\":{\"callback\":null},\"id\":\"78b3c707-e491-4f50-b9e0-e2048ae06937\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"77da4078-990b-445b-b18e-0b0eff122bcb\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"67c9bcf6-8f6e-40d2-903c-ad2db4d03b7d\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"598db0dc-0197-4a7f-b407-1ff4e97c5a5c\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"7a463858-4d59-4dd1-b7d2-2f06ffd2a76d\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"a301dc96-0e9e-42b2-97fb-e7fa447efb4e\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"bd01e185-c3f2-4ab3-a8c3-55d40991fe75\",\"type\":\"CDSView\"}},\"id\":\"3741d0dc-15de-4b89-962a-60fedbde1384\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"line_color\":\"green\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"23a9eb93-1a44-4684-9a88-4f72d9f359df\",\"type\":\"Line\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1a8802c2-bc90-4162-98c9-4ed5735ebb8d\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"8eb90333-74d7-41b2-89a4-28748afd0989\",\"type\":\"PanTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b4\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"d7039fe2-bf07-41e0-be11-039e53a3c0e8\",\"type\":\"Line\"},{\"attributes\":{\"data_source\":{\"id\":\"36badff3-36b9-47af-8206-0bf008f378b3\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"23a9eb93-1a44-4684-9a88-4f72d9f359df\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"d7039fe2-bf07-41e0-be11-039e53a3c0e8\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"25fa38ba-2e6d-4f85-bee5-18a116cf8e0c\",\"type\":\"CDSView\"}},\"id\":\"de29c889-0723-444e-8213-7f7dd031b6c4\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"36badff3-36b9-47af-8206-0bf008f378b3\",\"type\":\"ColumnDataSource\"}},\"id\":\"25fa38ba-2e6d-4f85-bee5-18a116cf8e0c\",\"type\":\"CDSView\"},{\"attributes\":{\"callback\":null},\"id\":\"c8c36dd9-5fe9-4b82-979a-c3b330e5cde0\",\"type\":\"DataRange1d\"},{\"attributes\":{\"axis_label\":\"epoch\",\"formatter\":{\"id\":\"b85d22a7-4001-4ae1-ad0a-87c5341795c4\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"95724dae-3f6f-4137-9470-6b6828b23cef\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"fafdb790-8c49-4aac-b90b-9934d1953340\",\"type\":\"BasicTicker\"}},\"id\":\"f915cbc7-0572-4eb4-a8a4-da20121bbf52\",\"type\":\"LinearAxis\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"78e2c447-7eba-4375-ac28-1d4f7e5208fd\",\"type\":\"PanTool\"},{\"id\":\"aee6ded5-905a-4488-8607-9553100f46e4\",\"type\":\"BoxZoomTool\"},{\"id\":\"e8327286-b0f2-4251-9547-ff7633afd9ee\",\"type\":\"WheelZoomTool\"},{\"id\":\"b414c594-bfb4-4db0-8717-8dbec16b3adc\",\"type\":\"BoxSelectTool\"},{\"id\":\"ca6c0c79-0430-47ec-9ccd-105a788d3f1a\",\"type\":\"HoverTool\"},{\"id\":\"83b46df2-996e-4c76-904c-1196ae59b0fd\",\"type\":\"ResetTool\"},{\"id\":\"a148e887-c784-4192-ba69-50433e52e473\",\"type\":\"SaveTool\"}]},\"id\":\"83b26e1d-aeee-4a94-9e66-f9a30ed5a6af\",\"type\":\"Toolbar\"},{\"attributes\":{\"data_source\":{\"id\":\"1c0b16e4-d03b-4998-864f-e564c8d631fc\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"88974bf4-20e0-4f9d-bb78-30b03074da57\",\"type\":\"Line\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"26cda962-45f0-4396-b374-ecb15d85f496\",\"type\":\"Line\"},\"selection_glyph\":null,\"view\":{\"id\":\"f19639a9-e804-4915-a48b-2d94788f10da\",\"type\":\"CDSView\"}},\"id\":\"c4a13218-a5d7-40ea-871e-750491d0cd04\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"40fe148f-f6c2-49b7-99dd-6c5523e42e33\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"d5564027-79bc-4160-a249-085ffcbf6c82\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"76f4e99f-f45a-49dc-8918-aa25174472ac\",\"type\":\"Selection\"},{\"attributes\":{\"plot\":null,\"text\":\"Error@1\"},\"id\":\"056980c8-4d72-4ef4-80f8-97eceb59ff00\",\"type\":\"Title\"},{\"attributes\":{\"source\":{\"id\":\"b68987a5-aa41-468e-9e2a-236bf80ddc7d\",\"type\":\"ColumnDataSource\"}},\"id\":\"c2c3db4b-8266-4121-a931-30a07abd8ce3\",\"type\":\"CDSView\"},{\"attributes\":{\"label\":{\"value\":\"validation\"},\"renderers\":[{\"id\":\"466aafb3-cd18-48d4-a823-89a691fec850\",\"type\":\"GlyphRenderer\"}]},\"id\":\"8a841f84-05c4-4ebd-b6e6-4e2eaaa894d0\",\"type\":\"LegendItem\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"8cdea252-0c51-423b-a62f-ef2ea8b43665\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"plot\":{\"id\":\"95724dae-3f6f-4137-9470-6b6828b23cef\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"fafdb790-8c49-4aac-b90b-9934d1953340\",\"type\":\"BasicTicker\"}},\"id\":\"d664d811-99d9-47e3-8a82-b74473bad676\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"data\":{\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":{\"__ndarray__\":\"QBzr4noUK0BwRpT2KNwhQACI9NujcBxAIEp7g+tREkAgKH6M61EcQOCRXP7//w9AQJ2AJq5HB0DABRIU16MTQCAmUwXXowBAgD81XgrX/z9g2ht8PQoLQECwcmjhevw/wNMrZeF6/D8AfT81rkf5P4Boke3MzPw/AELPZj0K+z9ga5p3FK4BQAAwuyfXo/Q/gBBYOVyP8j/A0ytl4XrwPwB6NqsehfM/APyp8XoU9j/AgXNGXI/yP4BmZmZmZu4/wEkMAnsU9j8AhetRuB7xPwDlYaFmZu4/QCNKe+tR8D+A5/upmZnxP4A/NV4K1+M/AKrx0vUo9D8AFR3J9SjsP4BH4XoUruc/ADxO0VG45j8AWRe3mZnxPwAhsHK4Hu0/AGpN8x6F6z+AJ6CJcD3qP4CDL0xmZuY/gOYdp3A98j+A/kP6rUfpPwD0bFY9Cuc/gML1KFyP4j8A9GxWPQrnP4C6SQxSuO4/AEYldcL16D8AzczMzMzkPwDHurj1KPQ/gNqK/fUo5D+ArIvbKFzvPwB5WKj1KOQ/AM3MzMzM5D8Aak3zHoXrP4DQs1mF6+k/AM3MzMzM5D+AVZ+rPQrnPwB7FK5H4eI/AKK0N7ge5T8AwTkjCtfjPwBGJXXC9eg/AM/3UzMz4z8AGJXUmZnhP4CZmZmZmeE/AEHxY1yP6j/AgXNGXI/yP4DC9Shcj+I/AClcj8L14D8AUrgehevhP4AnoIlwPeI/AFtCPrge7T8AUrgehevhPwD2KFyPwuU/gI/C9Shc5z8AwTkjCtfjPwCF61G4HuU/gML1KFyP4j8AXrpJXI/qPwCitDe4HuU/AFK4HoXr4T8AIbByuB7lP4BQ/BgzM+M/AKRwPQrX0z8A9ihcj8LVPwAUrkfhetQ/AEjhehSu1z8AexSuR+HaPwBI4XoUrtc/ABSuR+F61D8A9ihcj8LVPwBI4XoUrtc/ALgehetR2D8AZmZmZmbWPwCkcD0K19M/AEjhehSu1z8ASOF6FK7XPwAzMzMzM9M/AIXrUbge1T8AmpmZmZnZPwBI4XoUrtc/ALgehetR2D8=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"bbc03f57-51bd-4433-afd2-34bab46692a4\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"fb2a1608-3a2e-48c1-9687-a8af0c1ec372\",\"type\":\"UnionRenderers\"}},\"id\":\"7e874580-b14b-45ad-877f-5de8914b2080\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"8eb90333-74d7-41b2-89a4-28748afd0989\",\"type\":\"PanTool\"},{\"id\":\"6521b8e8-a5b9-42d8-9dfb-f92fdfba0d66\",\"type\":\"BoxZoomTool\"},{\"id\":\"c37054fb-20ed-4596-94b9-69bc229202a6\",\"type\":\"WheelZoomTool\"},{\"id\":\"166208e0-66b6-4587-bfeb-5b839230e10e\",\"type\":\"BoxSelectTool\"},{\"id\":\"7613d940-c68a-48a6-a3fa-26ccd3c97706\",\"type\":\"HoverTool\"},{\"id\":\"7905b2af-4e24-409b-8f87-0f7ccb39e0fb\",\"type\":\"ResetTool\"},{\"id\":\"0c8653ee-2e38-4f5f-8cf5-24db362458fc\",\"type\":\"SaveTool\"}]},\"id\":\"255e85cb-a1ed-4d66-bbad-005a9ba4b0d4\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null},\"id\":\"d8fcc7e3-588f-48f4-b44c-ade0739120c5\",\"type\":\"DataRange1d\"},{\"attributes\":{\"below\":[{\"id\":\"f915cbc7-0572-4eb4-a8a4-da20121bbf52\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"713d83b8-e4a2-45c4-aa6a-682ab1c71766\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":800,\"renderers\":[{\"id\":\"f915cbc7-0572-4eb4-a8a4-da20121bbf52\",\"type\":\"LinearAxis\"},{\"id\":\"d664d811-99d9-47e3-8a82-b74473bad676\",\"type\":\"Grid\"},{\"id\":\"713d83b8-e4a2-45c4-aa6a-682ab1c71766\",\"type\":\"LinearAxis\"},{\"id\":\"945a31b3-c289-4ea7-a900-b09fd2a59001\",\"type\":\"Grid\"},{\"id\":\"6be26ffe-1371-42c9-9e1c-c60698392c24\",\"type\":\"BoxAnnotation\"},{\"id\":\"73e4c421-85b1-4894-88c6-5d1227f405fe\",\"type\":\"BoxAnnotation\"},{\"id\":\"ed6b417f-89a8-4eba-8b31-a2ce221c4fd9\",\"type\":\"Legend\"},{\"id\":\"c4a13218-a5d7-40ea-871e-750491d0cd04\",\"type\":\"GlyphRenderer\"},{\"id\":\"466aafb3-cd18-48d4-a823-89a691fec850\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"442ca243-0f85-4960-b4fc-da393e6b4bd0\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"7cab60f3-39d9-4691-a8ec-be5d2e5cb116\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"c1ba3ed3-5293-4b9f-87ff-c38164329d50\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"98144e71-438a-4a14-9d9b-f9a99ebaa3b7\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"d8fcc7e3-588f-48f4-b44c-ade0739120c5\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"0c90ed29-5b2e-4b96-b5fa-c115f9abb2da\",\"type\":\"LinearScale\"}},\"id\":\"95724dae-3f6f-4137-9470-6b6828b23cef\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"21f3f29a-074a-42d3-a837-8fa473899810\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"below\":[{\"id\":\"612a8912-82cc-49d1-8813-e11bf80394f7\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"bd80b207-4211-4cee-b993-35d45c484ed6\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":800,\"renderers\":[{\"id\":\"612a8912-82cc-49d1-8813-e11bf80394f7\",\"type\":\"LinearAxis\"},{\"id\":\"d7720869-d0a0-455a-bf9c-d0f1e796d3ef\",\"type\":\"Grid\"},{\"id\":\"bd80b207-4211-4cee-b993-35d45c484ed6\",\"type\":\"LinearAxis\"},{\"id\":\"e32c2132-8ee3-44dc-a838-7c0c107f4478\",\"type\":\"Grid\"},{\"id\":\"1a8802c2-bc90-4162-98c9-4ed5735ebb8d\",\"type\":\"BoxAnnotation\"},{\"id\":\"c6568e5e-a476-4569-b3a3-849fac46bcfc\",\"type\":\"BoxAnnotation\"},{\"id\":\"d6dc2f58-03ea-456d-bf41-b2c1818fafce\",\"type\":\"Legend\"},{\"id\":\"3741d0dc-15de-4b89-962a-60fedbde1384\",\"type\":\"GlyphRenderer\"},{\"id\":\"e628d7ca-0a47-4b73-8a18-46d6cb00e302\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"056980c8-4d72-4ef4-80f8-97eceb59ff00\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"255e85cb-a1ed-4d66-bbad-005a9ba4b0d4\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"78b3c707-e491-4f50-b9e0-e2048ae06937\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"6d225bf3-8a4e-409d-b474-bd48d0fabe5b\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"13944eec-3d55-45c7-8388-3fc76f1f2d65\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"4bab36cb-c900-4f6a-b192-f3cc63c4651a\",\"type\":\"LinearScale\"}},\"id\":\"39c76116-1a45-47c0-ba63-5d5431a0a045\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"6d225bf3-8a4e-409d-b474-bd48d0fabe5b\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null},\"id\":\"13944eec-3d55-45c7-8388-3fc76f1f2d65\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"4bab36cb-c900-4f6a-b192-f3cc63c4651a\",\"type\":\"LinearScale\"},{\"attributes\":{\"overlay\":{\"id\":\"6be26ffe-1371-42c9-9e1c-c60698392c24\",\"type\":\"BoxAnnotation\"}},\"id\":\"25f7009a-2d25-41d3-90de-68a4936acfcb\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"plot\":{\"id\":\"39c76116-1a45-47c0-ba63-5d5431a0a045\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"56d4778f-b0de-40cd-8acc-7058bba2892b\",\"type\":\"BasicTicker\"}},\"id\":\"d7720869-d0a0-455a-bf9c-d0f1e796d3ef\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"0c8653ee-2e38-4f5f-8cf5-24db362458fc\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"bbc03f57-51bd-4433-afd2-34bab46692a4\",\"type\":\"Selection\"},{\"attributes\":{\"callback\":null,\"renderers\":\"auto\"},\"id\":\"7613d940-c68a-48a6-a3fa-26ccd3c97706\",\"type\":\"HoverTool\"},{\"attributes\":{\"axis_label\":\"epoch\",\"formatter\":{\"id\":\"725044d0-22d8-4f7a-803d-22f1f05fbc37\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"39c76116-1a45-47c0-ba63-5d5431a0a045\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"56d4778f-b0de-40cd-8acc-7058bba2892b\",\"type\":\"BasicTicker\"}},\"id\":\"612a8912-82cc-49d1-8813-e11bf80394f7\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"af8ae069-872d-4a34-a37c-49eb3847a019\",\"type\":\"BasicTicker\"},{\"attributes\":{\"label\":{\"value\":\"training\"},\"renderers\":[{\"id\":\"3741d0dc-15de-4b89-962a-60fedbde1384\",\"type\":\"GlyphRenderer\"}]},\"id\":\"571f4af9-b376-4b89-abb3-a1a8fd861373\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"56d4778f-b0de-40cd-8acc-7058bba2892b\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"error %\",\"formatter\":{\"id\":\"c492b0ab-22b0-440d-897b-9187c7f4b411\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"39c76116-1a45-47c0-ba63-5d5431a0a045\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ae7020f9-93e0-4cef-b6b9-cd47fcc23925\",\"type\":\"BasicTicker\"}},\"id\":\"bd80b207-4211-4cee-b993-35d45c484ed6\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"98144e71-438a-4a14-9d9b-f9a99ebaa3b7\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"ae7020f9-93e0-4cef-b6b9-cd47fcc23925\",\"type\":\"BasicTicker\"},{\"attributes\":{\"label\":{\"value\":\"training\"},\"renderers\":[{\"id\":\"69dfddb3-f419-4740-b733-a9343e3a9b3b\",\"type\":\"GlyphRenderer\"}]},\"id\":\"862d6a77-fc4e-4c1f-b8e3-bbbfadf293af\",\"type\":\"LegendItem\"},{\"attributes\":{\"overlay\":{\"id\":\"1a8802c2-bc90-4162-98c9-4ed5735ebb8d\",\"type\":\"BoxAnnotation\"}},\"id\":\"6521b8e8-a5b9-42d8-9dfb-f92fdfba0d66\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"39c76116-1a45-47c0-ba63-5d5431a0a045\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"ae7020f9-93e0-4cef-b6b9-cd47fcc23925\",\"type\":\"BasicTicker\"}},\"id\":\"e32c2132-8ee3-44dc-a838-7c0c107f4478\",\"type\":\"Grid\"}],\"root_ids\":[\"01deb12a-9068-4da0-b445-c6f6f35d648d\"]},\"title\":\"Bokeh Application\",\"version\":\"0.13.0\"}}\n",
              "        </script>\n",
              "        <script type=\"text/javascript\">\n",
              "          (function() {\n",
              "            var fn = function() {\n",
              "              Bokeh.safely(function() {\n",
              "                (function(root) {\n",
              "                  function embed_document(root) {\n",
              "                    \n",
              "                  var docs_json = document.getElementById('60858516-1046-4c09-8871-465170aad63c').textContent;\n",
              "                  var render_items = [{\"docid\":\"8fb5e072-f80b-4e0e-beeb-6585e15f7613\",\"roots\":{\"01deb12a-9068-4da0-b445-c6f6f35d648d\":\"35b1a588-9075-4ea1-9f98-9250b914f1e6\"}}];\n",
              "                  root.Bokeh.embed.embed_items(docs_json, render_items);\n",
              "                \n",
              "                  }\n",
              "                  if (root.Bokeh !== undefined) {\n",
              "                    embed_document(root);\n",
              "                  } else {\n",
              "                    var attempts = 0;\n",
              "                    var timer = setInterval(function(root) {\n",
              "                      if (root.Bokeh !== undefined) {\n",
              "                        embed_document(root);\n",
              "                        clearInterval(timer);\n",
              "                      }\n",
              "                      attempts++;\n",
              "                      if (attempts > 100) {\n",
              "                        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
              "                        clearInterval(timer);\n",
              "                      }\n",
              "                    }, 10, root)\n",
              "                  }\n",
              "                })(window);\n",
              "              });\n",
              "            };\n",
              "            if (document.readyState != \"loading\") fn();\n",
              "            else document.addEventListener(\"DOMContentLoaded\", fn);\n",
              "          })();\n",
              "        </script>\n",
              "    \n",
              "  </body>\n",
              "  \n",
              "</html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "Oi7kgIZ2oM-z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}